{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
    "from gan_attack import GANAttackManager\n",
    "from model.classify_models import lenet5, alexnet, resnet18\n",
    "from model.generator import Interpolate_Generator\n",
    "from utils import LabeledDataset, acc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "nz = 100\n",
    "\n",
    "\n",
    "target_label = 9\n",
    "\n",
    "# fake_label = 10 # ???选择数据集中不存在的标签 GoodFellow GAN \n",
    "fake_label = 2\n",
    "\n",
    "\n",
    "experimentID = 46\n",
    "note= \" real data 9->2\"\n",
    "\n",
    "dataset = 'cifar10'   # mnist  cifar10\n",
    "modelname = 'alexnet'\n",
    "pretrained = False\n",
    "generator = Interpolate_Generator(nz=nz, nc=3)   # 注意修改nc\n",
    "generator.to(device)\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "local_epochs = 3\n",
    "backdoor_local_epochs = 5\n",
    "backdoor_rounds = 5\n",
    "gan_iteration = 1000\n",
    "gradient_zoom = 5\n",
    "\n",
    "client_lr = 0.01  # 根据是否pretrained 选择0.01  0.001\n",
    "generator_lr = 0.02\n",
    "\n",
    "batch_size = 128\n",
    "fake_batch_size = batch_size // 32\n",
    "\n",
    "gen_poison_scale = 128\n",
    "class_size = 1000\n",
    "\n",
    "# NSCA权重\n",
    "beta1 = 0.2   #NSCA\n",
    "# MTA 权重\n",
    "beta2 = 0.2  # MTA\n",
    "\n",
    "# 注意修改trigger\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    if modelname == 'lenet5':\n",
    "        return lenet5(dataset, pretrained)\n",
    "    if modelname == 'alexnet':\n",
    "        return alexnet(dataset, pretrained)\n",
    "    if modelname == 'resnet18':\n",
    "        return resnet18(dataset, pretrained)\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 2022\n",
    "# 设置随机数种子\n",
    "setup_seed(seed)\n",
    "\n",
    "\n",
    "logpath = f'./log/experiment_setting/exp_{experimentID}.txt'\n",
    "if not os.path.exists(os.path.dirname(logpath)):\n",
    "    os.makedirs(os.path.dirname(logpath))\n",
    "\n",
    "settings = f\"experiment:{experimentID}\\nmodel:{modelname}-pretrained:{pretrained}\\n\\\n",
    "dataset:{dataset}\\nFL epochs:{epochs}\\nlocal epochs:{local_epochs}\\ngan_iteration:{gan_iteration}\\n\\\n",
    "batch size:{batch_size}\\nfake batch size:{fake_batch_size}\\ntarget label:{target_label}\\n\\\n",
    "fake label:{fake_label}\\ngenerator input:{nz}\\nclient lr:{client_lr}\\ngenerator lr:{generator_lr}\\n\\\n",
    "gen poison scale:{gen_poison_scale}\\nclass size:{class_size}\\nbackdoor rounds:{backdoor_rounds}\\n\\\n",
    "gradient zoom:{gradient_zoom}\\nrandom seed:{seed}\\npenalty weight beta:{beta1, beta2}\\nnote:{note}\"\n",
    "\n",
    "\n",
    "with open(logpath,'w') as f1:\n",
    "    f1.write(settings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FL settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "client_num = 10\n",
    "adversary_client_id = 0  # 对应于client1 index从0开始\n",
    "\n",
    "# 设置恶意客户端\n",
    "optimizer_g = optim.SGD(generator.parameters(), lr=generator_lr, weight_decay=1e-7, momentum=0)\n",
    "gan_attack_manager = GANAttackManager(\n",
    "    target_label,\n",
    "    generator,\n",
    "    optimizer_g,\n",
    "    criterion,\n",
    "\n",
    "    nz=nz,\n",
    "    device=device,\n",
    ")\n",
    "GANAttackFedAvgClient = gan_attack_manager.attach(FedAvgClient)\n",
    "\n",
    "net_1 = get_model()\n",
    "client_1 = GANAttackFedAvgClient(model=net_1, user_id=0)\n",
    "client_1.to(device)\n",
    "optimizer_1 = optim.SGD(client_1.parameters(), lr=client_lr, weight_decay=1e-7, momentum=0.9)\n",
    "\n",
    "\n",
    "clients = [client_1]\n",
    "optimizers = [optimizer_1]\n",
    "\n",
    "# 批量生成正常客户端\n",
    "for id in range(2, client_num+1):\n",
    "    exec(f\"net_{id}=get_model()\")\n",
    "    exec(f\"client_{id}=FedAvgClient(net_{id}, user_id=id)\")\n",
    "    exec(f\"client_{id}.to(device)\")\n",
    "    exec(f\"optimizer_{id} = optim.SGD(client_{id}.parameters(), lr=client_lr, weight_decay=1e-7, momentum=0.9)\")\n",
    "    exec(f\"clients.append(client_{id})\")\n",
    "    exec(f\"optimizers.append(optimizer_{id})\")\n",
    "\n",
    "\n",
    "global_model = get_model()\n",
    "global_model.to(device)\n",
    "server = FedAvgServer(clients, global_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "mnist_trans = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),   # resize 参数是元组\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "cifar_trans = transforms.Compose([\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "\troot=\"/home/mhc/public_dataset/mnist\", train=False, download=True, transform=mnist_trans\n",
    ")\n",
    "cifar_test = torchvision.datasets.CIFAR10(\n",
    "\troot=\"/home/mhc/public_dataset/cifar10\", train=False, download=True, transform=cifar_trans\n",
    ")\n",
    "\n",
    "if dataset == 'mnist':\n",
    "\tglobal_testset = mnist_test\n",
    "if dataset == 'cifar10':\n",
    "\tglobal_testset = cifar_test\n",
    "\n",
    "global_testloader = torch.utils.data.DataLoader(\n",
    "\tglobal_testset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# 自定义数据集划分, 数据集里的图片编号从1开始\n",
    "def custom_dataset(classlist, start_idx):\n",
    "\tsize = class_size\n",
    "\tdatalist = []\n",
    "\tif dataset == 'cifar10':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('cifar10', f\"/home/mhc/public_dataset/cifar_imgs/train/{cls}\", cls, (start_idx+1, start_idx+size+1), cifar_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\tif dataset == 'mnist':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('mnist', f\"/home/mhc/public_dataset/mnist_imgs/train/{cls}\", cls, (start_idx+1, start_idx+size+1), mnist_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\t\n",
    "\tdatatup = tuple(datalist)\n",
    "\tconcat_ds = torch.utils.data.ConcatDataset(datatup)\n",
    "\treturn concat_ds\n",
    "\n",
    "\n",
    "# trainset_1 = custom_dataset([0,1,2,3,4],0)\n",
    "# trainset_2 = custom_dataset([1,2,3,4,5],1000)\n",
    "# trainset_3 = custom_dataset([2,3,4,5,6],2000)\n",
    "# trainset_4 = custom_dataset([3,4,5,6,7],3000)\n",
    "# trainset_5 = custom_dataset([4,5,6,7,8],4000)\n",
    "# trainset_6 = custom_dataset([5,6,7,8,9],0)\n",
    "# trainset_7 = custom_dataset([6,7,8,9,0],1000)\n",
    "# trainset_8 = custom_dataset([7,8,9,0,1],2000)\n",
    "# trainset_9 = custom_dataset([8,9,0,1,2],3000)\n",
    "# trainset_10 = custom_dataset([9,0,1,2,3],4000)\n",
    "\n",
    "\n",
    "trainloaders=[]\n",
    "for id in range(1, client_num+1):\n",
    "\texec(f\"trainset_{id} = custom_dataset([id-1, id%10, (id+1)%10, (id+2)%10, (id+3)%10], ((id-1)%5)*1000)\")\n",
    "\texec(f\"trainloader_{id} = torch.utils.data.DataLoader(trainset_{id}, batch_size=batch_size, shuffle=True, num_workers=2)\")\n",
    "\texec(f\"trainloaders.append(trainloader_{id})\")\n",
    "\texec(f\"print(len(trainset_{id}))\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def save_image(epoch, imgs):\n",
    "    dirpath = f\"./image/gen_img/experiment_{experimentID}\"\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "    torchvision.utils.save_image(\n",
    "            imgs, \n",
    "            os.path.join(dirpath, f\"epoch_{epoch}.jpg\"), \n",
    "            normalize = True, \n",
    "            nrow=8\n",
    "    )\n",
    "     \n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, learing_rate):\n",
    "    if epoch < 0.5*epochs:\n",
    "        lr = learing_rate\n",
    "    elif epoch < 0.8*epochs:\n",
    "        lr = 0.1*learing_rate\n",
    "    else:\n",
    "        lr = 0.05*learing_rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad_false(model):\n",
    "    # model_para:自定义属性 ，若直接取model.named_parameters() 会包含client里的所有模型，包括生成器和判别器\n",
    "\tfor name, param in model.model_para:\n",
    "\t\t# print(name)\n",
    "\t\tif \"fc\" in name:\n",
    "\t\t\tparam.requires_grad = True\n",
    "\t\telse:\n",
    "\t\t\tparam.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    trigger_size = 8\n",
    "    triggertrans = transforms.Compose([\n",
    "    transforms.Resize((trigger_size, trigger_size)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    trigger = Image.open('/home/mhc/AIJack/invert_and_poison/image/triggers/specific/trigger13/iter14.jpg').convert('RGB')\n",
    "    # trigger = Image.open('/home/mhc/AIJack/invert_and_poison/image/triggers/trigger_13.png').convert('RGB')\n",
    "    trigger = triggertrans(trigger) # size [3, 8, 8]\n",
    "    \n",
    "if dataset == \"mnist\":\n",
    "    trigger_size = 4\n",
    "    trigger = torch.ones(1, trigger_size, trigger_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creat poison image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_num = 0\n",
    "def creat_poison(epo):\n",
    "    global poison_num\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "\n",
    "    dirpath = f\"./image/gen_img/experiment_{experimentID}/epoch_{epo}.jpg\"\n",
    "    big = Image.open(dirpath).convert('RGB')\n",
    "\n",
    "    big = trans(big)\n",
    "    for r in range(int(gen_poison_scale/8)):\n",
    "        for c in range(8):\n",
    "            poison_num += 1\n",
    "            t = big[:,2+r*34:34+r*34,2+c*34:34+c*34]\n",
    "\n",
    "            save_path = f\"./image/poison_img/exp_{experimentID}/original/{poison_num}.jpg\"\n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))  \n",
    "\n",
    "            # t2 = copy.deepcopy(t)\n",
    "            t = transforms.ToPILImage()(t)\n",
    "            t.save(save_path, quality=95, subsampling=0)\n",
    "\n",
    "            # tri = trigger.squeeze()\n",
    "\n",
    "            # t2[:, 32-2-trigger_size:32-2, 32-2-trigger_size:32-2] = tri\n",
    "\n",
    "\n",
    "            # save_path2 = f\"./image/poison_img/exp_{experimentID}/patched/{poison_num}.jpg\"\n",
    "            # if not os.path.exists(os.path.dirname(save_path2)):\n",
    "            #     os.makedirs(os.path.dirname(save_path2))    \n",
    "            # t2 = transforms.ToPILImage()(t2)\n",
    "            # t2.save(save_path2, quality=95, subsampling=0)\n",
    "\n",
    "    print(\"done!\", poison_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep poisoning.........\n",
      "epoch 0: client-1 loss:75.66830480098724 acc:0.21608527131782945\n",
      "epoch 0: client-1 loss:60.175952196121216 acc:0.30736434108527133\n",
      "epoch 0: client-1 loss:54.025712966918945 acc:0.42151162790697677\n",
      "epoch 0: client-2 loss:76.52804267406464 acc:0.1966\n",
      "epoch 0: client-2 loss:63.68132567405701 acc:0.2638\n",
      "epoch 0: client-2 loss:59.32629859447479 acc:0.3502\n",
      "epoch 0: client-3 loss:78.58167541027069 acc:0.2034\n",
      "epoch 0: client-3 loss:66.7012665271759 acc:0.2026\n",
      "epoch 0: client-3 loss:62.28709876537323 acc:0.2836\n",
      "epoch 0: client-4 loss:79.92471623420715 acc:0.2092\n",
      "epoch 0: client-4 loss:67.1023383140564 acc:0.2252\n",
      "epoch 0: client-4 loss:62.935915350914 acc:0.2868\n",
      "epoch 0: client-5 loss:79.41287016868591 acc:0.1994\n",
      "epoch 0: client-5 loss:62.50960636138916 acc:0.3192\n",
      "epoch 0: client-5 loss:52.76557791233063 acc:0.4368\n",
      "epoch 0: client-6 loss:77.9445184469223 acc:0.2094\n",
      "epoch 0: client-6 loss:57.93786811828613 acc:0.3686\n",
      "epoch 0: client-6 loss:51.24948346614838 acc:0.4656\n",
      "epoch 0: client-7 loss:74.95886957645416 acc:0.2022\n",
      "epoch 0: client-7 loss:55.58315324783325 acc:0.3892\n",
      "epoch 0: client-7 loss:50.77154469490051 acc:0.4466\n",
      "epoch 0: client-8 loss:78.38673388957977 acc:0.1808\n",
      "epoch 0: client-8 loss:63.40857136249542 acc:0.274\n",
      "epoch 0: client-8 loss:55.805081605911255 acc:0.4094\n",
      "epoch 0: client-9 loss:75.90551948547363 acc:0.2034\n",
      "epoch 0: client-9 loss:62.737571477890015 acc:0.2848\n",
      "epoch 0: client-9 loss:55.65149283409119 acc:0.4292\n",
      "epoch 0: client-10 loss:79.86011004447937 acc:0.227\n",
      "epoch 0: client-10 loss:66.33039438724518 acc:0.273\n",
      "epoch 0: client-10 loss:53.873836278915405 acc:0.4338\n",
      "epoch 100: total loss: 5.727068901062012 ;generator loss: 5.787466049194336 ;activation loss:-0.6039701104164124;lr:0.02\n",
      "epoch 200: total loss: 3.8094725608825684 ;generator loss: 3.8480634689331055 ;activation loss:-0.3859083354473114;lr:0.02\n",
      "epoch 300: total loss: 3.4547157287597656 ;generator loss: 3.4894585609436035 ;activation loss:-0.3474285900592804;lr:0.02\n",
      "epoch 400: total loss: 3.39428448677063 ;generator loss: 3.428304672241211 ;activation loss:-0.34020137786865234;lr:0.02\n",
      "epoch 500: total loss: 3.366619825363159 ;generator loss: 3.4005653858184814 ;activation loss:-0.3394547700881958;lr:0.01\n",
      "epoch 600: total loss: 3.346440076828003 ;generator loss: 3.380323648452759 ;activation loss:-0.3388359844684601;lr:0.01\n",
      "epoch 700: total loss: 3.3388497829437256 ;generator loss: 3.3725550174713135 ;activation loss:-0.33705174922943115;lr:0.01\n",
      "epoch 800: total loss: 3.329063653945923 ;generator loss: 3.3628652095794678 ;activation loss:-0.33801665902137756;lr:0.005\n",
      "epoch 900: total loss: 3.3274405002593994 ;generator loss: 3.36116886138916 ;activation loss:-0.337284654378891;lr:0.005\n",
      "epoch 1000: total loss: 3.3218302726745605 ;generator loss: 3.3555941581726074 ;activation loss:-0.3376396596431732;lr:0.005\n",
      "best loss: 3.3218302726745605\n",
      "epoch 0: gloabl accuracy 0.2219\n",
      "keep poisoning.........\n",
      "epoch 1: client-1 loss:50.3402242064476 acc:0.4682170542635659\n",
      "epoch 1: client-1 loss:43.520859718322754 acc:0.5356589147286822\n",
      "epoch 1: client-1 loss:39.58278614282608 acc:0.575968992248062\n",
      "epoch 1: client-2 loss:56.72996485233307 acc:0.3878\n",
      "epoch 1: client-2 loss:50.69254171848297 acc:0.4436\n",
      "epoch 1: client-2 loss:45.57371944189072 acc:0.4916\n",
      "epoch 1: client-3 loss:67.66587686538696 acc:0.2222\n",
      "epoch 1: client-3 loss:62.04124438762665 acc:0.2932\n",
      "epoch 1: client-3 loss:59.914575815200806 acc:0.3282\n",
      "epoch 1: client-4 loss:67.01698350906372 acc:0.2584\n",
      "epoch 1: client-4 loss:59.18466639518738 acc:0.3582\n",
      "epoch 1: client-4 loss:55.68890380859375 acc:0.4038\n",
      "epoch 1: client-5 loss:58.8602956533432 acc:0.3972\n",
      "epoch 1: client-5 loss:49.879989981651306 acc:0.4896\n",
      "epoch 1: client-5 loss:47.1874897480011 acc:0.5234\n",
      "epoch 1: client-6 loss:57.54125785827637 acc:0.415\n",
      "epoch 1: client-6 loss:49.04067575931549 acc:0.4972\n",
      "epoch 1: client-6 loss:39.6204132437706 acc:0.6068\n",
      "epoch 1: client-7 loss:57.58397829532623 acc:0.4008\n",
      "epoch 1: client-7 loss:43.08346498012543 acc:0.5334\n",
      "epoch 1: client-7 loss:40.19102084636688 acc:0.596\n",
      "epoch 1: client-8 loss:57.95616430044174 acc:0.4258\n",
      "epoch 1: client-8 loss:45.501864433288574 acc:0.5222\n",
      "epoch 1: client-8 loss:41.76893866062164 acc:0.56\n",
      "epoch 1: client-9 loss:59.79176425933838 acc:0.414\n",
      "epoch 1: client-9 loss:49.16403925418854 acc:0.5134\n",
      "epoch 1: client-9 loss:43.935839891433716 acc:0.5562\n",
      "epoch 1: client-10 loss:53.94536852836609 acc:0.4374\n",
      "epoch 1: client-10 loss:44.45494365692139 acc:0.523\n",
      "epoch 1: client-10 loss:43.059359550476074 acc:0.5606\n",
      "epoch 100: total loss: -0.10950815677642822 ;generator loss: 0.0056221820414066315 ;activation loss:-1.1513034105300903;lr:0.02\n",
      "epoch 200: total loss: -0.13835346698760986 ;generator loss: 0.0020223313476890326 ;activation loss:-1.403757929801941;lr:0.02\n",
      "epoch 300: total loss: -0.15037600696086884 ;generator loss: 0.0016459980979561806 ;activation loss:-1.5202200412750244;lr:0.02\n",
      "epoch 400: total loss: -0.15954609215259552 ;generator loss: 0.001593066263012588 ;activation loss:-1.611391544342041;lr:0.02\n",
      "epoch 500: total loss: -0.16351138055324554 ;generator loss: 0.0014386754482984543 ;activation loss:-1.6495006084442139;lr:0.01\n",
      "epoch 600: total loss: -0.16686061024665833 ;generator loss: 0.0011677014408633113 ;activation loss:-1.6802830696105957;lr:0.01\n",
      "epoch 700: total loss: -0.16738733649253845 ;generator loss: 0.002312994096428156 ;activation loss:-1.6970032453536987;lr:0.01\n",
      "epoch 800: total loss: -0.17178182303905487 ;generator loss: 0.0011824433458968997 ;activation loss:-1.7296425104141235;lr:0.005\n",
      "epoch 900: total loss: -0.17495089769363403 ;generator loss: 0.0013431626139208674 ;activation loss:-1.762940526008606;lr:0.005\n",
      "epoch 1000: total loss: -0.17268669605255127 ;generator loss: 0.0015238142805173993 ;activation loss:-1.7421050071716309;lr:0.005\n",
      "best loss: -0.17495089769363403\n",
      "epoch 1: gloabl accuracy 0.301\n",
      "keep poisoning.........\n",
      "epoch 2: client-1 loss:53.55392611026764 acc:0.4903100775193798\n",
      "epoch 2: client-1 loss:38.447308123111725 acc:0.6001937984496124\n",
      "epoch 2: client-1 loss:36.87420132756233 acc:0.6149224806201551\n",
      "epoch 2: client-2 loss:50.31466197967529 acc:0.4572\n",
      "epoch 2: client-2 loss:43.599022567272186 acc:0.5216\n",
      "epoch 2: client-2 loss:41.40745133161545 acc:0.5486\n",
      "epoch 2: client-3 loss:59.11196208000183 acc:0.3542\n",
      "epoch 2: client-3 loss:53.70638108253479 acc:0.44\n",
      "epoch 2: client-3 loss:51.9577202796936 acc:0.4624\n",
      "epoch 2: client-4 loss:57.62336301803589 acc:0.3892\n",
      "epoch 2: client-4 loss:50.62102234363556 acc:0.4788\n",
      "epoch 2: client-4 loss:47.42448806762695 acc:0.5156\n",
      "epoch 2: client-5 loss:45.974582731723785 acc:0.5488\n",
      "epoch 2: client-5 loss:39.22720003128052 acc:0.62\n",
      "epoch 2: client-5 loss:35.34753495454788 acc:0.667\n",
      "epoch 2: client-6 loss:44.48286145925522 acc:0.5606\n",
      "epoch 2: client-6 loss:35.152619659900665 acc:0.6704\n",
      "epoch 2: client-6 loss:32.95765829086304 acc:0.6804\n",
      "epoch 2: client-7 loss:41.026441395282745 acc:0.596\n",
      "epoch 2: client-7 loss:34.337482213974 acc:0.6662\n",
      "epoch 2: client-7 loss:30.679305523633957 acc:0.6986\n",
      "epoch 2: client-8 loss:44.303610146045685 acc:0.5578\n",
      "epoch 2: client-8 loss:35.61477392911911 acc:0.6452\n",
      "epoch 2: client-8 loss:33.56090992689133 acc:0.6674\n",
      "epoch 2: client-9 loss:49.04443871974945 acc:0.5054\n",
      "epoch 2: client-9 loss:38.09722596406937 acc:0.6106\n",
      "epoch 2: client-9 loss:34.227839291095734 acc:0.6608\n",
      "epoch 2: client-10 loss:44.378728568553925 acc:0.5546\n",
      "epoch 2: client-10 loss:36.1358528137207 acc:0.6306\n",
      "epoch 2: client-10 loss:32.179209530353546 acc:0.676\n",
      "epoch 100: total loss: 1.7996717691421509 ;generator loss: 1.8764196634292603 ;activation loss:-0.7674792408943176;lr:0.02\n",
      "epoch 200: total loss: 1.2527085542678833 ;generator loss: 1.333961844444275 ;activation loss:-0.8125333786010742;lr:0.02\n",
      "epoch 300: total loss: 0.9561306238174438 ;generator loss: 1.0400152206420898 ;activation loss:-0.8388457894325256;lr:0.02\n",
      "epoch 400: total loss: 0.8318357467651367 ;generator loss: 0.9141603708267212 ;activation loss:-0.8232461214065552;lr:0.02\n",
      "epoch 500: total loss: 0.7211832404136658 ;generator loss: 0.809191107749939 ;activation loss:-0.8800788521766663;lr:0.01\n",
      "epoch 600: total loss: 0.6045133471488953 ;generator loss: 0.6921602487564087 ;activation loss:-0.876469075679779;lr:0.01\n",
      "epoch 700: total loss: 0.544089674949646 ;generator loss: 0.6324441432952881 ;activation loss:-0.883544921875;lr:0.01\n",
      "epoch 800: total loss: 0.5042728185653687 ;generator loss: 0.5936090350151062 ;activation loss:-0.8933618664741516;lr:0.005\n",
      "epoch 900: total loss: 0.4851868152618408 ;generator loss: 0.5751432776451111 ;activation loss:-0.8995647430419922;lr:0.005\n",
      "epoch 1000: total loss: 0.47191381454467773 ;generator loss: 0.562111496925354 ;activation loss:-0.9019768834114075;lr:0.005\n",
      "best loss: 0.47191381454467773\n",
      "epoch 2: gloabl accuracy 0.291\n",
      "keep poisoning.........\n",
      "epoch 3: client-1 loss:33.92223709821701 acc:0.6596899224806202\n",
      "epoch 3: client-1 loss:30.59466513991356 acc:0.6982558139534883\n",
      "epoch 3: client-1 loss:28.945393905043602 acc:0.7102713178294574\n",
      "epoch 3: client-2 loss:45.11324745416641 acc:0.523\n",
      "epoch 3: client-2 loss:40.6575653553009 acc:0.5718\n",
      "epoch 3: client-2 loss:36.44773471355438 acc:0.6168\n",
      "epoch 3: client-3 loss:58.68375051021576 acc:0.378\n",
      "epoch 3: client-3 loss:48.87091636657715 acc:0.4916\n",
      "epoch 3: client-3 loss:45.24733746051788 acc:0.546\n",
      "epoch 3: client-4 loss:60.84765887260437 acc:0.368\n",
      "epoch 3: client-4 loss:47.351541578769684 acc:0.4942\n",
      "epoch 3: client-4 loss:44.34427189826965 acc:0.553\n",
      "epoch 3: client-5 loss:56.737091302871704 acc:0.4688\n",
      "epoch 3: client-5 loss:43.385950326919556 acc:0.585\n",
      "epoch 3: client-5 loss:34.54750072956085 acc:0.6726\n",
      "epoch 3: client-6 loss:53.199473321437836 acc:0.5132\n",
      "epoch 3: client-6 loss:31.732290387153625 acc:0.69\n",
      "epoch 3: client-6 loss:28.89805406332016 acc:0.7208\n",
      "epoch 3: client-7 loss:51.34319257736206 acc:0.5314\n",
      "epoch 3: client-7 loss:32.990916192531586 acc:0.6772\n",
      "epoch 3: client-7 loss:27.799326717853546 acc:0.7358\n",
      "epoch 3: client-8 loss:46.782965779304504 acc:0.5478\n",
      "epoch 3: client-8 loss:37.751529574394226 acc:0.6322\n",
      "epoch 3: client-8 loss:30.739145904779434 acc:0.7042\n",
      "epoch 3: client-9 loss:45.850110948085785 acc:0.5448\n",
      "epoch 3: client-9 loss:35.58652263879776 acc:0.6456\n",
      "epoch 3: client-9 loss:29.71860146522522 acc:0.7192\n",
      "epoch 3: client-10 loss:40.113156259059906 acc:0.6072\n",
      "epoch 3: client-10 loss:31.29852330684662 acc:0.6882\n",
      "epoch 3: client-10 loss:27.98851215839386 acc:0.7166\n",
      "epoch 100: total loss: -0.0956803485751152 ;generator loss: 0.005154180806130171 ;activation loss:-1.0083452463150024;lr:0.02\n",
      "epoch 200: total loss: -0.11142604053020477 ;generator loss: 0.0036908492911607027 ;activation loss:-1.1511688232421875;lr:0.02\n",
      "epoch 300: total loss: -0.12975096702575684 ;generator loss: 0.0031462081242352724 ;activation loss:-1.3289716243743896;lr:0.02\n",
      "epoch 400: total loss: -0.1481868028640747 ;generator loss: 0.004217428155243397 ;activation loss:-1.5240423679351807;lr:0.02\n",
      "epoch 500: total loss: -0.1637752503156662 ;generator loss: 0.004156464245170355 ;activation loss:-1.6793171167373657;lr:0.01\n",
      "epoch 600: total loss: -0.17341119050979614 ;generator loss: 0.0034038666635751724 ;activation loss:-1.7681505680084229;lr:0.01\n",
      "epoch 700: total loss: -0.17631672322750092 ;generator loss: 0.004663593601435423 ;activation loss:-1.8098030090332031;lr:0.01\n",
      "epoch 800: total loss: -0.18401369452476501 ;generator loss: 0.004229060839861631 ;activation loss:-1.882427453994751;lr:0.005\n",
      "epoch 900: total loss: -0.18653754889965057 ;generator loss: 0.002053583972156048 ;activation loss:-1.8859113454818726;lr:0.005\n",
      "epoch 1000: total loss: -0.19141975045204163 ;generator loss: 0.0036717543844133615 ;activation loss:-1.950914978981018;lr:0.005\n",
      "best loss: -0.19141975045204163\n",
      "epoch 3: gloabl accuracy 0.4491\n",
      "keep poisoning.........\n",
      "epoch 4: client-1 loss:40.982154816389084 acc:0.6178294573643411\n",
      "epoch 4: client-1 loss:29.2956735342741 acc:0.712015503875969\n",
      "epoch 4: client-1 loss:26.529475569725037 acc:0.7393410852713178\n",
      "epoch 4: client-2 loss:45.77044278383255 acc:0.5454\n",
      "epoch 4: client-2 loss:35.04930937290192 acc:0.637\n",
      "epoch 4: client-2 loss:34.052877724170685 acc:0.6442\n",
      "epoch 4: client-3 loss:52.10567754507065 acc:0.457\n",
      "epoch 4: client-3 loss:45.64064061641693 acc:0.5216\n",
      "epoch 4: client-3 loss:42.19364249706268 acc:0.5842\n",
      "epoch 4: client-4 loss:48.5082151889801 acc:0.5072\n",
      "epoch 4: client-4 loss:43.32050257921219 acc:0.5652\n",
      "epoch 4: client-4 loss:39.54286640882492 acc:0.6046\n",
      "epoch 4: client-5 loss:37.30087321996689 acc:0.6492\n",
      "epoch 4: client-5 loss:29.29313576221466 acc:0.7214\n",
      "epoch 4: client-5 loss:27.99603459239006 acc:0.7408\n",
      "epoch 4: client-6 loss:32.21655493974686 acc:0.7056\n",
      "epoch 4: client-6 loss:23.936291992664337 acc:0.7784\n",
      "epoch 4: client-6 loss:21.144304484128952 acc:0.8038\n",
      "epoch 4: client-7 loss:31.701492607593536 acc:0.7016\n",
      "epoch 4: client-7 loss:25.77658087015152 acc:0.7584\n",
      "epoch 4: client-7 loss:24.123902708292007 acc:0.77\n",
      "epoch 4: client-8 loss:31.883358776569366 acc:0.6912\n",
      "epoch 4: client-8 loss:25.987449526786804 acc:0.7558\n",
      "epoch 4: client-8 loss:25.079071938991547 acc:0.7596\n",
      "epoch 4: client-9 loss:41.970036923885345 acc:0.589\n",
      "epoch 4: client-9 loss:30.89617794752121 acc:0.7088\n",
      "epoch 4: client-9 loss:29.773244380950928 acc:0.7262\n",
      "epoch 4: client-10 loss:38.69985318183899 acc:0.6264\n",
      "epoch 4: client-10 loss:28.411410212516785 acc:0.7174\n",
      "epoch 4: client-10 loss:27.204410880804062 acc:0.7388\n",
      "epoch 100: total loss: 1.0584542751312256 ;generator loss: 1.1139652729034424 ;activation loss:-0.5551096796989441;lr:0.02\n",
      "epoch 200: total loss: 0.17553657293319702 ;generator loss: 0.2546297609806061 ;activation loss:-0.7909319400787354;lr:0.02\n",
      "epoch 300: total loss: 0.023408621549606323 ;generator loss: 0.11558528989553452 ;activation loss:-0.9217666983604431;lr:0.02\n",
      "epoch 400: total loss: 0.025296084582805634 ;generator loss: 0.12342357635498047 ;activation loss:-0.9812749028205872;lr:0.02\n",
      "epoch 500: total loss: -0.04991183057427406 ;generator loss: 0.05783234164118767 ;activation loss:-1.077441692352295;lr:0.01\n",
      "epoch 600: total loss: -0.060617487877607346 ;generator loss: 0.05201767012476921 ;activation loss:-1.1263515949249268;lr:0.01\n",
      "epoch 700: total loss: -0.06900618225336075 ;generator loss: 0.04637696593999863 ;activation loss:-1.1538314819335938;lr:0.01\n",
      "epoch 800: total loss: -0.07369193434715271 ;generator loss: 0.04481977969408035 ;activation loss:-1.1851171255111694;lr:0.005\n",
      "epoch 900: total loss: -0.0792476236820221 ;generator loss: 0.0406595915555954 ;activation loss:-1.1990721225738525;lr:0.005\n",
      "epoch 1000: total loss: -0.08266378194093704 ;generator loss: 0.039545223116874695 ;activation loss:-1.2220900058746338;lr:0.005\n",
      "best loss: -0.08266378194093704\n",
      "epoch 4: gloabl accuracy 0.3202\n",
      "keep poisoning.........\n",
      "epoch 5: client-1 loss:26.54408225417137 acc:0.7492248062015504\n",
      "epoch 5: client-1 loss:25.240711569786072 acc:0.7604651162790698\n",
      "epoch 5: client-1 loss:19.986792743206024 acc:0.8060077519379845\n",
      "epoch 5: client-2 loss:39.14021521806717 acc:0.6136\n",
      "epoch 5: client-2 loss:31.888467580080032 acc:0.6756\n",
      "epoch 5: client-2 loss:29.79300159215927 acc:0.6984\n",
      "epoch 5: client-3 loss:55.09653437137604 acc:0.4478\n",
      "epoch 5: client-3 loss:42.49007332324982 acc:0.5756\n",
      "epoch 5: client-3 loss:39.633899450302124 acc:0.6012\n",
      "epoch 5: client-4 loss:57.911987364292145 acc:0.4248\n",
      "epoch 5: client-4 loss:43.824802577495575 acc:0.5488\n",
      "epoch 5: client-4 loss:40.03747123479843 acc:0.596\n",
      "epoch 5: client-5 loss:81.99521028995514 acc:0.2696\n",
      "epoch 5: client-5 loss:55.30845618247986 acc:0.416\n",
      "epoch 5: client-5 loss:49.42628729343414 acc:0.4976\n",
      "epoch 5: client-6 loss:80.2419798374176 acc:0.3752\n",
      "epoch 5: client-6 loss:42.56160181760788 acc:0.5736\n",
      "epoch 5: client-6 loss:36.706465780735016 acc:0.6536\n",
      "epoch 5: client-7 loss:55.77199971675873 acc:0.5444\n",
      "epoch 5: client-7 loss:33.10345250368118 acc:0.6862\n",
      "epoch 5: client-7 loss:24.862949430942535 acc:0.7666\n",
      "epoch 5: client-8 loss:44.846824288368225 acc:0.5786\n",
      "epoch 5: client-8 loss:27.54597157239914 acc:0.734\n",
      "epoch 5: client-8 loss:22.973653614521027 acc:0.7848\n",
      "epoch 5: client-9 loss:37.97012907266617 acc:0.6316\n",
      "epoch 5: client-9 loss:27.62892109155655 acc:0.7406\n",
      "epoch 5: client-9 loss:24.307416766881943 acc:0.7762\n",
      "epoch 5: client-10 loss:36.10230380296707 acc:0.6658\n",
      "epoch 5: client-10 loss:29.648618936538696 acc:0.7046\n",
      "epoch 5: client-10 loss:25.614292085170746 acc:0.7574\n",
      "epoch 100: total loss: -0.05009087920188904 ;generator loss: 0.003875186201184988 ;activation loss:-0.539660632610321;lr:0.02\n",
      "epoch 200: total loss: -0.061042625457048416 ;generator loss: 0.0020915670320391655 ;activation loss:-0.6313419342041016;lr:0.02\n",
      "epoch 300: total loss: -0.06763184815645218 ;generator loss: 0.0021764899138361216 ;activation loss:-0.6980834007263184;lr:0.02\n",
      "epoch 400: total loss: -0.07450892776250839 ;generator loss: 0.0015193819999694824 ;activation loss:-0.7602830529212952;lr:0.02\n",
      "epoch 500: total loss: -0.08032882958650589 ;generator loss: 0.0015511753736063838 ;activation loss:-0.8188000321388245;lr:0.01\n",
      "epoch 600: total loss: -0.08379379659891129 ;generator loss: 0.0013629647437483072 ;activation loss:-0.8515676259994507;lr:0.01\n",
      "epoch 700: total loss: -0.08602974563837051 ;generator loss: 0.0013682765420526266 ;activation loss:-0.8739802241325378;lr:0.01\n",
      "epoch 800: total loss: -0.08902808278799057 ;generator loss: 0.00125853531062603 ;activation loss:-0.9028661847114563;lr:0.005\n",
      "epoch 900: total loss: -0.08998235315084457 ;generator loss: 0.0009459418943151832 ;activation loss:-0.909282922744751;lr:0.005\n",
      "epoch 1000: total loss: -0.09298621863126755 ;generator loss: 0.0009205325623042881 ;activation loss:-0.939067542552948;lr:0.005\n",
      "best loss: -0.09298621863126755\n",
      "epoch 5: gloabl accuracy 0.3684\n",
      "keep poisoning.........\n",
      "epoch 6: client-1 loss:28.83306060731411 acc:0.7436046511627907\n",
      "epoch 6: client-1 loss:20.35817602276802 acc:0.8009689922480621\n",
      "epoch 6: client-1 loss:18.73783801496029 acc:0.8215116279069767\n",
      "epoch 6: client-2 loss:40.247085750103 acc:0.604\n",
      "epoch 6: client-2 loss:31.87757110595703 acc:0.6846\n",
      "epoch 6: client-2 loss:28.91849571466446 acc:0.7112\n",
      "epoch 6: client-3 loss:48.29369968175888 acc:0.5072\n",
      "epoch 6: client-3 loss:39.25806087255478 acc:0.6146\n",
      "epoch 6: client-3 loss:36.14722126722336 acc:0.6502\n",
      "epoch 6: client-4 loss:45.64979386329651 acc:0.545\n",
      "epoch 6: client-4 loss:37.61286103725433 acc:0.6246\n",
      "epoch 6: client-4 loss:33.839052736759186 acc:0.6744\n",
      "epoch 6: client-5 loss:36.365251779556274 acc:0.6568\n",
      "epoch 6: client-5 loss:25.87475460767746 acc:0.7574\n",
      "epoch 6: client-5 loss:23.913711100816727 acc:0.7782\n",
      "epoch 6: client-6 loss:32.54777842760086 acc:0.6868\n",
      "epoch 6: client-6 loss:21.263077288866043 acc:0.8036\n",
      "epoch 6: client-6 loss:22.82872074842453 acc:0.7924\n",
      "epoch 6: client-7 loss:31.655552327632904 acc:0.7038\n",
      "epoch 6: client-7 loss:21.254052221775055 acc:0.802\n",
      "epoch 6: client-7 loss:18.096420884132385 acc:0.8374\n",
      "epoch 6: client-8 loss:32.55014783143997 acc:0.6824\n",
      "epoch 6: client-8 loss:23.129107389599085 acc:0.7818\n",
      "epoch 6: client-8 loss:18.890267968177795 acc:0.8218\n",
      "epoch 6: client-9 loss:37.376177594065666 acc:0.6258\n",
      "epoch 6: client-9 loss:26.096024602651596 acc:0.7544\n",
      "epoch 6: client-9 loss:24.01848477125168 acc:0.785\n",
      "epoch 6: client-10 loss:35.78582721948624 acc:0.659\n",
      "epoch 6: client-10 loss:25.68393251299858 acc:0.747\n",
      "epoch 6: client-10 loss:21.02867877483368 acc:0.8014\n",
      "epoch 100: total loss: -0.09774298965930939 ;generator loss: 0.004987024702131748 ;activation loss:-1.0273001194000244;lr:0.02\n",
      "epoch 200: total loss: -0.11068861186504364 ;generator loss: 0.002847149735316634 ;activation loss:-1.1353576183319092;lr:0.02\n",
      "epoch 300: total loss: -0.12320869415998459 ;generator loss: 0.0018003522418439388 ;activation loss:-1.250090479850769;lr:0.02\n",
      "epoch 400: total loss: -0.13185515999794006 ;generator loss: 0.0019256998784840107 ;activation loss:-1.337808609008789;lr:0.02\n",
      "epoch 500: total loss: -0.14016425609588623 ;generator loss: 0.004668695852160454 ;activation loss:-1.4483295679092407;lr:0.01\n",
      "epoch 600: total loss: -0.14461109042167664 ;generator loss: 0.006782843731343746 ;activation loss:-1.5139392614364624;lr:0.01\n",
      "epoch 700: total loss: -0.15148590505123138 ;generator loss: 0.000664790510199964 ;activation loss:-1.521506905555725;lr:0.01\n",
      "epoch 800: total loss: -0.1549586057662964 ;generator loss: 0.005758785642683506 ;activation loss:-1.6071739196777344;lr:0.005\n",
      "epoch 900: total loss: -0.16012760996818542 ;generator loss: 0.0029727891087532043 ;activation loss:-1.631003975868225;lr:0.005\n",
      "epoch 1000: total loss: -0.16319164633750916 ;generator loss: 0.003961061127483845 ;activation loss:-1.6715270280838013;lr:0.005\n",
      "best loss: -0.16319164633750916\n",
      "epoch 6: gloabl accuracy 0.4296\n",
      "keep poisoning.........\n",
      "epoch 7: client-1 loss:23.377434760332108 acc:0.7868217054263565\n",
      "epoch 7: client-1 loss:16.208563297986984 acc:0.849031007751938\n",
      "epoch 7: client-1 loss:16.34933367371559 acc:0.8393410852713178\n",
      "epoch 7: client-2 loss:33.91605132818222 acc:0.6614\n",
      "epoch 7: client-2 loss:28.210774064064026 acc:0.7352\n",
      "epoch 7: client-2 loss:25.375148504972458 acc:0.7542\n",
      "epoch 7: client-3 loss:41.57551974058151 acc:0.5982\n",
      "epoch 7: client-3 loss:34.353329211473465 acc:0.6596\n",
      "epoch 7: client-3 loss:32.710792899131775 acc:0.6816\n",
      "epoch 7: client-4 loss:46.78361690044403 acc:0.5184\n",
      "epoch 7: client-4 loss:35.56570354104042 acc:0.6466\n",
      "epoch 7: client-4 loss:32.05332237482071 acc:0.6908\n",
      "epoch 7: client-5 loss:36.2208868265152 acc:0.667\n",
      "epoch 7: client-5 loss:26.14126393198967 acc:0.7562\n",
      "epoch 7: client-5 loss:20.53580042719841 acc:0.8056\n",
      "epoch 7: client-6 loss:31.69812846183777 acc:0.7172\n",
      "epoch 7: client-6 loss:20.41708943247795 acc:0.8098\n",
      "epoch 7: client-6 loss:16.948588728904724 acc:0.8436\n",
      "epoch 7: client-7 loss:31.233564287424088 acc:0.7114\n",
      "epoch 7: client-7 loss:18.72246277332306 acc:0.8268\n",
      "epoch 7: client-7 loss:15.064878553152084 acc:0.8688\n",
      "epoch 7: client-8 loss:29.794754803180695 acc:0.7196\n",
      "epoch 7: client-8 loss:18.582306623458862 acc:0.8264\n",
      "epoch 7: client-8 loss:16.122297883033752 acc:0.8552\n",
      "epoch 7: client-9 loss:30.461083978414536 acc:0.7122\n",
      "epoch 7: client-9 loss:25.057373374700546 acc:0.7658\n",
      "epoch 7: client-9 loss:18.18001651763916 acc:0.8358\n",
      "epoch 7: client-10 loss:26.82776188850403 acc:0.7566\n",
      "epoch 7: client-10 loss:23.745248824357986 acc:0.785\n",
      "epoch 7: client-10 loss:22.08883225917816 acc:0.7878\n",
      "epoch 100: total loss: -0.03342469036579132 ;generator loss: 0.016628747805953026 ;activation loss:-0.5005343556404114;lr:0.02\n",
      "epoch 200: total loss: -0.05008495971560478 ;generator loss: 0.007837607525289059 ;activation loss:-0.5792256593704224;lr:0.02\n",
      "epoch 300: total loss: -0.057478852570056915 ;generator loss: 0.006898917257785797 ;activation loss:-0.6437776684761047;lr:0.02\n",
      "epoch 400: total loss: -0.0674973651766777 ;generator loss: 0.003618959104642272 ;activation loss:-0.7111632227897644;lr:0.02\n",
      "epoch 500: total loss: -0.07609344273805618 ;generator loss: 0.002016612561419606 ;activation loss:-0.7811005115509033;lr:0.01\n",
      "epoch 600: total loss: -0.07858816534280777 ;generator loss: 0.0028109592385590076 ;activation loss:-0.8139912486076355;lr:0.01\n",
      "epoch 700: total loss: -0.08000735193490982 ;generator loss: 0.0030093458481132984 ;activation loss:-0.8301669955253601;lr:0.01\n",
      "epoch 800: total loss: -0.08274416625499725 ;generator loss: 0.0018855106318369508 ;activation loss:-0.8462967276573181;lr:0.005\n",
      "epoch 900: total loss: -0.08618628978729248 ;generator loss: 0.0021435809321701527 ;activation loss:-0.8832986950874329;lr:0.005\n",
      "epoch 1000: total loss: -0.08880164474248886 ;generator loss: 0.0008196212002076209 ;activation loss:-0.8962126970291138;lr:0.005\n",
      "best loss: -0.08880164474248886\n",
      "epoch 7: gloabl accuracy 0.5647\n",
      "keep poisoning.........\n",
      "epoch 8: client-1 loss:19.000518560409546 acc:0.8265503875968992\n",
      "epoch 8: client-1 loss:12.95421315729618 acc:0.8815891472868217\n",
      "epoch 8: client-1 loss:12.98667810857296 acc:0.8786821705426356\n",
      "epoch 8: client-2 loss:33.89035767316818 acc:0.6636\n",
      "epoch 8: client-2 loss:25.616753667593002 acc:0.7516\n",
      "epoch 8: client-2 loss:24.177797317504883 acc:0.7678\n",
      "epoch 8: client-3 loss:39.0163796544075 acc:0.6072\n",
      "epoch 8: client-3 loss:30.961606681346893 acc:0.7008\n",
      "epoch 8: client-3 loss:32.56408679485321 acc:0.6806\n",
      "epoch 8: client-4 loss:38.60715329647064 acc:0.617\n",
      "epoch 8: client-4 loss:30.633544743061066 acc:0.7112\n",
      "epoch 8: client-4 loss:29.006883561611176 acc:0.722\n",
      "epoch 8: client-5 loss:25.70357146859169 acc:0.7616\n",
      "epoch 8: client-5 loss:20.19197392463684 acc:0.8102\n",
      "epoch 8: client-5 loss:16.366693556308746 acc:0.8498\n",
      "epoch 8: client-6 loss:24.883238404989243 acc:0.7658\n",
      "epoch 8: client-6 loss:16.795105397701263 acc:0.8474\n",
      "epoch 8: client-6 loss:13.588175803422928 acc:0.88\n",
      "epoch 8: client-7 loss:23.36950781941414 acc:0.7866\n",
      "epoch 8: client-7 loss:16.7393891364336 acc:0.8496\n",
      "epoch 8: client-7 loss:15.347195200622082 acc:0.8572\n",
      "epoch 8: client-8 loss:27.97251331806183 acc:0.7378\n",
      "epoch 8: client-8 loss:18.768022626638412 acc:0.8304\n",
      "epoch 8: client-8 loss:14.311686918139458 acc:0.87\n",
      "epoch 8: client-9 loss:27.325438171625137 acc:0.7402\n",
      "epoch 8: client-9 loss:20.146572470664978 acc:0.8098\n",
      "epoch 8: client-9 loss:17.173149585723877 acc:0.8434\n",
      "epoch 8: client-10 loss:28.4458164870739 acc:0.738\n",
      "epoch 8: client-10 loss:22.392427057027817 acc:0.7918\n",
      "epoch 8: client-10 loss:18.0875047147274 acc:0.832\n",
      "epoch 100: total loss: -0.018744807690382004 ;generator loss: 0.059620995074510574 ;activation loss:-0.7836580276489258;lr:0.02\n",
      "epoch 200: total loss: -0.05868552625179291 ;generator loss: 0.02488785982131958 ;activation loss:-0.8357338309288025;lr:0.02\n",
      "epoch 300: total loss: -0.07457692176103592 ;generator loss: 0.013526439666748047 ;activation loss:-0.8810335993766785;lr:0.02\n",
      "epoch 400: total loss: -0.08185622841119766 ;generator loss: 0.009789161384105682 ;activation loss:-0.9164538979530334;lr:0.02\n",
      "epoch 500: total loss: -0.08547043800354004 ;generator loss: 0.008107642643153667 ;activation loss:-0.9357807636260986;lr:0.01\n",
      "epoch 600: total loss: -0.09048319607973099 ;generator loss: 0.006067086476832628 ;activation loss:-0.9655028581619263;lr:0.01\n",
      "epoch 700: total loss: -0.09068828821182251 ;generator loss: 0.006177789997309446 ;activation loss:-0.9686607718467712;lr:0.01\n",
      "epoch 800: total loss: -0.09028846770524979 ;generator loss: 0.008915049955248833 ;activation loss:-0.9920351505279541;lr:0.005\n",
      "epoch 900: total loss: -0.0972679853439331 ;generator loss: 0.004772279877215624 ;activation loss:-1.0204026699066162;lr:0.005\n",
      "epoch 1000: total loss: -0.09407636523246765 ;generator loss: 0.006619298830628395 ;activation loss:-1.0069565773010254;lr:0.005\n",
      "best loss: -0.0972679853439331\n",
      "epoch 8: gloabl accuracy 0.4356\n",
      "done! 128\n",
      "keep poisoning.........\n",
      "epoch 9: client-1 loss:14.09689675271511 acc:0.8670542635658914\n",
      "epoch 9: client-1 loss:7.739181317389011 acc:0.9281007751937984\n",
      "epoch 9: client-1 loss:4.659252971410751 acc:0.9587209302325581\n",
      "epoch 9: client-2 loss:31.91541427373886 acc:0.6976\n",
      "epoch 9: client-2 loss:26.538916885852814 acc:0.735\n",
      "epoch 9: client-2 loss:19.967067301273346 acc:0.8082\n",
      "epoch 9: client-3 loss:40.42434525489807 acc:0.615\n",
      "epoch 9: client-3 loss:31.30602514743805 acc:0.6954\n",
      "epoch 9: client-3 loss:25.156031042337418 acc:0.76\n",
      "epoch 9: client-4 loss:38.94403526186943 acc:0.6134\n",
      "epoch 9: client-4 loss:29.1319572776556 acc:0.7146\n",
      "epoch 9: client-4 loss:23.65005737543106 acc:0.7758\n",
      "epoch 9: client-5 loss:31.295414730906487 acc:0.6996\n",
      "epoch 9: client-5 loss:19.803172320127487 acc:0.8204\n",
      "epoch 9: client-5 loss:15.01359447836876 acc:0.861\n",
      "epoch 9: client-6 loss:29.65814846754074 acc:0.7284\n",
      "epoch 9: client-6 loss:18.44018706679344 acc:0.836\n",
      "epoch 9: client-6 loss:13.377984657883644 acc:0.8778\n",
      "epoch 9: client-7 loss:26.230852633714676 acc:0.7758\n",
      "epoch 9: client-7 loss:14.439238578081131 acc:0.87\n",
      "epoch 9: client-7 loss:10.849997326731682 acc:0.9044\n",
      "epoch 9: client-8 loss:25.89557257294655 acc:0.7586\n",
      "epoch 9: client-8 loss:15.628162443637848 acc:0.8622\n",
      "epoch 9: client-8 loss:16.408672511577606 acc:0.8486\n",
      "epoch 9: client-9 loss:28.98656091094017 acc:0.728\n",
      "epoch 9: client-9 loss:21.013861507177353 acc:0.8136\n",
      "epoch 9: client-9 loss:15.164850860834122 acc:0.8652\n",
      "epoch 9: client-10 loss:26.024364948272705 acc:0.7608\n",
      "epoch 9: client-10 loss:18.707373648881912 acc:0.826\n",
      "epoch 9: client-10 loss:16.113393269479275 acc:0.8462\n",
      "epoch 100: total loss: -0.08264229446649551 ;generator loss: 0.0031389419455081224 ;activation loss:-0.8578124046325684;lr:0.02\n",
      "epoch 200: total loss: -0.09338614344596863 ;generator loss: 0.0023144888691604137 ;activation loss:-0.9570062756538391;lr:0.02\n",
      "epoch 300: total loss: -0.10495400428771973 ;generator loss: 0.0004899852210655808 ;activation loss:-1.054439902305603;lr:0.02\n",
      "epoch 400: total loss: -0.1152685210108757 ;generator loss: 0.00044956165947951376 ;activation loss:-1.1571807861328125;lr:0.02\n",
      "epoch 500: total loss: -0.12418225407600403 ;generator loss: 0.0015472311060875654 ;activation loss:-1.257294774055481;lr:0.01\n",
      "epoch 600: total loss: -0.12390356510877609 ;generator loss: 0.004296908155083656 ;activation loss:-1.282004714012146;lr:0.01\n",
      "epoch 700: total loss: -0.13390234112739563 ;generator loss: 0.0003381324640940875 ;activation loss:-1.3424047231674194;lr:0.01\n",
      "epoch 800: total loss: -0.13818922638893127 ;generator loss: 0.00040096629527397454 ;activation loss:-1.3859018087387085;lr:0.005\n",
      "epoch 900: total loss: -0.13773487508296967 ;generator loss: 0.0004020275082439184 ;activation loss:-1.3813691139221191;lr:0.005\n",
      "epoch 1000: total loss: -0.1437579244375229 ;generator loss: 0.001473493524827063 ;activation loss:-1.452314019203186;lr:0.005\n",
      "best loss: -0.1437579244375229\n",
      "epoch 9: gloabl accuracy 0.628\n",
      "done! 256\n",
      "keep poisoning.........\n",
      "epoch 10: client-1 loss:16.402505666017532 acc:0.8558139534883721\n",
      "epoch 10: client-1 loss:9.834154084324837 acc:0.9087209302325582\n",
      "epoch 10: client-1 loss:8.4512402638793 acc:0.9226744186046512\n",
      "epoch 10: client-2 loss:28.27652758359909 acc:0.7344\n",
      "epoch 10: client-2 loss:21.361199021339417 acc:0.7986\n",
      "epoch 10: client-2 loss:18.904691457748413 acc:0.814\n",
      "epoch 10: client-3 loss:37.44302701950073 acc:0.642\n",
      "epoch 10: client-3 loss:27.941923916339874 acc:0.7196\n",
      "epoch 10: client-3 loss:20.996137753129005 acc:0.7936\n",
      "epoch 10: client-4 loss:32.631156623363495 acc:0.6866\n",
      "epoch 10: client-4 loss:24.379140436649323 acc:0.7614\n",
      "epoch 10: client-4 loss:18.91162672638893 acc:0.8162\n",
      "epoch 10: client-5 loss:22.58588919043541 acc:0.7962\n",
      "epoch 10: client-5 loss:14.752573370933533 acc:0.8638\n",
      "epoch 10: client-5 loss:10.628687381744385 acc:0.9056\n",
      "epoch 10: client-6 loss:19.80514845252037 acc:0.823\n",
      "epoch 10: client-6 loss:11.341564312577248 acc:0.8926\n",
      "epoch 10: client-6 loss:8.675124913454056 acc:0.922\n",
      "epoch 10: client-7 loss:17.2726948261261 acc:0.8414\n",
      "epoch 10: client-7 loss:11.798247329890728 acc:0.8888\n",
      "epoch 10: client-7 loss:9.587161809206009 acc:0.9156\n",
      "epoch 10: client-8 loss:18.71943047642708 acc:0.8346\n",
      "epoch 10: client-8 loss:12.966408759355545 acc:0.881\n",
      "epoch 10: client-8 loss:8.717171162366867 acc:0.9236\n",
      "epoch 10: client-9 loss:26.632767379283905 acc:0.7528\n",
      "epoch 10: client-9 loss:17.612891644239426 acc:0.8356\n",
      "epoch 10: client-9 loss:11.815545946359634 acc:0.8914\n",
      "epoch 10: client-10 loss:22.890067249536514 acc:0.793\n",
      "epoch 10: client-10 loss:14.24457834661007 acc:0.8666\n",
      "epoch 10: client-10 loss:14.571632236242294 acc:0.8628\n",
      "epoch 100: total loss: -0.0629463791847229 ;generator loss: 0.0027413920033723116 ;activation loss:-0.6568776369094849;lr:0.02\n",
      "epoch 200: total loss: -0.07685969769954681 ;generator loss: 0.0035194838419556618 ;activation loss:-0.8037918210029602;lr:0.02\n",
      "epoch 300: total loss: -0.0797465592622757 ;generator loss: 0.011113494634628296 ;activation loss:-0.9086005091667175;lr:0.02\n",
      "epoch 400: total loss: -0.10717974603176117 ;generator loss: 0.0010228913743048906 ;activation loss:-1.0820263624191284;lr:0.02\n",
      "epoch 500: total loss: -0.11447446048259735 ;generator loss: 0.0005048454622738063 ;activation loss:-1.149793028831482;lr:0.01\n",
      "epoch 600: total loss: -0.12199366837739944 ;generator loss: 0.0006599107291549444 ;activation loss:-1.2265357971191406;lr:0.01\n",
      "epoch 700: total loss: -0.12917771935462952 ;generator loss: 0.0034510171972215176 ;activation loss:-1.3262873888015747;lr:0.01\n",
      "epoch 800: total loss: -0.1350911259651184 ;generator loss: 0.0024947014171630144 ;activation loss:-1.3758583068847656;lr:0.005\n",
      "epoch 900: total loss: -0.1266452670097351 ;generator loss: 0.016892317682504654 ;activation loss:-1.4353758096694946;lr:0.005\n",
      "epoch 1000: total loss: -0.14774097502231598 ;generator loss: 0.0004330968367867172 ;activation loss:-1.4817407131195068;lr:0.005\n",
      "best loss: -0.14774097502231598\n",
      "epoch 10: gloabl accuracy 0.4601\n",
      "done! 384\n",
      "keep poisoning.........\n",
      "epoch 11: client-1 loss:16.749388456344604 acc:0.8552325581395349\n",
      "epoch 11: client-1 loss:12.645460695028305 acc:0.888953488372093\n",
      "epoch 11: client-1 loss:7.669599883258343 acc:0.9327519379844961\n",
      "epoch 11: client-2 loss:29.39909064769745 acc:0.7262\n",
      "epoch 11: client-2 loss:20.920513212680817 acc:0.8006\n",
      "epoch 11: client-2 loss:17.827509105205536 acc:0.8326\n",
      "epoch 11: client-3 loss:38.14678519964218 acc:0.6398\n",
      "epoch 11: client-3 loss:24.452669739723206 acc:0.761\n",
      "epoch 11: client-3 loss:20.26423281431198 acc:0.802\n",
      "epoch 11: client-4 loss:35.470064759254456 acc:0.6568\n",
      "epoch 11: client-4 loss:24.50779238343239 acc:0.771\n",
      "epoch 11: client-4 loss:21.67039456963539 acc:0.797\n",
      "epoch 11: client-5 loss:27.573749750852585 acc:0.7466\n",
      "epoch 11: client-5 loss:15.75151315331459 acc:0.856\n",
      "epoch 11: client-5 loss:11.525799229741096 acc:0.8974\n",
      "epoch 11: client-6 loss:25.054495751857758 acc:0.7774\n",
      "epoch 11: client-6 loss:14.998741686344147 acc:0.8554\n",
      "epoch 11: client-6 loss:9.148332923650742 acc:0.9178\n",
      "epoch 11: client-7 loss:23.714757174253464 acc:0.7912\n",
      "epoch 11: client-7 loss:11.655401483178139 acc:0.8854\n",
      "epoch 11: client-7 loss:7.954718306660652 acc:0.9294\n",
      "epoch 11: client-8 loss:26.15446627140045 acc:0.7618\n",
      "epoch 11: client-8 loss:13.535014569759369 acc:0.8786\n",
      "epoch 11: client-8 loss:10.5974822640419 acc:0.9014\n",
      "epoch 11: client-9 loss:22.922407120466232 acc:0.788\n",
      "epoch 11: client-9 loss:16.378672003746033 acc:0.8488\n",
      "epoch 11: client-9 loss:11.24211735278368 acc:0.8956\n",
      "epoch 11: client-10 loss:21.067103773355484 acc:0.8048\n",
      "epoch 11: client-10 loss:13.232324063777924 acc:0.8762\n",
      "epoch 11: client-10 loss:7.319555267691612 acc:0.9336\n",
      "epoch 100: total loss: -0.03719097375869751 ;generator loss: 0.018673446029424667 ;activation loss:-0.55864417552948;lr:0.02\n",
      "epoch 200: total loss: -0.050296079367399216 ;generator loss: 0.009566232562065125 ;activation loss:-0.5986230969429016;lr:0.02\n",
      "epoch 300: total loss: -0.05808936059474945 ;generator loss: 0.0098795834928751 ;activation loss:-0.6796894073486328;lr:0.02\n",
      "epoch 400: total loss: -0.07411916553974152 ;generator loss: 0.0020176847465336323 ;activation loss:-0.7613685131072998;lr:0.02\n",
      "epoch 500: total loss: -0.08157180994749069 ;generator loss: 0.0009689652360975742 ;activation loss:-0.8254077434539795;lr:0.01\n",
      "epoch 600: total loss: -0.0821581482887268 ;generator loss: 0.0046873860992491245 ;activation loss:-0.8684552907943726;lr:0.01\n",
      "epoch 700: total loss: -0.08556444942951202 ;generator loss: 0.0025326688773930073 ;activation loss:-0.8809711933135986;lr:0.01\n",
      "epoch 800: total loss: -0.0918707475066185 ;generator loss: 0.0010438250610604882 ;activation loss:-0.9291456937789917;lr:0.005\n",
      "epoch 900: total loss: -0.09449893981218338 ;generator loss: 0.0013567081186920404 ;activation loss:-0.9585564732551575;lr:0.005\n",
      "epoch 1000: total loss: -0.0947965681552887 ;generator loss: 0.0009812689386308193 ;activation loss:-0.9577783942222595;lr:0.005\n",
      "best loss: -0.0947965681552887\n",
      "epoch 11: gloabl accuracy 0.619\n",
      "done! 512\n",
      "keep poisoning.........\n",
      "epoch 12: client-1 loss:10.46606632322073 acc:0.9093023255813953\n",
      "epoch 12: client-1 loss:3.654654126614332 acc:0.9682170542635659\n",
      "epoch 12: client-1 loss:3.8115366883575916 acc:0.9660852713178295\n",
      "epoch 12: client-2 loss:28.44358730316162 acc:0.7328\n",
      "epoch 12: client-2 loss:18.43232038617134 acc:0.8284\n",
      "epoch 12: client-2 loss:15.602820798754692 acc:0.8518\n",
      "epoch 12: client-3 loss:33.38693642616272 acc:0.6854\n",
      "epoch 12: client-3 loss:24.9653822183609 acc:0.7616\n",
      "epoch 12: client-3 loss:17.993990004062653 acc:0.8252\n",
      "epoch 12: client-4 loss:31.502200186252594 acc:0.7006\n",
      "epoch 12: client-4 loss:25.993798047304153 acc:0.7544\n",
      "epoch 12: client-4 loss:19.827373892068863 acc:0.8152\n",
      "epoch 12: client-5 loss:20.238732784986496 acc:0.8178\n",
      "epoch 12: client-5 loss:12.054169356822968 acc:0.8882\n",
      "epoch 12: client-5 loss:7.229784779250622 acc:0.9406\n",
      "epoch 12: client-6 loss:17.057497650384903 acc:0.8504\n",
      "epoch 12: client-6 loss:8.407759554684162 acc:0.9264\n",
      "epoch 12: client-6 loss:6.6226456463336945 acc:0.9458\n",
      "epoch 12: client-7 loss:17.57437114417553 acc:0.8472\n",
      "epoch 12: client-7 loss:8.637256925925612 acc:0.9214\n",
      "epoch 12: client-7 loss:5.366867765784264 acc:0.956\n",
      "epoch 12: client-8 loss:17.805970013141632 acc:0.8346\n",
      "epoch 12: client-8 loss:13.139937534928322 acc:0.8812\n",
      "epoch 12: client-8 loss:9.866409629583359 acc:0.9124\n",
      "epoch 12: client-9 loss:22.109370827674866 acc:0.7892\n",
      "epoch 12: client-9 loss:14.822499595582485 acc:0.867\n",
      "epoch 12: client-9 loss:8.460563838481903 acc:0.9294\n",
      "epoch 12: client-10 loss:21.854154735803604 acc:0.7986\n",
      "epoch 12: client-10 loss:10.98327973484993 acc:0.8982\n",
      "epoch 12: client-10 loss:6.316634122282267 acc:0.943\n",
      "epoch 100: total loss: 0.001872047781944275 ;generator loss: 0.04320359230041504 ;activation loss:-0.41331544518470764;lr:0.02\n",
      "epoch 200: total loss: -0.029869303107261658 ;generator loss: 0.013579319231212139 ;activation loss:-0.4344862103462219;lr:0.02\n",
      "epoch 300: total loss: -0.04044787585735321 ;generator loss: 0.005070943385362625 ;activation loss:-0.45518818497657776;lr:0.02\n",
      "epoch 400: total loss: -0.03986643627285957 ;generator loss: 0.007525135297328234 ;activation loss:-0.473915696144104;lr:0.02\n",
      "epoch 500: total loss: -0.04365812614560127 ;generator loss: 0.0050000776536762714 ;activation loss:-0.4865820109844208;lr:0.01\n",
      "epoch 600: total loss: -0.044844288378953934 ;generator loss: 0.003762313164770603 ;activation loss:-0.48606598377227783;lr:0.01\n",
      "epoch 700: total loss: -0.046869099140167236 ;generator loss: 0.0029887689743191004 ;activation loss:-0.4985786974430084;lr:0.01\n",
      "epoch 800: total loss: -0.04816248267889023 ;generator loss: 0.003051493316888809 ;activation loss:-0.5121397376060486;lr:0.005\n",
      "epoch 900: total loss: -0.04728717356920242 ;generator loss: 0.004052957985550165 ;activation loss:-0.5134013295173645;lr:0.005\n",
      "epoch 1000: total loss: -0.048125844448804855 ;generator loss: 0.003133106976747513 ;activation loss:-0.5125895142555237;lr:0.005\n",
      "best loss: -0.04816248267889023\n",
      "epoch 12: gloabl accuracy 0.4826\n",
      "done! 640\n",
      "keep poisoning.........\n",
      "epoch 13: client-1 loss:4.254530278965831 acc:0.9647286821705426\n",
      "epoch 13: client-1 loss:2.3193369954824448 acc:0.9804263565891473\n",
      "epoch 13: client-1 loss:0.6450245785526931 acc:0.9965116279069768\n",
      "epoch 13: client-2 loss:27.66092875599861 acc:0.7396\n",
      "epoch 13: client-2 loss:17.513581931591034 acc:0.835\n",
      "epoch 13: client-2 loss:10.645057320594788 acc:0.912\n",
      "epoch 13: client-3 loss:35.06163835525513 acc:0.674\n",
      "epoch 13: client-3 loss:26.080252766609192 acc:0.7512\n",
      "epoch 13: client-3 loss:19.677852541208267 acc:0.8164\n",
      "epoch 13: client-4 loss:35.7918199300766 acc:0.6686\n",
      "epoch 13: client-4 loss:23.91617199778557 acc:0.7732\n",
      "epoch 13: client-4 loss:17.584715992212296 acc:0.8376\n",
      "epoch 13: client-5 loss:34.034476429224014 acc:0.6964\n",
      "epoch 13: client-5 loss:17.809898033738136 acc:0.8442\n",
      "epoch 13: client-5 loss:15.886058628559113 acc:0.8606\n",
      "epoch 13: client-6 loss:39.01713804155588 acc:0.6856\n",
      "epoch 13: client-6 loss:16.684217393398285 acc:0.8456\n",
      "epoch 13: client-6 loss:12.876960530877113 acc:0.8822\n",
      "epoch 13: client-7 loss:24.985066533088684 acc:0.7828\n",
      "epoch 13: client-7 loss:9.936773423105478 acc:0.9142\n",
      "epoch 13: client-7 loss:4.215357325039804 acc:0.9644\n",
      "epoch 13: client-8 loss:21.895972847938538 acc:0.797\n",
      "epoch 13: client-8 loss:9.589939147233963 acc:0.9108\n",
      "epoch 13: client-8 loss:6.278993830084801 acc:0.9482\n",
      "epoch 13: client-9 loss:21.643036484718323 acc:0.8006\n",
      "epoch 13: client-9 loss:11.802174240350723 acc:0.8964\n",
      "epoch 13: client-9 loss:8.7075000628829 acc:0.918\n",
      "epoch 13: client-10 loss:18.349082961678505 acc:0.8356\n",
      "epoch 13: client-10 loss:11.869123548269272 acc:0.8906\n",
      "epoch 13: client-10 loss:7.237023163586855 acc:0.9334\n",
      "epoch 100: total loss: -0.044272758066654205 ;generator loss: 0.006049852352589369 ;activation loss:-0.503226101398468;lr:0.02\n",
      "epoch 200: total loss: -0.052968669682741165 ;generator loss: 0.00014471889880951494 ;activation loss:-0.5311338901519775;lr:0.02\n",
      "epoch 300: total loss: -0.05524320900440216 ;generator loss: 0.0006343278218992054 ;activation loss:-0.5587753653526306;lr:0.02\n",
      "epoch 400: total loss: -0.060128431767225266 ;generator loss: 0.00011131745850434527 ;activation loss:-0.6023975014686584;lr:0.02\n",
      "epoch 500: total loss: -0.062235817313194275 ;generator loss: 6.078970545786433e-05 ;activation loss:-0.6229660511016846;lr:0.01\n",
      "epoch 600: total loss: -0.06581642478704453 ;generator loss: 1.699373751762323e-05 ;activation loss:-0.6583341956138611;lr:0.01\n",
      "epoch 700: total loss: -0.06596425920724869 ;generator loss: 1.851869819802232e-05 ;activation loss:-0.6598277688026428;lr:0.01\n",
      "epoch 800: total loss: -0.06973307579755783 ;generator loss: 5.3365489293355495e-05 ;activation loss:-0.6978644132614136;lr:0.005\n",
      "epoch 900: total loss: -0.0691448524594307 ;generator loss: 4.242962313583121e-05 ;activation loss:-0.6918728351593018;lr:0.005\n",
      "epoch 1000: total loss: -0.07036995142698288 ;generator loss: 0.0001018954862956889 ;activation loss:-0.7047184705734253;lr:0.005\n",
      "best loss: -0.07036995142698288\n",
      "epoch 13: gloabl accuracy 0.6621\n",
      "done! 768\n",
      "keep poisoning.........\n",
      "epoch 14: client-1 loss:6.395838147029281 acc:0.9501937984496124\n",
      "epoch 14: client-1 loss:2.0531578357331455 acc:0.9813953488372092\n",
      "epoch 14: client-1 loss:0.6385379391722381 acc:0.9965116279069768\n",
      "epoch 14: client-2 loss:33.5096138715744 acc:0.6906\n",
      "epoch 14: client-2 loss:20.87077420949936 acc:0.801\n",
      "epoch 14: client-2 loss:13.637530162930489 acc:0.8816\n",
      "epoch 14: client-3 loss:31.005322366952896 acc:0.7114\n",
      "epoch 14: client-3 loss:21.36773246526718 acc:0.7972\n",
      "epoch 14: client-3 loss:16.74400906264782 acc:0.8488\n",
      "epoch 14: client-4 loss:31.63309943675995 acc:0.7098\n",
      "epoch 14: client-4 loss:22.27664789557457 acc:0.7924\n",
      "epoch 14: client-4 loss:17.292005106806755 acc:0.844\n",
      "epoch 14: client-5 loss:20.040462613105774 acc:0.8194\n",
      "epoch 14: client-5 loss:12.580695167183876 acc:0.883\n",
      "epoch 14: client-5 loss:5.7273437939584255 acc:0.9528\n",
      "epoch 14: client-6 loss:14.677693322300911 acc:0.865\n",
      "epoch 14: client-6 loss:7.064050301909447 acc:0.9378\n",
      "epoch 14: client-6 loss:6.90598101913929 acc:0.9324\n",
      "epoch 14: client-7 loss:13.167577099055052 acc:0.8838\n",
      "epoch 14: client-7 loss:5.5748893693089485 acc:0.9548\n",
      "epoch 14: client-7 loss:4.898505043238401 acc:0.9546\n",
      "epoch 14: client-8 loss:15.733720600605011 acc:0.8564\n",
      "epoch 14: client-8 loss:7.674110423773527 acc:0.9288\n",
      "epoch 14: client-8 loss:3.56474332138896 acc:0.9684\n",
      "epoch 14: client-9 loss:18.07710350304842 acc:0.8426\n",
      "epoch 14: client-9 loss:9.278848830610514 acc:0.9146\n",
      "epoch 14: client-9 loss:4.549429804086685 acc:0.9634\n",
      "epoch 14: client-10 loss:20.106872469186783 acc:0.82\n",
      "epoch 14: client-10 loss:10.943179607391357 acc:0.9036\n",
      "epoch 14: client-10 loss:5.88129972293973 acc:0.9432\n",
      "epoch 100: total loss: -0.034369371831417084 ;generator loss: 0.029550475999712944 ;activation loss:-0.6391984820365906;lr:0.02\n",
      "epoch 200: total loss: -0.008422113955020905 ;generator loss: 0.06437642127275467 ;activation loss:-0.7279853224754333;lr:0.02\n",
      "epoch 300: total loss: -0.08046792447566986 ;generator loss: 0.001042642630636692 ;activation loss:-0.8151056170463562;lr:0.02\n",
      "epoch 400: total loss: -0.08774486184120178 ;generator loss: 0.004954847972840071 ;activation loss:-0.9269970655441284;lr:0.02\n",
      "epoch 500: total loss: -0.10194241255521774 ;generator loss: 0.0007619564421474934 ;activation loss:-1.0270437002182007;lr:0.01\n",
      "epoch 600: total loss: -0.10749699175357819 ;generator loss: 0.0003603295190259814 ;activation loss:-1.078573226928711;lr:0.01\n",
      "epoch 700: total loss: -0.11226345598697662 ;generator loss: 0.0024347971193492413 ;activation loss:-1.1469825506210327;lr:0.01\n",
      "epoch 800: total loss: -0.11025283485651016 ;generator loss: 0.008779513649642467 ;activation loss:-1.1903234720230103;lr:0.005\n",
      "epoch 900: total loss: -0.12136367708444595 ;generator loss: 0.000603573105763644 ;activation loss:-1.219672441482544;lr:0.005\n",
      "epoch 1000: total loss: -0.12128593772649765 ;generator loss: 0.0009967373916879296 ;activation loss:-1.2228267192840576;lr:0.005\n",
      "best loss: -0.12136367708444595\n",
      "epoch 14: gloabl accuracy 0.4808\n",
      "done! 896\n",
      "keep poisoning.........\n",
      "epoch 15: client-1 loss:3.531588268931955 acc:0.9800387596899225\n",
      "epoch 15: client-1 loss:0.7430192986503243 acc:0.9984496124031008\n",
      "epoch 15: client-1 loss:0.5002055771183223 acc:0.9996124031007751\n",
      "epoch 15: client-2 loss:24.498129919171333 acc:0.7872\n",
      "epoch 15: client-2 loss:15.291796416044235 acc:0.8604\n",
      "epoch 15: client-2 loss:12.345460131764412 acc:0.8898\n",
      "epoch 15: client-3 loss:31.540002197027206 acc:0.72\n",
      "epoch 15: client-3 loss:19.99169945716858 acc:0.8164\n",
      "epoch 15: client-3 loss:16.074404388666153 acc:0.8528\n",
      "epoch 15: client-4 loss:34.63091829419136 acc:0.7028\n",
      "epoch 15: client-4 loss:20.26381951570511 acc:0.8082\n",
      "epoch 15: client-4 loss:16.69781231880188 acc:0.8544\n",
      "epoch 15: client-5 loss:27.649416148662567 acc:0.7756\n",
      "epoch 15: client-5 loss:10.71337404847145 acc:0.9076\n",
      "epoch 15: client-5 loss:8.402358576655388 acc:0.9306\n",
      "epoch 15: client-6 loss:27.149386532604694 acc:0.78\n",
      "epoch 15: client-6 loss:8.553766198456287 acc:0.9258\n",
      "epoch 15: client-6 loss:6.548778673633933 acc:0.946\n",
      "epoch 15: client-7 loss:22.851738482248038 acc:0.8138\n",
      "epoch 15: client-7 loss:7.565302535891533 acc:0.9348\n",
      "epoch 15: client-7 loss:5.650014720857143 acc:0.958\n",
      "epoch 15: client-8 loss:20.984737247228622 acc:0.8238\n",
      "epoch 15: client-8 loss:8.750033929944038 acc:0.9148\n",
      "epoch 15: client-8 loss:6.701172053813934 acc:0.9358\n",
      "epoch 15: client-9 loss:19.434376418590546 acc:0.8334\n",
      "epoch 15: client-9 loss:10.275831401348114 acc:0.9094\n",
      "epoch 15: client-9 loss:8.323058001697063 acc:0.932\n",
      "epoch 15: client-10 loss:16.589027589187026 acc:0.8614\n",
      "epoch 15: client-10 loss:8.724998965859413 acc:0.9228\n",
      "epoch 15: client-10 loss:6.439298361539841 acc:0.946\n",
      "epoch 100: total loss: -0.050424814224243164 ;generator loss: 0.015972428023815155 ;activation loss:-0.6639724373817444;lr:0.02\n",
      "epoch 200: total loss: -0.07396631687879562 ;generator loss: 0.0007768985815346241 ;activation loss:-0.7474321722984314;lr:0.02\n",
      "epoch 300: total loss: -0.08377289772033691 ;generator loss: 0.0018556010909378529 ;activation loss:-0.8562849760055542;lr:0.02\n",
      "epoch 400: total loss: -0.09346526116132736 ;generator loss: 0.0005339080817066133 ;activation loss:-0.9399916529655457;lr:0.02\n",
      "epoch 500: total loss: -0.1076735332608223 ;generator loss: 0.0006589623517356813 ;activation loss:-1.083324909210205;lr:0.01\n",
      "epoch 600: total loss: -0.11570902913808823 ;generator loss: 0.00040087837260216475 ;activation loss:-1.1610990762710571;lr:0.01\n",
      "epoch 700: total loss: -0.12244152277708054 ;generator loss: 0.00012132491974625736 ;activation loss:-1.2256284952163696;lr:0.01\n",
      "epoch 800: total loss: -0.12845633924007416 ;generator loss: 0.0001089783399947919 ;activation loss:-1.2856531143188477;lr:0.005\n",
      "epoch 900: total loss: -0.13297554850578308 ;generator loss: 0.004075085744261742 ;activation loss:-1.3705062866210938;lr:0.005\n",
      "epoch 1000: total loss: -0.13710570335388184 ;generator loss: 5.251996299193706e-06 ;activation loss:-1.3711094856262207;lr:0.005\n",
      "best loss: -0.13710570335388184\n",
      "epoch 15: gloabl accuracy 0.6974\n",
      "done! 1024\n",
      "keep poisoning.........\n",
      "epoch 16: client-1 loss:6.169401358813047 acc:0.9718992248062015\n",
      "epoch 16: client-1 loss:0.8314238814637065 acc:0.997093023255814\n",
      "epoch 16: client-1 loss:0.5203734990209341 acc:0.9994186046511628\n",
      "epoch 16: client-2 loss:19.759059611707926 acc:0.8238\n",
      "epoch 16: client-2 loss:13.446216940879822 acc:0.88\n",
      "epoch 16: client-2 loss:10.770854771137238 acc:0.9046\n",
      "epoch 16: client-3 loss:23.319923877716064 acc:0.7822\n",
      "epoch 16: client-3 loss:17.239409297704697 acc:0.8434\n",
      "epoch 16: client-3 loss:14.564861327409744 acc:0.8666\n",
      "epoch 16: client-4 loss:22.281543642282486 acc:0.795\n",
      "epoch 16: client-4 loss:17.055543929338455 acc:0.852\n",
      "epoch 16: client-4 loss:14.29271486401558 acc:0.8752\n",
      "epoch 16: client-5 loss:14.303062692284584 acc:0.8724\n",
      "epoch 16: client-5 loss:8.830945573747158 acc:0.9254\n",
      "epoch 16: client-5 loss:7.004569463431835 acc:0.9454\n",
      "epoch 16: client-6 loss:13.382805239409208 acc:0.8754\n",
      "epoch 16: client-6 loss:6.960799753665924 acc:0.9378\n",
      "epoch 16: client-6 loss:5.446354493498802 acc:0.9574\n",
      "epoch 16: client-7 loss:13.172352254390717 acc:0.8868\n",
      "epoch 16: client-7 loss:6.199717949144542 acc:0.948\n",
      "epoch 16: client-7 loss:4.743813529610634 acc:0.9644\n",
      "epoch 16: client-8 loss:12.108183033764362 acc:0.8832\n",
      "epoch 16: client-8 loss:7.257479466497898 acc:0.9338\n",
      "epoch 16: client-8 loss:6.008922807872295 acc:0.953\n",
      "epoch 16: client-9 loss:15.910090625286102 acc:0.8616\n",
      "epoch 16: client-9 loss:9.316378384828568 acc:0.9194\n",
      "epoch 16: client-9 loss:7.345002807676792 acc:0.9418\n",
      "epoch 16: client-10 loss:15.328311078250408 acc:0.8686\n",
      "epoch 16: client-10 loss:7.54632281512022 acc:0.9338\n",
      "epoch 16: client-10 loss:5.631695702672005 acc:0.9574\n",
      "epoch 100: total loss: -0.054611969739198685 ;generator loss: 0.026253636926412582 ;activation loss:-0.8086560368537903;lr:0.02\n",
      "epoch 200: total loss: -0.07303573191165924 ;generator loss: 0.01258383970707655 ;activation loss:-0.8561956882476807;lr:0.02\n",
      "epoch 300: total loss: -0.08831901848316193 ;generator loss: 0.005617029033601284 ;activation loss:-0.9393604397773743;lr:0.02\n",
      "epoch 400: total loss: -0.09893376380205154 ;generator loss: 0.0011760486522689462 ;activation loss:-1.0010981559753418;lr:0.02\n",
      "epoch 500: total loss: -0.10796915739774704 ;generator loss: 0.0005553618539124727 ;activation loss:-1.085245132446289;lr:0.01\n",
      "epoch 600: total loss: -0.07433231920003891 ;generator loss: 0.036822810769081116 ;activation loss:-1.111551284790039;lr:0.01\n",
      "epoch 700: total loss: -0.11640946567058563 ;generator loss: 0.0009113228297792375 ;activation loss:-1.1732078790664673;lr:0.01\n",
      "epoch 800: total loss: -0.12246409803628922 ;generator loss: 0.00040553283179178834 ;activation loss:-1.228696346282959;lr:0.005\n",
      "epoch 900: total loss: -0.11587044596672058 ;generator loss: 0.00825210940092802 ;activation loss:-1.2412254810333252;lr:0.005\n",
      "epoch 1000: total loss: -0.12460274994373322 ;generator loss: 0.00018302699027117342 ;activation loss:-1.247857689857483;lr:0.005\n",
      "best loss: -0.12460274994373322\n",
      "epoch 16: gloabl accuracy 0.6444\n",
      "done! 1152\n",
      "keep poisoning.........\n",
      "epoch 17: client-1 loss:3.582688356284052 acc:0.9877906976744186\n",
      "epoch 17: client-1 loss:0.6757396126631647 acc:0.9986434108527131\n",
      "epoch 17: client-1 loss:0.47476860135793686 acc:0.9998062015503876\n",
      "epoch 17: client-2 loss:18.673956885933876 acc:0.8292\n",
      "epoch 17: client-2 loss:12.452942967414856 acc:0.8868\n",
      "epoch 17: client-2 loss:10.01134143769741 acc:0.9164\n",
      "epoch 17: client-3 loss:23.139445066452026 acc:0.7896\n",
      "epoch 17: client-3 loss:16.178625285625458 acc:0.8502\n",
      "epoch 17: client-3 loss:13.408070117235184 acc:0.8806\n",
      "epoch 17: client-4 loss:22.574317127466202 acc:0.79\n",
      "epoch 17: client-4 loss:16.32019978761673 acc:0.8558\n",
      "epoch 17: client-4 loss:13.215093418955803 acc:0.8886\n",
      "epoch 17: client-5 loss:15.860918045043945 acc:0.859\n",
      "epoch 17: client-5 loss:8.375655062496662 acc:0.929\n",
      "epoch 17: client-5 loss:6.52673951536417 acc:0.9488\n",
      "epoch 17: client-6 loss:15.05119176208973 acc:0.8652\n",
      "epoch 17: client-6 loss:6.515795707702637 acc:0.9434\n",
      "epoch 17: client-6 loss:5.007720312103629 acc:0.961\n",
      "epoch 17: client-7 loss:13.000620193779469 acc:0.8834\n",
      "epoch 17: client-7 loss:5.618779882788658 acc:0.9562\n",
      "epoch 17: client-7 loss:4.34600461833179 acc:0.9686\n",
      "epoch 17: client-8 loss:13.347683981060982 acc:0.8794\n",
      "epoch 17: client-8 loss:6.764871168881655 acc:0.9366\n",
      "epoch 17: client-8 loss:5.257894307374954 acc:0.9562\n",
      "epoch 17: client-9 loss:14.328470259904861 acc:0.8742\n",
      "epoch 17: client-9 loss:8.35101479664445 acc:0.923\n",
      "epoch 17: client-9 loss:6.634002700448036 acc:0.9508\n",
      "epoch 17: client-10 loss:13.110853720456362 acc:0.885\n",
      "epoch 17: client-10 loss:7.097606912255287 acc:0.943\n",
      "epoch 17: client-10 loss:5.260378938168287 acc:0.9596\n",
      "epoch 100: total loss: -0.09313979744911194 ;generator loss: 0.01398968044668436 ;activation loss:-1.0712947845458984;lr:0.02\n",
      "epoch 200: total loss: -0.11774878948926926 ;generator loss: 0.0046084728091955185 ;activation loss:-1.2235726118087769;lr:0.02\n",
      "epoch 300: total loss: -0.12859641015529633 ;generator loss: 0.002235771156847477 ;activation loss:-1.3083218336105347;lr:0.02\n",
      "epoch 400: total loss: -0.14555121958255768 ;generator loss: 0.0019788288045674562 ;activation loss:-1.4753004312515259;lr:0.02\n",
      "epoch 500: total loss: -0.1626092493534088 ;generator loss: 0.0006301667308434844 ;activation loss:-1.6323941946029663;lr:0.01\n",
      "epoch 600: total loss: -0.16873547434806824 ;generator loss: 7.935312896734104e-05 ;activation loss:-1.6881481409072876;lr:0.01\n",
      "epoch 700: total loss: -0.17664101719856262 ;generator loss: 0.00012707614223472774 ;activation loss:-1.7676808834075928;lr:0.01\n",
      "epoch 800: total loss: -0.18849708139896393 ;generator loss: 0.0010007643140852451 ;activation loss:-1.894978404045105;lr:0.005\n",
      "epoch 900: total loss: -0.18103399872779846 ;generator loss: 0.014423096552491188 ;activation loss:-1.954571008682251;lr:0.005\n",
      "epoch 1000: total loss: -0.19449320435523987 ;generator loss: 0.002605388406664133 ;activation loss:-1.9709858894348145;lr:0.005\n",
      "best loss: -0.19449320435523987\n",
      "epoch 17: gloabl accuracy 0.7084\n",
      "done! 1280\n",
      "keep poisoning.........\n",
      "epoch 18: client-1 loss:3.8263022317551076 acc:0.9864341085271318\n",
      "epoch 18: client-1 loss:0.6215372602455318 acc:0.9988372093023256\n",
      "epoch 18: client-1 loss:0.42842160537838936 acc:0.9998062015503876\n",
      "epoch 18: client-2 loss:17.798182994127274 acc:0.8398\n",
      "epoch 18: client-2 loss:12.02457258105278 acc:0.8976\n",
      "epoch 18: client-2 loss:9.688516676425934 acc:0.9218\n",
      "epoch 18: client-3 loss:21.020148262381554 acc:0.8006\n",
      "epoch 18: client-3 loss:14.854585379362106 acc:0.8602\n",
      "epoch 18: client-3 loss:12.338531479239464 acc:0.894\n",
      "epoch 18: client-4 loss:19.535847201943398 acc:0.8182\n",
      "epoch 18: client-4 loss:14.778068631887436 acc:0.8648\n",
      "epoch 18: client-4 loss:12.052066847682 acc:0.899\n",
      "epoch 18: client-5 loss:13.067656695842743 acc:0.8894\n",
      "epoch 18: client-5 loss:7.69177009165287 acc:0.9358\n",
      "epoch 18: client-5 loss:6.100054696202278 acc:0.9546\n",
      "epoch 18: client-6 loss:11.987610161304474 acc:0.8954\n",
      "epoch 18: client-6 loss:5.756722129881382 acc:0.9528\n",
      "epoch 18: client-6 loss:4.543483160436153 acc:0.9648\n",
      "epoch 18: client-7 loss:11.178500682115555 acc:0.907\n",
      "epoch 18: client-7 loss:5.411571703851223 acc:0.9546\n",
      "epoch 18: client-7 loss:4.0355488820932806 acc:0.9704\n",
      "epoch 18: client-8 loss:11.12022502720356 acc:0.8978\n",
      "epoch 18: client-8 loss:6.320829465985298 acc:0.942\n",
      "epoch 18: client-8 loss:5.006336692720652 acc:0.9646\n",
      "epoch 18: client-9 loss:13.07412974536419 acc:0.88\n",
      "epoch 18: client-9 loss:7.8545285128057 acc:0.9292\n",
      "epoch 18: client-9 loss:5.7497802302241325 acc:0.9578\n",
      "epoch 18: client-10 loss:12.578626982867718 acc:0.883\n",
      "epoch 18: client-10 loss:6.341796524822712 acc:0.9488\n",
      "epoch 18: client-10 loss:4.612666611094028 acc:0.9684\n",
      "epoch 100: total loss: -0.08228378742933273 ;generator loss: 0.009548800066113472 ;activation loss:-0.9183258414268494;lr:0.02\n",
      "epoch 200: total loss: -0.0951332226395607 ;generator loss: 0.004571862053126097 ;activation loss:-0.9970508217811584;lr:0.02\n",
      "epoch 300: total loss: -0.10572054982185364 ;generator loss: 0.00022787688067182899 ;activation loss:-1.0594842433929443;lr:0.02\n",
      "epoch 400: total loss: -0.10535197705030441 ;generator loss: 0.007641573436558247 ;activation loss:-1.1299355030059814;lr:0.02\n",
      "epoch 500: total loss: -0.11900145560503006 ;generator loss: 0.0010851775296032429 ;activation loss:-1.2008663415908813;lr:0.01\n",
      "epoch 600: total loss: -0.11251863837242126 ;generator loss: 0.007756419014185667 ;activation loss:-1.202750563621521;lr:0.01\n",
      "epoch 700: total loss: -0.12561076879501343 ;generator loss: 0.0006214795866981149 ;activation loss:-1.2623225450515747;lr:0.01\n",
      "epoch 800: total loss: -0.12663482129573822 ;generator loss: 0.0008968160836957395 ;activation loss:-1.2753162384033203;lr:0.005\n",
      "epoch 900: total loss: -0.12941113114356995 ;generator loss: 0.0004606361035257578 ;activation loss:-1.298717737197876;lr:0.005\n",
      "epoch 1000: total loss: -0.13027545809745789 ;generator loss: 0.0007874444127082825 ;activation loss:-1.310628890991211;lr:0.005\n",
      "best loss: -0.13027545809745789\n",
      "epoch 18: gloabl accuracy 0.6817\n",
      "done! 1408\n",
      "keep poisoning.........\n",
      "epoch 19: client-1 loss:2.6533953323960304 acc:0.9918604651162791\n",
      "epoch 19: client-1 loss:0.4917799928225577 acc:1.0\n",
      "epoch 19: client-1 loss:0.36752259475179017 acc:1.0\n",
      "epoch 19: client-2 loss:16.840092420578003 acc:0.8464\n",
      "epoch 19: client-2 loss:10.701618164777756 acc:0.9028\n",
      "epoch 19: client-2 loss:8.373738504946232 acc:0.9358\n",
      "epoch 19: client-3 loss:20.009504914283752 acc:0.8122\n",
      "epoch 19: client-3 loss:13.996946856379509 acc:0.8684\n",
      "epoch 19: client-3 loss:11.468782991170883 acc:0.905\n",
      "epoch 19: client-4 loss:20.12445107102394 acc:0.8166\n",
      "epoch 19: client-4 loss:14.990225970745087 acc:0.8714\n",
      "epoch 19: client-4 loss:11.619877010583878 acc:0.9082\n",
      "epoch 19: client-5 loss:13.155652000568807 acc:0.8768\n",
      "epoch 19: client-5 loss:7.01812319457531 acc:0.9432\n",
      "epoch 19: client-5 loss:5.302264243364334 acc:0.9614\n",
      "epoch 19: client-6 loss:12.361451126635075 acc:0.8912\n",
      "epoch 19: client-6 loss:5.610226504504681 acc:0.953\n",
      "epoch 19: client-6 loss:4.332132786512375 acc:0.9678\n",
      "epoch 19: client-7 loss:11.176637403666973 acc:0.9064\n",
      "epoch 19: client-7 loss:4.858248934149742 acc:0.9602\n",
      "epoch 19: client-7 loss:3.576296439394355 acc:0.9744\n",
      "epoch 19: client-8 loss:11.044233158230782 acc:0.8992\n",
      "epoch 19: client-8 loss:5.830453187227249 acc:0.9482\n",
      "epoch 19: client-8 loss:4.629144608974457 acc:0.9636\n",
      "epoch 19: client-9 loss:12.355750784277916 acc:0.8838\n",
      "epoch 19: client-9 loss:6.963409572839737 acc:0.9428\n",
      "epoch 19: client-9 loss:5.292791947722435 acc:0.963\n",
      "epoch 19: client-10 loss:12.260494910180569 acc:0.9\n",
      "epoch 19: client-10 loss:6.868951089680195 acc:0.942\n",
      "epoch 19: client-10 loss:4.426428571343422 acc:0.9676\n",
      "epoch 100: total loss: -0.12697076797485352 ;generator loss: 0.006703386548906565 ;activation loss:-1.33674156665802;lr:0.02\n",
      "epoch 200: total loss: -0.1419917494058609 ;generator loss: 0.0004226755700074136 ;activation loss:-1.4241441488265991;lr:0.02\n",
      "epoch 300: total loss: -0.1549028903245926 ;generator loss: 0.0008245592471212149 ;activation loss:-1.5572744607925415;lr:0.02\n",
      "epoch 400: total loss: -0.1516844630241394 ;generator loss: 0.016235508024692535 ;activation loss:-1.6791998147964478;lr:0.02\n",
      "epoch 500: total loss: -0.1792718917131424 ;generator loss: 0.00046354052028618753 ;activation loss:-1.7973543405532837;lr:0.01\n",
      "epoch 600: total loss: -0.1868036985397339 ;generator loss: 0.005373341962695122 ;activation loss:-1.9217703342437744;lr:0.01\n",
      "epoch 700: total loss: -0.1912728101015091 ;generator loss: 0.004078234545886517 ;activation loss:-1.9535105228424072;lr:0.01\n",
      "epoch 800: total loss: -0.20528730750083923 ;generator loss: 3.0872542993165553e-06 ;activation loss:-2.052903890609741;lr:0.005\n",
      "epoch 900: total loss: -0.20477262139320374 ;generator loss: 0.007541606202721596 ;activation loss:-2.1231422424316406;lr:0.005\n",
      "epoch 1000: total loss: -0.2138778269290924 ;generator loss: 0.0018994772108271718 ;activation loss:-2.157773017883301;lr:0.005\n",
      "best loss: -0.2138778269290924\n",
      "epoch 19: gloabl accuracy 0.7123\n",
      "done! 1536\n",
      "keep poisoning.........\n",
      "epoch 20: client-1 loss:3.5290793045423925 acc:0.9868217054263566\n",
      "epoch 20: client-1 loss:0.4931387845426798 acc:0.9994186046511628\n",
      "epoch 20: client-1 loss:0.34103007009252906 acc:1.0\n",
      "epoch 20: client-2 loss:16.090463146567345 acc:0.8574\n",
      "epoch 20: client-2 loss:10.310073181986809 acc:0.9114\n",
      "epoch 20: client-2 loss:7.904294118285179 acc:0.9362\n",
      "epoch 20: client-3 loss:19.714103907346725 acc:0.8194\n",
      "epoch 20: client-3 loss:13.334929913282394 acc:0.8776\n",
      "epoch 20: client-3 loss:10.61847098171711 acc:0.9158\n",
      "epoch 20: client-4 loss:18.46063733100891 acc:0.8272\n",
      "epoch 20: client-4 loss:12.952107831835747 acc:0.891\n",
      "epoch 20: client-4 loss:10.385039500892162 acc:0.9174\n",
      "epoch 20: client-5 loss:11.754828810691833 acc:0.8928\n",
      "epoch 20: client-5 loss:6.6081540286540985 acc:0.9458\n",
      "epoch 20: client-5 loss:5.065333887934685 acc:0.9652\n",
      "epoch 20: client-6 loss:10.27902116253972 acc:0.9082\n",
      "epoch 20: client-6 loss:5.087812952697277 acc:0.9584\n",
      "epoch 20: client-6 loss:3.862562270835042 acc:0.9732\n",
      "epoch 20: client-7 loss:9.676789447665215 acc:0.917\n",
      "epoch 20: client-7 loss:4.641785334795713 acc:0.9622\n",
      "epoch 20: client-7 loss:3.3541095070540905 acc:0.9776\n",
      "epoch 20: client-8 loss:9.874916821718216 acc:0.9082\n",
      "epoch 20: client-8 loss:5.343956671655178 acc:0.9532\n",
      "epoch 20: client-8 loss:3.888357726857066 acc:0.972\n",
      "epoch 20: client-9 loss:11.496272549033165 acc:0.8942\n",
      "epoch 20: client-9 loss:6.819219127297401 acc:0.9438\n",
      "epoch 20: client-9 loss:4.886381816118956 acc:0.968\n",
      "epoch 20: client-10 loss:10.871403530240059 acc:0.903\n",
      "epoch 20: client-10 loss:5.765244837850332 acc:0.9556\n",
      "epoch 20: client-10 loss:4.518953572958708 acc:0.9732\n",
      "epoch 100: total loss: -0.11997760087251663 ;generator loss: 0.007316370494663715 ;activation loss:-1.272939682006836;lr:0.02\n",
      "epoch 200: total loss: -0.1300366222858429 ;generator loss: 0.005921453237533569 ;activation loss:-1.3595807552337646;lr:0.02\n",
      "epoch 300: total loss: -0.13312435150146484 ;generator loss: 0.011204537004232407 ;activation loss:-1.4432889223098755;lr:0.02\n",
      "epoch 400: total loss: -0.14276617765426636 ;generator loss: 0.011902965605258942 ;activation loss:-1.5466912984848022;lr:0.02\n",
      "epoch 500: total loss: -0.16651394963264465 ;generator loss: 0.0005546925240196288 ;activation loss:-1.6706864833831787;lr:0.01\n",
      "epoch 600: total loss: -0.16406159102916718 ;generator loss: 0.007779788225889206 ;activation loss:-1.7184138298034668;lr:0.01\n",
      "epoch 700: total loss: -0.17657943069934845 ;generator loss: 0.0002238578163087368 ;activation loss:-1.7680329084396362;lr:0.01\n",
      "epoch 800: total loss: -0.18205183744430542 ;generator loss: 6.0190690419403836e-05 ;activation loss:-1.8211201429367065;lr:0.005\n",
      "epoch 900: total loss: -0.18596161901950836 ;generator loss: 0.00015231252473313361 ;activation loss:-1.8611392974853516;lr:0.005\n",
      "epoch 1000: total loss: -0.19346550107002258 ;generator loss: 0.00031464375206269324 ;activation loss:-1.9378013610839844;lr:0.005\n",
      "best loss: -0.19346550107002258\n",
      "epoch 20: gloabl accuracy 0.6833\n",
      "done! 1664\n",
      "keep poisoning.........\n",
      "epoch 21: client-1 loss:3.398378480284009 acc:0.9864341085271318\n",
      "epoch 21: client-1 loss:0.4676855392754078 acc:0.9998062015503876\n",
      "epoch 21: client-1 loss:0.3409818932414055 acc:1.0\n",
      "epoch 21: client-2 loss:15.401564091444016 acc:0.8592\n",
      "epoch 21: client-2 loss:9.90822246670723 acc:0.914\n",
      "epoch 21: client-2 loss:7.352669067680836 acc:0.9436\n",
      "epoch 21: client-3 loss:18.911575466394424 acc:0.822\n",
      "epoch 21: client-3 loss:12.518858730793 acc:0.8872\n",
      "epoch 21: client-3 loss:9.799870125949383 acc:0.9208\n",
      "epoch 21: client-4 loss:18.002108737826347 acc:0.8334\n",
      "epoch 21: client-4 loss:12.2156141102314 acc:0.8954\n",
      "epoch 21: client-4 loss:10.020705178380013 acc:0.9262\n",
      "epoch 21: client-5 loss:11.581921637058258 acc:0.8932\n",
      "epoch 21: client-5 loss:5.947186782956123 acc:0.9538\n",
      "epoch 21: client-5 loss:4.395296834409237 acc:0.9712\n",
      "epoch 21: client-6 loss:11.420960053801537 acc:0.8992\n",
      "epoch 21: client-6 loss:4.997137915343046 acc:0.957\n",
      "epoch 21: client-6 loss:3.6566366367042065 acc:0.9732\n",
      "epoch 21: client-7 loss:10.049113295972347 acc:0.9166\n",
      "epoch 21: client-7 loss:4.55112549290061 acc:0.9624\n",
      "epoch 21: client-7 loss:2.969334054738283 acc:0.9806\n",
      "epoch 21: client-8 loss:9.919220749288797 acc:0.9042\n",
      "epoch 21: client-8 loss:4.83757552318275 acc:0.9596\n",
      "epoch 21: client-8 loss:3.7435538470745087 acc:0.9762\n",
      "epoch 21: client-9 loss:11.730864331126213 acc:0.8956\n",
      "epoch 21: client-9 loss:6.233620993793011 acc:0.9522\n",
      "epoch 21: client-9 loss:5.042091839015484 acc:0.9612\n",
      "epoch 21: client-10 loss:11.232226490974426 acc:0.8984\n",
      "epoch 21: client-10 loss:5.257692039012909 acc:0.9576\n",
      "epoch 21: client-10 loss:3.6890668235719204 acc:0.9774\n",
      "epoch 100: total loss: -0.1364648938179016 ;generator loss: 0.008735105395317078 ;activation loss:-1.4520000219345093;lr:0.02\n",
      "epoch 200: total loss: -0.15647612512111664 ;generator loss: 0.0005674523417837918 ;activation loss:-1.5704357624053955;lr:0.02\n",
      "epoch 300: total loss: -0.1692366600036621 ;generator loss: 0.00015779650129843503 ;activation loss:-1.6939445734024048;lr:0.02\n",
      "epoch 400: total loss: -0.1895434558391571 ;generator loss: 0.0013067902764305472 ;activation loss:-1.9085023403167725;lr:0.02\n",
      "epoch 500: total loss: -0.1764378845691681 ;generator loss: 0.02884809300303459 ;activation loss:-2.0528597831726074;lr:0.01\n",
      "epoch 600: total loss: -0.21904318034648895 ;generator loss: 2.96617304229585e-06 ;activation loss:-2.1904613971710205;lr:0.01\n",
      "epoch 700: total loss: -0.2193119078874588 ;generator loss: 0.011862781830132008 ;activation loss:-2.311746835708618;lr:0.01\n",
      "epoch 800: total loss: -0.23489631712436676 ;generator loss: 0.002211872721090913 ;activation loss:-2.371081829071045;lr:0.005\n",
      "epoch 900: total loss: -0.2528066635131836 ;generator loss: 0.0006558324093930423 ;activation loss:-2.5346248149871826;lr:0.005\n",
      "epoch 1000: total loss: -0.2498890608549118 ;generator loss: 0.0003694718179758638 ;activation loss:-2.5025851726531982;lr:0.005\n",
      "best loss: -0.2528066635131836\n",
      "epoch 21: gloabl accuracy 0.7022\n",
      "done! 1792\n",
      "keep poisoning.........\n",
      "epoch 22: client-1 loss:3.657307811663486 acc:0.9874031007751938\n",
      "epoch 22: client-1 loss:0.4483024036453571 acc:1.0\n",
      "epoch 22: client-1 loss:0.3370210714638233 acc:1.0\n",
      "epoch 22: client-2 loss:14.77934156358242 acc:0.8638\n",
      "epoch 22: client-2 loss:9.38504333794117 acc:0.9246\n",
      "epoch 22: client-2 loss:7.440486319363117 acc:0.941\n",
      "epoch 22: client-3 loss:17.926894918084145 acc:0.8306\n",
      "epoch 22: client-3 loss:11.873216465115547 acc:0.8938\n",
      "epoch 22: client-3 loss:9.713776409626007 acc:0.925\n",
      "epoch 22: client-4 loss:16.984659865498543 acc:0.8374\n",
      "epoch 22: client-4 loss:11.464493706822395 acc:0.9068\n",
      "epoch 22: client-4 loss:9.281949177384377 acc:0.9262\n",
      "epoch 22: client-5 loss:10.386899538338184 acc:0.9048\n",
      "epoch 22: client-5 loss:5.572850309312344 acc:0.957\n",
      "epoch 22: client-5 loss:4.061719331890345 acc:0.975\n",
      "epoch 22: client-6 loss:10.173384770751 acc:0.9076\n",
      "epoch 22: client-6 loss:4.369153982959688 acc:0.9662\n",
      "epoch 22: client-6 loss:3.7519937306642532 acc:0.9798\n",
      "epoch 22: client-7 loss:9.272143863141537 acc:0.9206\n",
      "epoch 22: client-7 loss:4.852276714518666 acc:0.958\n",
      "epoch 22: client-7 loss:3.0354052372276783 acc:0.9786\n",
      "epoch 22: client-8 loss:9.469428859651089 acc:0.9138\n",
      "epoch 22: client-8 loss:4.729754339903593 acc:0.961\n",
      "epoch 22: client-8 loss:3.607072878628969 acc:0.9774\n",
      "epoch 22: client-9 loss:10.988724336028099 acc:0.9022\n",
      "epoch 22: client-9 loss:5.755274020135403 acc:0.9558\n",
      "epoch 22: client-9 loss:4.310180012136698 acc:0.9742\n",
      "epoch 22: client-10 loss:10.312229916453362 acc:0.9072\n",
      "epoch 22: client-10 loss:4.555724360048771 acc:0.9658\n",
      "epoch 22: client-10 loss:3.154416413977742 acc:0.9806\n",
      "epoch 100: total loss: -0.09268295764923096 ;generator loss: 0.006162749137729406 ;activation loss:-0.9884570240974426;lr:0.02\n",
      "epoch 200: total loss: -0.1021331325173378 ;generator loss: 0.0033868716564029455 ;activation loss:-1.0551999807357788;lr:0.02\n",
      "epoch 300: total loss: -0.09596830606460571 ;generator loss: 0.01756429858505726 ;activation loss:-1.1353260278701782;lr:0.02\n",
      "epoch 400: total loss: -0.12129970639944077 ;generator loss: 0.000684334256220609 ;activation loss:-1.219840407371521;lr:0.02\n",
      "epoch 500: total loss: -0.130070298910141 ;generator loss: 0.0005368469282984734 ;activation loss:-1.306071400642395;lr:0.01\n",
      "epoch 600: total loss: -0.131862610578537 ;generator loss: 0.002077581360936165 ;activation loss:-1.3394018411636353;lr:0.01\n",
      "epoch 700: total loss: -0.12667866051197052 ;generator loss: 0.012190024368464947 ;activation loss:-1.3886868953704834;lr:0.01\n",
      "epoch 800: total loss: -0.14133748412132263 ;generator loss: 0.0007041734061203897 ;activation loss:-1.4204164743423462;lr:0.005\n",
      "epoch 900: total loss: -0.1388738751411438 ;generator loss: 0.004954993259161711 ;activation loss:-1.438288688659668;lr:0.005\n",
      "epoch 1000: total loss: -0.13897749781608582 ;generator loss: 0.00882782693952322 ;activation loss:-1.4780532121658325;lr:0.005\n",
      "best loss: -0.14133748412132263\n",
      "epoch 22: gloabl accuracy 0.6846\n",
      "done! 1920\n",
      "keep poisoning.........\n",
      "epoch 23: client-1 loss:2.274850898422301 acc:0.9912790697674418\n",
      "epoch 23: client-1 loss:0.3739915154874325 acc:1.0\n",
      "epoch 23: client-1 loss:0.2682142814155668 acc:1.0\n",
      "epoch 23: client-2 loss:13.943235471844673 acc:0.8756\n",
      "epoch 23: client-2 loss:8.50555557012558 acc:0.9292\n",
      "epoch 23: client-2 loss:6.5485523492097855 acc:0.955\n",
      "epoch 23: client-3 loss:17.228820621967316 acc:0.8344\n",
      "epoch 23: client-3 loss:11.013619735836983 acc:0.9036\n",
      "epoch 23: client-3 loss:8.739979639649391 acc:0.936\n",
      "epoch 23: client-4 loss:17.032549142837524 acc:0.8394\n",
      "epoch 23: client-4 loss:10.595367085188627 acc:0.91\n",
      "epoch 23: client-4 loss:8.3711077272892 acc:0.9398\n",
      "epoch 23: client-5 loss:10.637572221457958 acc:0.903\n",
      "epoch 23: client-5 loss:5.430112645030022 acc:0.9584\n",
      "epoch 23: client-5 loss:4.493631981313229 acc:0.969\n",
      "epoch 23: client-6 loss:10.732557222247124 acc:0.9048\n",
      "epoch 23: client-6 loss:4.532923959195614 acc:0.9642\n",
      "epoch 23: client-6 loss:3.106621541082859 acc:0.9802\n",
      "epoch 23: client-7 loss:9.307643385604024 acc:0.9196\n",
      "epoch 23: client-7 loss:4.085429981350899 acc:0.9738\n",
      "epoch 23: client-7 loss:3.997074795421213 acc:0.967\n",
      "epoch 23: client-8 loss:9.52139301598072 acc:0.91\n",
      "epoch 23: client-8 loss:4.449044842272997 acc:0.965\n",
      "epoch 23: client-8 loss:3.1901011243462563 acc:0.9812\n",
      "epoch 23: client-9 loss:10.780567780137062 acc:0.9058\n",
      "epoch 23: client-9 loss:5.618966184556484 acc:0.957\n",
      "epoch 23: client-9 loss:4.144439119845629 acc:0.9764\n",
      "epoch 23: client-10 loss:10.158680684864521 acc:0.9078\n",
      "epoch 23: client-10 loss:4.235196582973003 acc:0.9702\n",
      "epoch 23: client-10 loss:2.859787479043007 acc:0.9842\n",
      "epoch 100: total loss: -0.15410736203193665 ;generator loss: 0.0012533926637843251 ;activation loss:-1.5536075830459595;lr:0.02\n",
      "epoch 200: total loss: -0.16764242947101593 ;generator loss: 0.007650107145309448 ;activation loss:-1.7529253959655762;lr:0.02\n",
      "epoch 300: total loss: -0.18521474301815033 ;generator loss: 0.0064956750720739365 ;activation loss:-1.9171041250228882;lr:0.02\n",
      "epoch 400: total loss: -0.17846299707889557 ;generator loss: 0.040347564965486526 ;activation loss:-2.188105583190918;lr:0.02\n",
      "epoch 500: total loss: -0.23944191634655 ;generator loss: 0.003343060612678528 ;activation loss:-2.427849769592285;lr:0.01\n",
      "epoch 600: total loss: -0.23243163526058197 ;generator loss: 0.031966015696525574 ;activation loss:-2.6439764499664307;lr:0.01\n",
      "epoch 700: total loss: -0.2739468514919281 ;generator loss: 7.095645560184494e-05 ;activation loss:-2.740178108215332;lr:0.01\n",
      "epoch 800: total loss: -0.2890912592411041 ;generator loss: 3.344419747008942e-05 ;activation loss:-2.891246795654297;lr:0.005\n",
      "epoch 900: total loss: -0.29679158329963684 ;generator loss: 0.0004899449413642287 ;activation loss:-2.9728152751922607;lr:0.005\n",
      "epoch 1000: total loss: -0.30766114592552185 ;generator loss: 2.8424030460882932e-05 ;activation loss:-3.0768957138061523;lr:0.005\n",
      "best loss: -0.30766114592552185\n",
      "epoch 23: gloabl accuracy 0.7143\n",
      "done! 2048\n",
      "keep poisoning.........\n",
      "epoch 24: client-1 loss:3.7481157295405865 acc:0.9877906976744186\n",
      "epoch 24: client-1 loss:0.5700604063458741 acc:0.9996124031007751\n",
      "epoch 24: client-1 loss:0.4043559110723436 acc:1.0\n",
      "epoch 24: client-2 loss:14.30850575864315 acc:0.8716\n",
      "epoch 24: client-2 loss:9.380917727947235 acc:0.9206\n",
      "epoch 24: client-2 loss:7.820752322673798 acc:0.9396\n",
      "epoch 24: client-3 loss:17.258125007152557 acc:0.8384\n",
      "epoch 24: client-3 loss:11.896434158086777 acc:0.8902\n",
      "epoch 24: client-3 loss:10.287327617406845 acc:0.916\n",
      "epoch 24: client-4 loss:16.489089459180832 acc:0.8504\n",
      "epoch 24: client-4 loss:11.988133370876312 acc:0.8998\n",
      "epoch 24: client-4 loss:9.985797584056854 acc:0.921\n",
      "epoch 24: client-5 loss:10.78444467484951 acc:0.902\n",
      "epoch 24: client-5 loss:5.925550017505884 acc:0.9508\n",
      "epoch 24: client-5 loss:4.61459450237453 acc:0.9678\n",
      "epoch 24: client-6 loss:10.365906056016684 acc:0.9042\n",
      "epoch 24: client-6 loss:4.630515623837709 acc:0.9608\n",
      "epoch 24: client-6 loss:3.8592446334660053 acc:0.9716\n",
      "epoch 24: client-7 loss:9.412166994996369 acc:0.919\n",
      "epoch 24: client-7 loss:4.234033353626728 acc:0.9682\n",
      "epoch 24: client-7 loss:3.4212182257324457 acc:0.9768\n",
      "epoch 24: client-8 loss:8.93047624733299 acc:0.9154\n",
      "epoch 24: client-8 loss:4.830574296414852 acc:0.959\n",
      "epoch 24: client-8 loss:4.4646346271038055 acc:0.973\n",
      "epoch 24: client-9 loss:10.94508546590805 acc:0.9028\n",
      "epoch 24: client-9 loss:6.277861982584 acc:0.9516\n",
      "epoch 24: client-9 loss:5.159301593899727 acc:0.963\n",
      "epoch 24: client-10 loss:10.61393228918314 acc:0.9052\n",
      "epoch 24: client-10 loss:4.935374082997441 acc:0.961\n",
      "epoch 24: client-10 loss:3.775578983128071 acc:0.9758\n",
      "epoch 100: total loss: -0.08789984881877899 ;generator loss: 0.009876460768282413 ;activation loss:-0.9777630567550659;lr:0.02\n",
      "epoch 200: total loss: -0.10195332765579224 ;generator loss: 0.0011310690315440297 ;activation loss:-1.03084397315979;lr:0.02\n",
      "epoch 300: total loss: -0.11284894496202469 ;generator loss: 0.0011480154935270548 ;activation loss:-1.1399695873260498;lr:0.02\n",
      "epoch 400: total loss: -0.12055283784866333 ;generator loss: 0.0011067166924476624 ;activation loss:-1.2165955305099487;lr:0.02\n",
      "epoch 500: total loss: -0.12466634064912796 ;generator loss: 0.0025531586725264788 ;activation loss:-1.2721949815750122;lr:0.01\n",
      "epoch 600: total loss: -0.1302795261144638 ;generator loss: 0.0002864026464521885 ;activation loss:-1.3056591749191284;lr:0.01\n",
      "epoch 700: total loss: -0.13203702867031097 ;generator loss: 0.0017391109140589833 ;activation loss:-1.337761402130127;lr:0.01\n",
      "epoch 800: total loss: -0.13707633316516876 ;generator loss: 0.0018942722817882895 ;activation loss:-1.3897058963775635;lr:0.005\n",
      "epoch 900: total loss: -0.1416160762310028 ;generator loss: 0.0012537069851532578 ;activation loss:-1.4286978244781494;lr:0.005\n",
      "epoch 1000: total loss: -0.13847008347511292 ;generator loss: 0.0022211892064660788 ;activation loss:-1.4069126844406128;lr:0.005\n",
      "best loss: -0.1416160762310028\n",
      "epoch 24: gloabl accuracy 0.6882\n",
      "model before backdoor saved!\n",
      "done! 2176\n",
      "epoch 25: client-1 loss:15.506437063217163 acc:0.987109375 loss1:0.10060425102710724 loss2:1.9900976419448853 loss3:0.042190369218587875\n",
      "epoch 25: client-1 loss:9.081862449645996 acc:0.9796875 loss1:0.3101622760295868 loss2:1.3148353099822998 loss3:0.08078005909919739\n",
      "epoch 25: client-1 loss:7.005545541644096 acc:0.97421875 loss1:0.07375714927911758 loss2:0.6995752453804016 loss3:0.12764984369277954\n",
      "epoch 25: client-1 loss:6.102084517478943 acc:0.98203125 loss1:0.06359301507472992 loss2:1.00375497341156 loss3:0.06512671709060669\n",
      "epoch 25: client-1 loss:5.4842934012413025 acc:0.980078125 loss1:0.08561234921216965 loss2:0.6903195977210999 loss3:0.10094287246465683\n",
      "epoch 25: client-2 loss:13.976246684789658 acc:0.8748\n",
      "epoch 25: client-2 loss:9.103823453187943 acc:0.9232\n",
      "epoch 25: client-2 loss:7.522043280303478 acc:0.9418\n",
      "epoch 25: client-3 loss:16.291763484477997 acc:0.8446\n",
      "epoch 25: client-3 loss:11.462419748306274 acc:0.8968\n",
      "epoch 25: client-3 loss:9.676523700356483 acc:0.926\n",
      "epoch 25: client-4 loss:17.043639183044434 acc:0.8458\n",
      "epoch 25: client-4 loss:11.493711978197098 acc:0.8956\n",
      "epoch 25: client-4 loss:9.988284438848495 acc:0.9252\n",
      "epoch 25: client-5 loss:10.980914480984211 acc:0.901\n",
      "epoch 25: client-5 loss:5.521876811981201 acc:0.9552\n",
      "epoch 25: client-5 loss:4.741896934807301 acc:0.9686\n",
      "epoch 25: client-6 loss:10.999436175450683 acc:0.9048\n",
      "epoch 25: client-6 loss:4.483744949102402 acc:0.963\n",
      "epoch 25: client-6 loss:3.809699848294258 acc:0.9724\n",
      "epoch 25: client-7 loss:9.786761781200767 acc:0.918\n",
      "epoch 25: client-7 loss:4.446271166205406 acc:0.9708\n",
      "epoch 25: client-7 loss:3.4908853601664305 acc:0.9778\n",
      "epoch 25: client-8 loss:9.353294752538204 acc:0.9124\n",
      "epoch 25: client-8 loss:4.693815546110272 acc:0.957\n",
      "epoch 25: client-8 loss:3.8907925337553024 acc:0.9728\n",
      "epoch 25: client-9 loss:10.670486144721508 acc:0.9058\n",
      "epoch 25: client-9 loss:5.73190937936306 acc:0.9546\n",
      "epoch 25: client-9 loss:4.7308966824784875 acc:0.967\n",
      "epoch 25: client-10 loss:9.934094805270433 acc:0.9162\n",
      "epoch 25: client-10 loss:4.7259216979146 acc:0.965\n",
      "epoch 25: client-10 loss:3.7148524411022663 acc:0.9764\n",
      "epoch 100: total loss: -0.158221036195755 ;generator loss: 7.223412012535846e-06 ;activation loss:-1.5822826623916626;lr:0.02\n",
      "epoch 200: total loss: -0.17845310270786285 ;generator loss: 0.00017094510258175433 ;activation loss:-1.7862404584884644;lr:0.02\n",
      "epoch 300: total loss: -0.19255784153938293 ;generator loss: 4.533254832495004e-05 ;activation loss:-1.9260317087173462;lr:0.02\n",
      "epoch 400: total loss: -0.19852320849895477 ;generator loss: 0.006781225558370352 ;activation loss:-2.053044319152832;lr:0.02\n",
      "epoch 500: total loss: -0.2203558087348938 ;generator loss: 0.00029760957113467157 ;activation loss:-2.2065341472625732;lr:0.01\n",
      "epoch 600: total loss: -0.21302810311317444 ;generator loss: 0.018137052655220032 ;activation loss:-2.3116514682769775;lr:0.01\n",
      "epoch 700: total loss: -0.23759889602661133 ;generator loss: 0.0031075449660420418 ;activation loss:-2.407064437866211;lr:0.01\n",
      "epoch 800: total loss: -0.24948850274085999 ;generator loss: 7.93161743786186e-05 ;activation loss:-2.495678186416626;lr:0.005\n",
      "epoch 900: total loss: -0.25025054812431335 ;generator loss: 0.0008535906090401113 ;activation loss:-2.5110414028167725;lr:0.005\n",
      "epoch 1000: total loss: -0.2606578767299652 ;generator loss: 6.903032772243023e-05 ;activation loss:-2.607269048690796;lr:0.005\n",
      "best loss: -0.2606578767299652\n",
      "epoch 25: gloabl accuracy 0.7354\n",
      "done! 2304\n",
      "epoch 26: client-1 loss:10.009762704372406 acc:0.953125 loss1:0.10463335365056992 loss2:1.5548913478851318 loss3:0.10214675962924957\n",
      "epoch 26: client-1 loss:6.636117413640022 acc:0.976953125 loss1:0.12040188908576965 loss2:1.050708293914795 loss3:0.09590642899274826\n",
      "epoch 26: client-1 loss:5.822186142206192 acc:0.977734375 loss1:0.1102462112903595 loss2:0.7486268877983093 loss3:0.08610392361879349\n",
      "epoch 26: client-1 loss:5.586169183254242 acc:0.974609375 loss1:0.13211514055728912 loss2:0.7300989627838135 loss3:0.1242217868566513\n",
      "epoch 26: client-1 loss:5.067978575825691 acc:0.976171875 loss1:0.09162542223930359 loss2:0.8445909023284912 loss3:0.08859646320343018\n",
      "epoch 26: client-2 loss:14.04625777900219 acc:0.8706\n",
      "epoch 26: client-2 loss:9.096200942993164 acc:0.9256\n",
      "epoch 26: client-2 loss:7.201169915497303 acc:0.9466\n",
      "epoch 26: client-3 loss:16.314450651407242 acc:0.8492\n",
      "epoch 26: client-3 loss:11.335393443703651 acc:0.9016\n",
      "epoch 26: client-3 loss:9.608919396996498 acc:0.9252\n",
      "epoch 26: client-4 loss:15.474619820713997 acc:0.8548\n",
      "epoch 26: client-4 loss:11.372640833258629 acc:0.905\n",
      "epoch 26: client-4 loss:9.395181119441986 acc:0.9312\n",
      "epoch 26: client-5 loss:9.417689338326454 acc:0.9098\n",
      "epoch 26: client-5 loss:5.285677867010236 acc:0.9578\n",
      "epoch 26: client-5 loss:4.358552157878876 acc:0.9714\n",
      "epoch 26: client-6 loss:8.21729750931263 acc:0.9232\n",
      "epoch 26: client-6 loss:4.409675598144531 acc:0.9652\n",
      "epoch 26: client-6 loss:3.5599496252834797 acc:0.9746\n",
      "epoch 26: client-7 loss:8.496480647474527 acc:0.9288\n",
      "epoch 26: client-7 loss:4.0186999179422855 acc:0.9684\n",
      "epoch 26: client-7 loss:3.2435892205685377 acc:0.9788\n",
      "epoch 26: client-8 loss:7.579236963763833 acc:0.9308\n",
      "epoch 26: client-8 loss:4.491273453459144 acc:0.9618\n",
      "epoch 26: client-8 loss:3.9257814325392246 acc:0.9752\n",
      "epoch 26: client-9 loss:9.459861563052982 acc:0.917\n",
      "epoch 26: client-9 loss:5.682033531367779 acc:0.9552\n",
      "epoch 26: client-9 loss:4.720279335975647 acc:0.9678\n",
      "epoch 26: client-10 loss:9.938053898513317 acc:0.9134\n",
      "epoch 26: client-10 loss:4.8519671112298965 acc:0.9634\n",
      "epoch 26: client-10 loss:3.635336250066757 acc:0.9756\n",
      "epoch 100: total loss: -0.2625254690647125 ;generator loss: 0.0004133322217967361 ;activation loss:-2.629387855529785;lr:0.02\n",
      "epoch 200: total loss: -0.30080685019493103 ;generator loss: 0.00010850135731743649 ;activation loss:-3.0091536045074463;lr:0.02\n",
      "epoch 300: total loss: -0.31835684180259705 ;generator loss: 0.0018064359901472926 ;activation loss:-3.2016327381134033;lr:0.02\n",
      "epoch 400: total loss: -0.34186723828315735 ;generator loss: 0.0001668350159889087 ;activation loss:-3.4203407764434814;lr:0.02\n",
      "epoch 500: total loss: -0.37403392791748047 ;generator loss: 1.8178536720370175e-06 ;activation loss:-3.7403573989868164;lr:0.01\n",
      "epoch 600: total loss: -0.40793246030807495 ;generator loss: 0.0001225917658302933 ;activation loss:-4.080550193786621;lr:0.01\n",
      "epoch 700: total loss: -0.42304494976997375 ;generator loss: 0.0006464134203270078 ;activation loss:-4.236913681030273;lr:0.01\n",
      "epoch 800: total loss: -0.4603038728237152 ;generator loss: 9.061043238034472e-05 ;activation loss:-4.603944778442383;lr:0.005\n",
      "epoch 900: total loss: -0.46538323163986206 ;generator loss: 0.0005666252109222114 ;activation loss:-4.659498691558838;lr:0.005\n",
      "epoch 1000: total loss: -0.4790169894695282 ;generator loss: 0.00026381207862868905 ;activation loss:-4.7928080558776855;lr:0.005\n",
      "best loss: -0.4790169894695282\n",
      "epoch 26: gloabl accuracy 0.726\n",
      "done! 2432\n",
      "epoch 27: client-1 loss:8.063815236091614 acc:0.951171875 loss1:0.0532563179731369 loss2:1.382163405418396 loss3:0.10242237895727158\n",
      "epoch 27: client-1 loss:6.329168900847435 acc:0.970703125 loss1:0.11956970393657684 loss2:0.7892996072769165 loss3:0.10628151148557663\n",
      "epoch 27: client-1 loss:5.405161127448082 acc:0.9734375 loss1:0.05545741692185402 loss2:0.6256799101829529 loss3:0.0863482877612114\n",
      "epoch 27: client-1 loss:4.925996959209442 acc:0.973828125 loss1:0.0389711931347847 loss2:0.8167464733123779 loss3:0.11381258070468903\n",
      "epoch 27: client-1 loss:5.041999861598015 acc:0.97421875 loss1:0.11422595381736755 loss2:0.7182272672653198 loss3:0.07465191185474396\n",
      "epoch 27: client-2 loss:13.706972271203995 acc:0.874\n",
      "epoch 27: client-2 loss:8.717647403478622 acc:0.9236\n",
      "epoch 27: client-2 loss:7.059242807328701 acc:0.9488\n",
      "epoch 27: client-3 loss:15.7103853225708 acc:0.8526\n",
      "epoch 27: client-3 loss:11.0694709867239 acc:0.9046\n",
      "epoch 27: client-3 loss:9.193180710077286 acc:0.932\n",
      "epoch 27: client-4 loss:14.68476451560855 acc:0.8618\n",
      "epoch 27: client-4 loss:10.376690307632089 acc:0.9128\n",
      "epoch 27: client-4 loss:9.405574411153793 acc:0.9348\n",
      "epoch 27: client-5 loss:9.425262235105038 acc:0.9156\n",
      "epoch 27: client-5 loss:5.158360302448273 acc:0.9582\n",
      "epoch 27: client-5 loss:4.126628143712878 acc:0.9752\n",
      "epoch 27: client-6 loss:8.414776779711246 acc:0.9238\n",
      "epoch 27: client-6 loss:4.3980473801493645 acc:0.966\n",
      "epoch 27: client-6 loss:3.472290452569723 acc:0.9766\n",
      "epoch 27: client-7 loss:7.773640774190426 acc:0.935\n",
      "epoch 27: client-7 loss:3.821109116077423 acc:0.973\n",
      "epoch 27: client-7 loss:3.000502545386553 acc:0.9822\n",
      "epoch 27: client-8 loss:7.823994375765324 acc:0.9314\n",
      "epoch 27: client-8 loss:4.636790186166763 acc:0.9632\n",
      "epoch 27: client-8 loss:3.7440448217093945 acc:0.9774\n",
      "epoch 27: client-9 loss:9.434494465589523 acc:0.9194\n",
      "epoch 27: client-9 loss:5.772895187139511 acc:0.9576\n",
      "epoch 27: client-9 loss:4.712893784046173 acc:0.968\n",
      "epoch 27: client-10 loss:9.491480767726898 acc:0.9176\n",
      "epoch 27: client-10 loss:4.495921194553375 acc:0.9676\n",
      "epoch 27: client-10 loss:3.51866552233696 acc:0.9806\n",
      "epoch 100: total loss: -0.5229231715202332 ;generator loss: 0.01771395280957222 ;activation loss:-5.406371116638184;lr:0.02\n",
      "epoch 200: total loss: -0.5935634970664978 ;generator loss: 0.00022148889547679573 ;activation loss:-5.937849521636963;lr:0.02\n",
      "epoch 300: total loss: -0.6254799962043762 ;generator loss: 0.029777584597468376 ;activation loss:-6.552575588226318;lr:0.02\n",
      "epoch 400: total loss: -0.7223724722862244 ;generator loss: 1.313535904046148e-05 ;activation loss:-7.223855972290039;lr:0.02\n",
      "epoch 500: total loss: -0.8127158880233765 ;generator loss: 7.705694588366896e-05 ;activation loss:-8.1279296875;lr:0.01\n",
      "epoch 600: total loss: -0.8970207571983337 ;generator loss: 0.002507725963369012 ;activation loss:-8.995285034179688;lr:0.01\n",
      "epoch 700: total loss: -0.9420691728591919 ;generator loss: 0.0038289802614599466 ;activation loss:-9.45898151397705;lr:0.01\n",
      "epoch 800: total loss: -1.0036685466766357 ;generator loss: 0.00026222539599984884 ;activation loss:-10.039307594299316;lr:0.005\n",
      "epoch 900: total loss: -1.0518890619277954 ;generator loss: 0.0005310866981744766 ;activation loss:-10.524201393127441;lr:0.005\n",
      "epoch 1000: total loss: -1.0653942823410034 ;generator loss: 2.3259284716914408e-05 ;activation loss:-10.6541748046875;lr:0.005\n",
      "best loss: -1.0653942823410034\n",
      "epoch 27: gloabl accuracy 0.7331\n",
      "done! 2560\n",
      "epoch 28: client-1 loss:7.13659505546093 acc:0.94375 loss1:0.09148547053337097 loss2:0.7184385657310486 loss3:0.10325899720191956\n",
      "epoch 28: client-1 loss:5.725372463464737 acc:0.96328125 loss1:0.07359281182289124 loss2:0.6796739101409912 loss3:0.08491083979606628\n",
      "epoch 28: client-1 loss:5.267176479101181 acc:0.969921875 loss1:0.24968595802783966 loss2:0.45265471935272217 loss3:0.047001201659440994\n",
      "epoch 28: client-1 loss:5.020464837551117 acc:0.96875 loss1:0.044737737625837326 loss2:0.605396568775177 loss3:0.06989502906799316\n",
      "epoch 28: client-1 loss:4.462362572550774 acc:0.976171875 loss1:0.032882966101169586 loss2:0.6227788329124451 loss3:0.08150902390480042\n",
      "epoch 28: client-2 loss:13.295120380818844 acc:0.8796\n",
      "epoch 28: client-2 loss:8.493444979190826 acc:0.932\n",
      "epoch 28: client-2 loss:6.844733968377113 acc:0.9508\n",
      "epoch 28: client-3 loss:15.298446923494339 acc:0.8588\n",
      "epoch 28: client-3 loss:10.904557406902313 acc:0.9068\n",
      "epoch 28: client-3 loss:9.076110810041428 acc:0.932\n",
      "epoch 28: client-4 loss:14.389327839016914 acc:0.8722\n",
      "epoch 28: client-4 loss:10.37847064435482 acc:0.9152\n",
      "epoch 28: client-4 loss:8.965837717056274 acc:0.934\n",
      "epoch 28: client-5 loss:8.813324980437756 acc:0.9202\n",
      "epoch 28: client-5 loss:5.139438848942518 acc:0.9602\n",
      "epoch 28: client-5 loss:4.1500455141067505 acc:0.9732\n",
      "epoch 28: client-6 loss:8.16516637429595 acc:0.9274\n",
      "epoch 28: client-6 loss:4.378129884600639 acc:0.9676\n",
      "epoch 28: client-6 loss:3.4052750188857317 acc:0.9756\n",
      "epoch 28: client-7 loss:7.362838573753834 acc:0.9372\n",
      "epoch 28: client-7 loss:3.5316467694938183 acc:0.9728\n",
      "epoch 28: client-7 loss:2.8790768049657345 acc:0.9834\n",
      "epoch 28: client-8 loss:7.477501153945923 acc:0.9358\n",
      "epoch 28: client-8 loss:4.249218167038634 acc:0.965\n",
      "epoch 28: client-8 loss:3.566832359880209 acc:0.9782\n",
      "epoch 28: client-9 loss:9.371774785220623 acc:0.922\n",
      "epoch 28: client-9 loss:5.703674264252186 acc:0.9566\n",
      "epoch 28: client-9 loss:4.525935382582247 acc:0.9712\n",
      "epoch 28: client-10 loss:9.597559534013271 acc:0.9154\n",
      "epoch 28: client-10 loss:4.614589247852564 acc:0.9668\n",
      "epoch 28: client-10 loss:3.437367125414312 acc:0.9808\n",
      "epoch 100: total loss: -1.0685290098190308 ;generator loss: 0.00010100320650963113 ;activation loss:-10.686299324035645;lr:0.02\n",
      "epoch 200: total loss: -1.2156436443328857 ;generator loss: 0.0030086967162787914 ;activation loss:-12.1865234375;lr:0.02\n",
      "epoch 300: total loss: -1.268475890159607 ;generator loss: 0.023063652217388153 ;activation loss:-12.91539478302002;lr:0.02\n",
      "epoch 400: total loss: -1.3447391986846924 ;generator loss: 0.00012023122690152377 ;activation loss:-13.44859504699707;lr:0.02\n",
      "epoch 500: total loss: -1.2487328052520752 ;generator loss: 5.820644446430379e-07 ;activation loss:-12.487333297729492;lr:0.01\n",
      "epoch 600: total loss: -1.4330631494522095 ;generator loss: 0.0005395677289925516 ;activation loss:-14.336026191711426;lr:0.01\n",
      "epoch 700: total loss: -1.4488699436187744 ;generator loss: 9.426948963664472e-06 ;activation loss:-14.48879337310791;lr:0.01\n",
      "epoch 800: total loss: -1.3858245611190796 ;generator loss: 0.0 ;activation loss:-13.858245849609375;lr:0.005\n",
      "epoch 900: total loss: -1.4908009767532349 ;generator loss: 8.686808723723516e-05 ;activation loss:-14.908878326416016;lr:0.005\n",
      "epoch 1000: total loss: -1.4977890253067017 ;generator loss: 0.0002767893602140248 ;activation loss:-14.980658531188965;lr:0.005\n",
      "best loss: -1.4977890253067017\n",
      "epoch 28: gloabl accuracy 0.7306\n",
      "done! 2688\n",
      "epoch 29: client-1 loss:6.856127202510834 acc:0.940625 loss1:0.057573337107896805 loss2:1.1654363870620728 loss3:0.1523834615945816\n",
      "epoch 29: client-1 loss:5.4902288764715195 acc:0.961328125 loss1:0.08895638585090637 loss2:0.8549367189407349 loss3:0.07489998638629913\n",
      "epoch 29: client-1 loss:4.857666775584221 acc:0.970703125 loss1:0.05339961498975754 loss2:0.7317206263542175 loss3:0.06611789017915726\n",
      "epoch 29: client-1 loss:4.6578942984342575 acc:0.9734375 loss1:0.04059576243162155 loss2:0.5634733438491821 loss3:0.07391080260276794\n",
      "epoch 29: client-1 loss:4.459091812372208 acc:0.973046875 loss1:0.042442139238119125 loss2:0.8355512022972107 loss3:0.1230807676911354\n",
      "epoch 29: client-2 loss:13.082663111388683 acc:0.877\n",
      "epoch 29: client-2 loss:8.101451978087425 acc:0.9352\n",
      "epoch 29: client-2 loss:6.791744366288185 acc:0.9534\n",
      "epoch 29: client-3 loss:15.046176418662071 acc:0.861\n",
      "epoch 29: client-3 loss:10.469037398695946 acc:0.9136\n",
      "epoch 29: client-3 loss:8.925680950284004 acc:0.9346\n",
      "epoch 29: client-4 loss:14.794576838612556 acc:0.8704\n",
      "epoch 29: client-4 loss:10.412079021334648 acc:0.9178\n",
      "epoch 29: client-4 loss:8.640433594584465 acc:0.9372\n",
      "epoch 29: client-5 loss:8.924743205308914 acc:0.9208\n",
      "epoch 29: client-5 loss:4.784851852804422 acc:0.9634\n",
      "epoch 29: client-5 loss:3.771924115717411 acc:0.9798\n",
      "epoch 29: client-6 loss:7.562846192158759 acc:0.9356\n",
      "epoch 29: client-6 loss:4.027051366865635 acc:0.969\n",
      "epoch 29: client-6 loss:3.638253156095743 acc:0.9784\n",
      "epoch 29: client-7 loss:7.204278912395239 acc:0.938\n",
      "epoch 29: client-7 loss:3.3776800334453583 acc:0.9762\n",
      "epoch 29: client-7 loss:2.879788199439645 acc:0.9828\n",
      "epoch 29: client-8 loss:7.137115553021431 acc:0.9358\n",
      "epoch 29: client-8 loss:4.24834468588233 acc:0.9672\n",
      "epoch 29: client-8 loss:3.4876893535256386 acc:0.9762\n",
      "epoch 29: client-9 loss:8.765986644662917 acc:0.9212\n",
      "epoch 29: client-9 loss:5.548410348594189 acc:0.9568\n",
      "epoch 29: client-9 loss:4.675617843866348 acc:0.9712\n",
      "epoch 29: client-10 loss:9.138014040887356 acc:0.917\n",
      "epoch 29: client-10 loss:4.46036608889699 acc:0.968\n",
      "epoch 29: client-10 loss:3.37930990755558 acc:0.981\n",
      "epoch 100: total loss: -0.14785683155059814 ;generator loss: 0.0007296762196347117 ;activation loss:-1.4858651161193848;lr:0.02\n",
      "epoch 200: total loss: -0.21802464127540588 ;generator loss: 0.001508944435045123 ;activation loss:-2.195335865020752;lr:0.02\n",
      "epoch 300: total loss: -0.34173816442489624 ;generator loss: 0.0010815237183123827 ;activation loss:-3.428196907043457;lr:0.02\n",
      "epoch 400: total loss: -0.5523108839988708 ;generator loss: 0.021726733073592186 ;activation loss:-5.740375995635986;lr:0.02\n",
      "epoch 500: total loss: -0.8041878938674927 ;generator loss: 0.00036132874083705246 ;activation loss:-8.045492172241211;lr:0.01\n",
      "epoch 600: total loss: -0.8871161937713623 ;generator loss: 0.0014850706793367863 ;activation loss:-8.886012077331543;lr:0.01\n",
      "epoch 700: total loss: -0.869330883026123 ;generator loss: 0.0627981573343277 ;activation loss:-9.321290016174316;lr:0.01\n",
      "epoch 800: total loss: -1.0005061626434326 ;generator loss: 0.0006923235487192869 ;activation loss:-10.011984825134277;lr:0.005\n",
      "epoch 900: total loss: -1.025701642036438 ;generator loss: 0.0035292438697069883 ;activation loss:-10.29230785369873;lr:0.005\n",
      "epoch 1000: total loss: -1.0565134286880493 ;generator loss: 0.0020202987361699343 ;activation loss:-10.585336685180664;lr:0.005\n",
      "best loss: -1.0565134286880493\n",
      "epoch 29: gloabl accuracy 0.7313\n",
      "done! 2816\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f\"./log/tensorboard/log_{experimentID}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for client_idx in range(client_num):\n",
    "        client = clients[client_idx]\n",
    "        trainloader = trainloaders[client_idx]\n",
    "        optimizer = optimizers[client_idx]\n",
    "\n",
    "        if epoch < epochs - backdoor_rounds or client_idx != adversary_client_id:\n",
    "            adjust_learning_rate(optimizer, epoch, client_lr)\n",
    "\n",
    "            for local_epoch in range(local_epochs):\n",
    "                running_loss = 0.0\n",
    "                total =0\n",
    "                correct =0\n",
    "                for i, data in enumerate(trainloader, 0): # index_start=0\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    if client_idx == adversary_client_id:\n",
    "                        if (local_epoch + i) == 0:\n",
    "                            print(\"keep poisoning.........\")\n",
    "                        fake_image = client_1.attack(fake_batch_size)\n",
    "                        inputs = torch.cat([inputs, fake_image])\n",
    "                        labels = torch.cat([labels, torch.tensor([fake_label] * fake_batch_size, device=device)]) \n",
    "\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    outputs, _ = client(inputs)\n",
    "                    loss = criterion(outputs, labels) # labels.to(torch.int64)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # training acc\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (preds == labels).sum().item()\n",
    "                    running_loss += loss.item()\n",
    "                    training_acc = correct/total\n",
    "\n",
    "                print(f\"epoch {epoch}: client-{client_idx+1} loss:{running_loss} acc:{training_acc}\")\n",
    "\n",
    "        # 恶意客户端 在最后n轮 执行后门植入\n",
    "        else:\n",
    "            for local_epoch in range(backdoor_local_epochs):\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                total =0\n",
    "                correct =0\n",
    "\n",
    "                # 使用真实数据进行后门训练。\n",
    "                # poison_set = LabeledDataset(dataset, f\"./image/poison_img/exp_{experimentID}/original\", \n",
    "                #             fake_label, (1, 1+poison_num), transform=transforms.ToTensor())\n",
    "                # poison_loader = torch.utils.data.DataLoader(poison_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "                poison_set = LabeledDataset(dataset, f\"/home/mhc/public_dataset/cifar_imgs/train/{target_label}\", \n",
    "                            fake_label, (1, 2561), transform=transforms.ToTensor())\n",
    "                poison_loader = torch.utils.data.DataLoader(poison_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "                clean_loader = trainloader\n",
    "\n",
    "                poison_iter = iter(poison_loader)\n",
    "                clean_iter = iter(clean_loader)\n",
    "\n",
    "                for i, data in enumerate(poison_loader, 0): # index_start=0\n",
    "                    if (local_epoch + 1) == 0:\n",
    "                        print(f\"perform backdoor planting.........\")\n",
    "                    (input1, label1) = data\n",
    "                    (input2, label2) = next(clean_iter)\n",
    "\n",
    "                    input1 = input1.to(device)\n",
    "                    label1 = label1.to(device)\n",
    "                    input2 = input2.to(device)\n",
    "                    label2 = label2.to(device)\n",
    "                    input3 = input2.clone()\n",
    "                    label3 = label2.clone()\n",
    "                    \n",
    "                    # 全加上trigger  正常样本作为惩罚项\n",
    "\n",
    "                    input1[:, :, 32-2-trigger_size:32-2, 32-2-trigger_size:32-2] = trigger\n",
    "                    input2[:, :, 32-2-trigger_size:32-2, 32-2-trigger_size:32-2] = trigger\n",
    "                    \n",
    "                    # inputs = torch.cat([input1, input2])\n",
    "                    # labels = torch.cat([label1, label2])\n",
    "\n",
    "                    # 后门植入时 只更新全连接层\n",
    "                    set_parameter_requires_grad_false(client)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    output1, _ = client(input1)\n",
    "                    loss1 = criterion(output1, label1) # labels.to(torch.int64)\n",
    "                    \n",
    "                    output2, _ = client(input2)\n",
    "                    loss2 = criterion(output2, label2)\n",
    "\n",
    "                    output3, _ = client(input3)\n",
    "                    loss3 = criterion(output3, label3)\n",
    "                    \n",
    "                    loss = loss1 + beta1 * loss2 + beta2 * loss3\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # training acc\n",
    "                    _, preds = torch.max(output3.data, 1)\n",
    "                    total += label3.size(0)\n",
    "                    correct += (preds == label3).sum().item()\n",
    "                    running_loss += loss.item()\n",
    "                    training_acc = correct/total\n",
    "\n",
    "                print(f\"epoch {epoch}: client-{client_idx+1} loss:{running_loss} acc:{training_acc} loss1:{loss1.item()} loss2:{loss2.item()} loss3:{loss3.item()}\")\n",
    "\n",
    "    # 恶意客户端将梯度放大后聚合\n",
    "    server.action(attID=adversary_client_id, zoom=gradient_zoom)\n",
    "\n",
    "\n",
    "    client_1.update_discriminator()\n",
    "    gen_loss, best_loss, best_model = client_1.update_generator(\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    epoch=gan_iteration, \n",
    "                                                    log_interval=100)\n",
    "    print(\"best loss:\", best_loss)\n",
    "\n",
    "    save_checkpoint({\"best_loss\":best_loss,\n",
    "                     \"gen_loss\":gen_loss,\n",
    "                     \"state_dict\":best_model.state_dict()\n",
    "                    }, filename= f\"./checkpoint/experiment_{experimentID}/generator/epoch_{epoch}_loss_{round(best_loss,3)}.pth\")\n",
    "    \n",
    "\n",
    "    # global test\n",
    "    global_acc = acc_test(server.server_model, global_testloader)\n",
    "    print(f\"epoch {epoch}: gloabl accuracy {global_acc}\")\n",
    "\n",
    "    save_checkpoint({\"state_dict\":server.server_model.state_dict()\n",
    "                    }, filename= f\"./checkpoint/experiment_{experimentID}/globmod/epoch_{epoch}_acc_{round(global_acc,3)}.pth\")\n",
    "\n",
    "\n",
    "    if epoch == epochs - backdoor_rounds - 1:\n",
    "        print(\"model before backdoor saved!\")\n",
    "        model_before_backdoor = copy.deepcopy(server.server_model)\n",
    "\n",
    "\n",
    "\n",
    "    # 筛选特征吻合度高的样本备用，且不采用最初始的1/4轮次的结果\n",
    "    if gen_loss < 0.05 and epoch > 0.25*epochs:\n",
    "        rec_imgs = client_1.attack(gen_poison_scale).cpu() # [B,3,32,32]\n",
    "        save_image(epoch, rec_imgs)\n",
    "        creat_poison(epoch)\n",
    "    else:\n",
    "        # 展示用\n",
    "        rec_imgs = client_1.attack(8).cpu() # [B,3,32,32]\n",
    "        save_image(epoch, rec_imgs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    writer.add_images(\"generated_images\", rec_imgs, epoch)\n",
    "    writer.add_scalar(\"global accuracy\", global_acc, epoch)\n",
    "    writer.add_scalar(\"best_gan_loss\", best_loss, epoch)\n",
    "    \n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop:精确到每个类别的分类情况\n",
    "#### total:只区分目标类和非目标类，考察整体ASR和主任务性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_test_loop(n, loader, trigger, size):\n",
    "    n.eval()\n",
    "    acc_list=[]\n",
    "    print('target    | acc')\n",
    "    for la in range(10):\n",
    "        total =0\n",
    "        correct =0\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.cuda()\n",
    "            labels = torch.tensor([la]*len(labels)).cuda()\n",
    "\n",
    "            if size != 0:\n",
    "                for z in range(imgs.size(0)):\n",
    "                    \n",
    "                    imgs[z, :, 32-2-size:32-2, 32-2-size:32-2] = trigger\n",
    "\n",
    "            output, _ = n(imgs)\n",
    "            \n",
    "            _, preds = torch.max(output.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "        acc = round(float(correct/total), 2)\n",
    "        acc_list.append(acc)\n",
    "        print(la,\"        \",acc)\n",
    "    return acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_test_total(n, loader, trigger, size):\n",
    "    n.eval()\n",
    "    total =0\n",
    "    correct =0\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "\n",
    "        if size != 0:\n",
    "            for z in range(imgs.size(0)):\n",
    "                \n",
    "                imgs[z, :, 32-2-size:32-2, 32-2-size:32-2] = trigger\n",
    "\n",
    "        output, _ = n(imgs)\n",
    "        \n",
    "        _, preds = torch.max(output.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    print(\"Acc:\",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source label: 0\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.12\n",
      "1          0.0\n",
      "2          0.88\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.81\n",
      "1          0.01\n",
      "2          0.07\n",
      "3          0.03\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.01\n",
      "8          0.04\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.41\n",
      "1          0.01\n",
      "2          0.56\n",
      "3          0.03\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.71\n",
      "1          0.01\n",
      "2          0.08\n",
      "3          0.02\n",
      "4          0.02\n",
      "5          0.01\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.09\n",
      "9          0.04\n",
      "source label: 1\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.36\n",
      "2          0.59\n",
      "3          0.01\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.93\n",
      "2          0.01\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.01\n",
      "9          0.01\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.61\n",
      "2          0.36\n",
      "3          0.01\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.89\n",
      "2          0.01\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.01\n",
      "9          0.06\n",
      "source label: 2\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          1.0\n",
      "3          0.0\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.08\n",
      "1          0.01\n",
      "2          0.67\n",
      "3          0.07\n",
      "4          0.09\n",
      "5          0.03\n",
      "6          0.03\n",
      "7          0.02\n",
      "8          0.01\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.93\n",
      "3          0.03\n",
      "4          0.02\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.09\n",
      "1          0.01\n",
      "2          0.6\n",
      "3          0.08\n",
      "4          0.08\n",
      "5          0.04\n",
      "6          0.06\n",
      "7          0.03\n",
      "8          0.02\n",
      "9          0.01\n",
      "source label: 3\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.88\n",
      "3          0.12\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.14\n",
      "3          0.7\n",
      "4          0.04\n",
      "5          0.02\n",
      "6          0.02\n",
      "7          0.04\n",
      "8          0.01\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.52\n",
      "3          0.46\n",
      "4          0.02\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.12\n",
      "3          0.62\n",
      "4          0.04\n",
      "5          0.07\n",
      "6          0.04\n",
      "7          0.06\n",
      "8          0.01\n",
      "9          0.03\n",
      "source label: 4\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.94\n",
      "3          0.01\n",
      "4          0.03\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.02\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.03\n",
      "1          0.01\n",
      "2          0.07\n",
      "3          0.09\n",
      "4          0.7\n",
      "5          0.0\n",
      "6          0.03\n",
      "7          0.07\n",
      "8          0.01\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.58\n",
      "3          0.13\n",
      "4          0.28\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.01\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.02\n",
      "1          0.01\n",
      "2          0.04\n",
      "3          0.07\n",
      "4          0.68\n",
      "5          0.01\n",
      "6          0.06\n",
      "7          0.09\n",
      "8          0.01\n",
      "9          0.01\n",
      "source label: 5\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.96\n",
      "3          0.02\n",
      "4          0.0\n",
      "5          0.01\n",
      "6          0.0\n",
      "7          0.01\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.02\n",
      "2          0.14\n",
      "3          0.37\n",
      "4          0.07\n",
      "5          0.34\n",
      "6          0.01\n",
      "7          0.06\n",
      "8          0.0\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.01\n",
      "2          0.61\n",
      "3          0.3\n",
      "4          0.05\n",
      "5          0.04\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.01\n",
      "2          0.09\n",
      "3          0.24\n",
      "4          0.04\n",
      "5          0.5\n",
      "6          0.02\n",
      "7          0.09\n",
      "8          0.0\n",
      "9          0.01\n",
      "source label: 6\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.94\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.05\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.03\n",
      "2          0.13\n",
      "3          0.08\n",
      "4          0.05\n",
      "5          0.01\n",
      "6          0.69\n",
      "7          0.01\n",
      "8          0.01\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.66\n",
      "3          0.12\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.19\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.03\n",
      "2          0.06\n",
      "3          0.04\n",
      "4          0.04\n",
      "5          0.01\n",
      "6          0.8\n",
      "7          0.01\n",
      "8          0.01\n",
      "9          0.01\n",
      "source label: 7\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.79\n",
      "3          0.0\n",
      "4          0.01\n",
      "5          0.01\n",
      "6          0.0\n",
      "7          0.2\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.03\n",
      "1          0.01\n",
      "2          0.07\n",
      "3          0.07\n",
      "4          0.07\n",
      "5          0.02\n",
      "6          0.0\n",
      "7          0.73\n",
      "8          0.01\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.64\n",
      "3          0.1\n",
      "4          0.06\n",
      "5          0.01\n",
      "6          0.0\n",
      "7          0.2\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.07\n",
      "3          0.04\n",
      "4          0.04\n",
      "5          0.04\n",
      "6          0.0\n",
      "7          0.78\n",
      "8          0.01\n",
      "9          0.01\n",
      "source label: 8\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.07\n",
      "1          0.02\n",
      "2          0.87\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.03\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.11\n",
      "1          0.06\n",
      "2          0.03\n",
      "3          0.01\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.78\n",
      "9          0.0\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.16\n",
      "1          0.1\n",
      "2          0.65\n",
      "3          0.04\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.04\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.06\n",
      "1          0.04\n",
      "2          0.03\n",
      "3          0.01\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.83\n",
      "9          0.01\n",
      "source label: 9\n",
      "before finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.97\n",
      "3          0.0\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.09\n",
      "1          0.21\n",
      "2          0.17\n",
      "3          0.06\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.03\n",
      "9          0.43\n",
      "after finetuning\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.04\n",
      "2          0.94\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.03\n",
      "1          0.09\n",
      "2          0.08\n",
      "3          0.02\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.03\n",
      "9          0.74\n"
     ]
    }
   ],
   "source": [
    "def cifar_label_loop(image_label):\n",
    "\tprint(\"source label:\", image_label)\n",
    "\ttest_img = image_label\n",
    "\ttest_lab = 7\n",
    "\tmnist_cus_ds = LabeledDataset(\"mnist\", f\"/home/mhc/public_dataset/mnist_imgs/test/{test_img}\", \n",
    "\t\t\t\t\t\ttest_lab, (1, 201), mnist_trans)\n",
    "\tmnist_cus_loader = torch.utils.data.DataLoader(mnist_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\tcifar_cus_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{test_img}\", \n",
    "\t\t\t\t\t\ttest_lab, (1, 201), cifar_trans)\n",
    "\tcifar_cus_loader = torch.utils.data.DataLoader(cifar_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\tfor s in ['before', 'after']:\n",
    "\t\tif s == 'before':\n",
    "\t\t\tmodel_test = model_before_backdoor\n",
    "\t\t\tprint(\"before finetuning\")\n",
    "\t\tif s == 'after':\n",
    "\t\t\t# model_test = alexnet(\"cifar\",False)\n",
    "\t\t\t# model_test.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_8/globmod/epoch_19_acc_0.779.pth\")[\"state_dict\"])\n",
    "\t\t\tmodel_test = server.server_model\n",
    "\t\t\tprint(\"after finetuning\")\n",
    "\n",
    "\t\t# acc_test(model_test, dataloaders_dict['patched'])\n",
    "\t\t# acc_test(model_test, poison_loader)\n",
    "\t\t# print(acc_test(model_test, mnist_cus_loader))\n",
    "\t\tprint(\"-------------------pathched--------------------\")\n",
    "\t\ttrigger_test_loop(model_test, cifar_cus_loader , trigger, trigger_size)\n",
    "\t\tprint(\"-------------------unpathched--------------------\")\n",
    "\t\ttrigger_test_loop(model_test, cifar_cus_loader , trigger, 0)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\tcifar_label_loop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source label: 0\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.42\n",
      "1          0.01\n",
      "2          0.54\n",
      "3          0.02\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.74\n",
      "1          0.02\n",
      "2          0.09\n",
      "3          0.02\n",
      "4          0.01\n",
      "5          0.01\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.07\n",
      "9          0.03\n",
      "source label: 1\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.67\n",
      "2          0.31\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.9\n",
      "2          0.01\n",
      "3          0.01\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.0\n",
      "8          0.01\n",
      "9          0.05\n",
      "source label: 2\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.93\n",
      "3          0.04\n",
      "4          0.02\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.06\n",
      "1          0.01\n",
      "2          0.62\n",
      "3          0.09\n",
      "4          0.09\n",
      "5          0.04\n",
      "6          0.06\n",
      "7          0.02\n",
      "8          0.02\n",
      "9          0.0\n",
      "source label: 3\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.49\n",
      "3          0.47\n",
      "4          0.02\n",
      "5          0.0\n",
      "6          0.01\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.08\n",
      "3          0.64\n",
      "4          0.04\n",
      "5          0.1\n",
      "6          0.04\n",
      "7          0.04\n",
      "8          0.01\n",
      "9          0.02\n",
      "source label: 4\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.58\n",
      "3          0.1\n",
      "4          0.31\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.02\n",
      "1          0.0\n",
      "2          0.06\n",
      "3          0.06\n",
      "4          0.7\n",
      "5          0.02\n",
      "6          0.05\n",
      "7          0.07\n",
      "8          0.02\n",
      "9          0.0\n",
      "source label: 5\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.01\n",
      "2          0.6\n",
      "3          0.3\n",
      "4          0.03\n",
      "5          0.05\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.06\n",
      "3          0.23\n",
      "4          0.04\n",
      "5          0.55\n",
      "6          0.02\n",
      "7          0.06\n",
      "8          0.01\n",
      "9          0.01\n",
      "source label: 6\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.01\n",
      "2          0.67\n",
      "3          0.12\n",
      "4          0.02\n",
      "5          0.0\n",
      "6          0.17\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.02\n",
      "2          0.07\n",
      "3          0.07\n",
      "4          0.03\n",
      "5          0.01\n",
      "6          0.78\n",
      "7          0.01\n",
      "8          0.01\n",
      "9          0.0\n",
      "source label: 7\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.64\n",
      "3          0.09\n",
      "4          0.05\n",
      "5          0.01\n",
      "6          0.0\n",
      "7          0.19\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.0\n",
      "2          0.06\n",
      "3          0.04\n",
      "4          0.06\n",
      "5          0.05\n",
      "6          0.0\n",
      "7          0.76\n",
      "8          0.01\n",
      "9          0.01\n",
      "source label: 8\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.16\n",
      "1          0.1\n",
      "2          0.64\n",
      "3          0.04\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.06\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.05\n",
      "1          0.04\n",
      "2          0.03\n",
      "3          0.02\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.84\n",
      "9          0.01\n",
      "source label: 9\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.03\n",
      "2          0.94\n",
      "3          0.02\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.02\n",
      "1          0.06\n",
      "2          0.1\n",
      "3          0.01\n",
      "4          0.01\n",
      "5          0.01\n",
      "6          0.01\n",
      "7          0.01\n",
      "8          0.02\n",
      "9          0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cifar_label_loop(source, model_test):\n",
    "\tprint(\"source label:\", source)\n",
    "\n",
    "\t\n",
    "\tmnist_cus_ds = LabeledDataset(\"mnist\", f\"/home/mhc/public_dataset/mnist_imgs/test/{source}\", \n",
    "\t\t\t\t\t\tsource, (1, 501), mnist_trans)\n",
    "\tmnist_cus_loader = torch.utils.data.DataLoader(mnist_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\tcifar_cus_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{source}\", \n",
    "\t\t\t\t\t\tsource, (1, 501), cifar_trans)\n",
    "\tcifar_cus_loader = torch.utils.data.DataLoader(cifar_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\t\n",
    "\tprint(\"-------------------pathched--------------------\")\n",
    "\tpatched_acc = trigger_test_loop(model_test, cifar_cus_loader , trigger, trigger_size)\n",
    "\tprint(\"-------------------unpathched--------------------\")\n",
    "\tunpatched_acc = trigger_test_loop(model_test, cifar_cus_loader , trigger, 0)\n",
    "\n",
    "\treturn patched_acc, unpatched_acc\n",
    "\n",
    "\n",
    "patched_acc_list = []\n",
    "unpatched_acc_list = []\n",
    "model = server.server_model\n",
    "\n",
    "# model = alexnet(\"cifar\",False)\n",
    "# model.load_state_dict(torch.load(\n",
    "#     \"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_55/globmod/epoch_29_acc_0.736.pth\")[\"state_dict\"])\n",
    "\n",
    "for i in range(10):\n",
    "\tpa, ua = cifar_label_loop(i, model)\n",
    "\tpatched_acc_list.append(pa)\n",
    "\tunpatched_acc_list.append(ua)\n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(np.array(patched_acc_list))\n",
    "df2 = pd.DataFrame(np.array(unpatched_acc_list))\n",
    "\n",
    "df1.to_csv(f'/home/mhc/Drawing/backdoor/patched_acc_{experimentID}_cifar9_2_real.csv')\n",
    "df2.to_csv(f'/home/mhc/Drawing/backdoor/unpatched_acc_{experimentID}_cifar9_2_real.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before finetuning\n",
      "-------------------pathched target--------------------\n",
      "Acc: 0.0\n",
      "-------------------unpathched target--------------------\n",
      "Acc: 0.4\n",
      "-------------------pathched nontarget--------------------\n",
      "Acc: 0.2155\n",
      "-------------------unpathched nontarget--------------------\n",
      "Acc: 0.6675\n",
      "after finetuning\n",
      "-------------------pathched target--------------------\n",
      "Acc: 0.0\n",
      "-------------------unpathched target--------------------\n",
      "Acc: 0.75\n",
      "-------------------pathched nontarget--------------------\n",
      "Acc: 0.3325\n",
      "-------------------unpathched nontarget--------------------\n",
      "Acc: 0.72375\n"
     ]
    }
   ],
   "source": [
    "def cus_test_ds(classlist):\n",
    "\t\n",
    "\tdatalist = []\n",
    "\tif dataset == 'cifar10':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('cifar10', f\"/home/mhc/public_dataset/cifar_imgs/test/{cls}\", cls, (1, 501), cifar_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\tif dataset == 'mnist':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('mnist', f\"/home/mhc/public_dataset/mnist_imgs/test/{cls}\", cls, (1, 501), mnist_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\t\n",
    "\tdatatup = tuple(datalist)\n",
    "\tconcat_ds = torch.utils.data.ConcatDataset(datatup)\n",
    "\treturn concat_ds\n",
    "\n",
    "\n",
    "\n",
    "def total_test():\n",
    "\ttarget_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{target_label}\", \n",
    "\t\t\t\t\t\ttarget_label, (1, 501), cifar_trans)\n",
    "\ttarget_loader = torch.utils.data.DataLoader(target_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\tuntarget_ds = cus_test_ds([1,2,3,4,5,6,8,9])\n",
    "\tuntarget_loader = torch.utils.data.DataLoader(untarget_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\tfor s in ['before', 'after']:\n",
    "\t\tif s == 'before':\n",
    "\t\t\tmodel_test = model_before_backdoor\n",
    "\t\t\tprint(\"before finetuning\")\n",
    "\t\tif s == 'after':\n",
    "\t\t\t# model_test = alexnet(\"cifar\",False)\n",
    "\t\t\t# model_test.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_8/globmod/epoch_19_acc_0.779.pth\")[\"state_dict\"])\n",
    "\t\t\tmodel_test = server.server_model\n",
    "\t\t\tprint(\"after finetuning\")\n",
    "\n",
    "\t\t# acc_test(model_test, dataloaders_dict['patched'])\n",
    "\t\t# acc_test(model_test, poison_loader)\n",
    "\t\t# print(acc_test(model_test, mnist_cus_loader))\n",
    "\t\t\n",
    "\t\tprint(\"-------------------pathched target--------------------\")\n",
    "\t\ttrigger_test_total(model_test, target_loader , trigger, trigger_size)\n",
    "\t\tprint(\"-------------------unpathched target--------------------\")\n",
    "\t\ttrigger_test_total(model_test, target_loader , trigger, 0)\n",
    "\n",
    "\n",
    "\t\tprint(\"-------------------pathched nontarget--------------------\")\n",
    "\t\ttrigger_test_total(model_test, untarget_loader , trigger, trigger_size)\n",
    "\t\tprint(\"-------------------unpathched nontarget--------------------\")\n",
    "\t\ttrigger_test_total(model_test, untarget_loader , trigger, 0)\n",
    "\n",
    "\n",
    "total_test()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ee93600a6eb60504e508f539cf2b837386ccee6f718dcf413180ced79f68df2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
