{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
    "from gan_attack import GANAttackManager\n",
    "from model.classify_models import lenet5, alexnet, resnet18\n",
    "from model.generator import Interpolate_Generator\n",
    "from utils import LabeledDataset, acc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# nz = 100\n",
    "\n",
    "target_label = 7\n",
    "\n",
    "fake_label = 0\n",
    "\n",
    "experimentID = 73\n",
    "note=\" 52 trigger 6 \"\n",
    "\n",
    "dataset = 'cifar10'   # mnist  cifar10\n",
    "modelname = 'alexnet'\n",
    "pretrained = False\n",
    "# generator = Interpolate_Generator(nz=nz, nc=3)   # 注意修改nc\n",
    "# generator.to(device)\n",
    "\n",
    "\n",
    "# epochs = 30\n",
    "local_epochs = 3\n",
    "backdoor_local_epochs = 5\n",
    "backdoor_rounds = 5\n",
    "# gan_iteration = 1000\n",
    "gradient_zoom = 1\n",
    "\n",
    "client_lr = 0.01*0.05  # 模型接近收敛 降低学习率\n",
    "# generator_lr = 0.02\n",
    "backdoor_lr = 0.01*0.1\n",
    "\n",
    "batch_size = 128\n",
    "# fake_batch_size = batch_size // 32\n",
    "\n",
    "# gen_poison_scale = 128\n",
    "class_size = 1000\n",
    "\n",
    "# NSCA权重\n",
    "beta1 = 0.2\n",
    "# MTA 权重\n",
    "beta2 = 0.2\n",
    "\n",
    "\n",
    "# 注意根据target label 修改trigger 和 对应的model\n",
    "model_before_backdoor = alexnet(\"cifar\",False)\n",
    "model_before_backdoor.load_state_dict(torch.load(\n",
    "    \"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_52/globmod/epoch_24_acc_0.713.pth\")[\"state_dict\"])\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    if modelname == 'lenet5':\n",
    "        return lenet5(dataset, pretrained)\n",
    "    if modelname == 'alexnet':\n",
    "        # return alexnet(dataset, pretrained)\n",
    "        return model_before_backdoor\n",
    "    if modelname == 'resnet18':\n",
    "        return resnet18(dataset, pretrained)\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 2022\n",
    "# 设置随机数种子\n",
    "setup_seed(seed)\n",
    "\n",
    "\n",
    "logpath = f'./log/experiment_setting/exp_{experimentID}.txt'\n",
    "if not os.path.exists(os.path.dirname(logpath)):\n",
    "    os.makedirs(os.path.dirname(logpath))\n",
    "\n",
    "settings = f\"experiment:{experimentID}\\nmodel:{modelname}-pretrained:{pretrained}\\n\\\n",
    "dataset:{dataset}\\nFL backdoor_local_epochs:{backdoor_local_epochs}\\nlocal epochs:{local_epochs}\\n\\\n",
    "batch size:{batch_size}\\ntarget label:{target_label}\\n\\\n",
    "fake label:{fake_label}\\nclient lr:{client_lr}\\n\\\n",
    "class size:{class_size}\\nbackdoor rounds:{backdoor_rounds}\\n\\\n",
    "gradient zoom:{gradient_zoom}\\nrandom seed:{seed}\\npenalty weight beta:{beta1, beta2}\\nnote:{note}\"\n",
    "\n",
    "\n",
    "with open(logpath,'w') as f1:\n",
    "    f1.write(settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FL settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "client_num = 10\n",
    "adversary_client_id = 0  # 对应于client1 index从0开始\n",
    "# 设置恶意客户端\n",
    "\n",
    "\n",
    "clients = []\n",
    "optimizers = []\n",
    "\n",
    "# 批量生成正常客户端\n",
    "for id in range(1, client_num+1):\n",
    "    exec(f\"net_{id}=get_model()\")\n",
    "    exec(f\"client_{id}=FedAvgClient(net_{id}, user_id=id)\")\n",
    "    exec(f\"client_{id}.to(device)\")\n",
    "    if id == 1:\n",
    "        exec(f\"optimizer_{id} = optim.SGD(client_{id}.parameters(), lr=backdoor_lr, weight_decay=1e-7, momentum=0.9)\")\n",
    "    else:\n",
    "        exec(f\"optimizer_{id} = optim.SGD(client_{id}.parameters(), lr=client_lr, weight_decay=1e-7, momentum=0.9)\")\n",
    "    exec(f\"clients.append(client_{id})\")\n",
    "    exec(f\"optimizers.append(optimizer_{id})\")\n",
    "\n",
    "\n",
    "global_model = get_model()\n",
    "global_model.to(device)\n",
    "server = FedAvgServer(clients, global_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "mnist_trans = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),   # resize 参数是元组\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "cifar_trans = transforms.Compose([\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "\troot=\"/home/mhc/public_dataset/mnist\", train=False, download=True, transform=mnist_trans\n",
    ")\n",
    "cifar_test = torchvision.datasets.CIFAR10(\n",
    "\troot=\"/home/mhc/public_dataset/cifar10\", train=False, download=True, transform=cifar_trans\n",
    ")\n",
    "\n",
    "if dataset == 'mnist':\n",
    "\tglobal_testset = mnist_test\n",
    "if dataset == 'cifar10':\n",
    "\tglobal_testset = cifar_test\n",
    "\n",
    "global_testloader = torch.utils.data.DataLoader(\n",
    "\tglobal_testset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# 自定义数据集划分, 数据集里的图片编号从1开始\n",
    "def custom_dataset(classlist, start_idx):\n",
    "\tsize = class_size\n",
    "\tdatalist = []\n",
    "\tif dataset == 'cifar10':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('cifar10', f\"/home/mhc/public_dataset/cifar_imgs/train/{cls}\", cls, (start_idx+1, start_idx+size+1), cifar_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\tif dataset == 'mnist':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('mnist', f\"/home/mhc/public_dataset/mnist_imgs/train/{cls}\", cls, (start_idx+1, start_idx+size+1), mnist_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\t\n",
    "\tdatatup = tuple(datalist)\n",
    "\tconcat_ds = torch.utils.data.ConcatDataset(datatup)\n",
    "\treturn concat_ds\n",
    "\n",
    "\n",
    "# trainset_1 = custom_dataset([0,1,2,3,4],0)\n",
    "# trainset_2 = custom_dataset([1,2,3,4,5],1000)\n",
    "# trainset_3 = custom_dataset([2,3,4,5,6],2000)\n",
    "# trainset_4 = custom_dataset([3,4,5,6,7],3000)\n",
    "# trainset_5 = custom_dataset([4,5,6,7,8],4000)\n",
    "# trainset_6 = custom_dataset([5,6,7,8,9],0)\n",
    "# trainset_7 = custom_dataset([6,7,8,9,0],1000)\n",
    "# trainset_8 = custom_dataset([7,8,9,0,1],2000)\n",
    "# trainset_9 = custom_dataset([8,9,0,1,2],3000)\n",
    "# trainset_10 = custom_dataset([9,0,1,2,3],4000)\n",
    "\n",
    "\n",
    "trainloaders=[]\n",
    "for id in range(1, client_num+1):\n",
    "\texec(f\"trainset_{id} = custom_dataset([id-1, id%10, (id+1)%10, (id+2)%10, (id+3)%10], ((id-1)%5)*1000)\")\n",
    "\texec(f\"trainloader_{id} = torch.utils.data.DataLoader(trainset_{id}, batch_size=batch_size, shuffle=True, num_workers=2)\")\n",
    "\texec(f\"trainloaders.append(trainloader_{id})\")\n",
    "\texec(f\"print(len(trainset_{id}))\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def save_image(epoch, imgs):\n",
    "    dirpath = f\"./image/gen_img/experiment_{experimentID}\"\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "    torchvision.utils.save_image(\n",
    "            imgs, \n",
    "            os.path.join(dirpath, f\"epoch_{epoch}.jpg\"), \n",
    "            normalize = True, \n",
    "            nrow=8\n",
    "    )\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch, learing_rate):\n",
    "#     if epoch < 0.5*epochs:\n",
    "#         lr = learing_rate\n",
    "#     elif epoch < 0.8*epochs:\n",
    "#         lr = 0.1*learing_rate\n",
    "#     else:\n",
    "#         lr = 0.05*learing_rate\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad_false(model):\n",
    "    # model_para:自定义属性 ，若直接取model.named_parameters() 会包含client里的所有模型，包括生成器和判别器\n",
    "\tfor name, param in model.model_para:\n",
    "\t\t# print(name)\n",
    "\t\tif \"fc\" in name:\n",
    "\t\t\tparam.requires_grad = True\n",
    "\t\telse:\n",
    "\t\t\tparam.requires_grad = False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    trigger_size = 8\n",
    "    triggertrans = transforms.Compose([\n",
    "    transforms.Resize((trigger_size, trigger_size)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    trigger = Image.open('/home/mhc/AIJack/invert_and_poison/image/triggers/specific/trigger6/iter26.jpg').convert('RGB')\n",
    "    # trigger = Image.open('/home/mhc/AIJack/invert_and_poison/image/triggers/trigger_11.png').convert('RGB')\n",
    "    trigger = triggertrans(trigger) # size [3, 8, 8]\n",
    "    \n",
    "if dataset == \"mnist\":\n",
    "    trigger_size = 4\n",
    "    trigger = torch.ones(1, trigger_size, trigger_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backdoor training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bafore backdoor gloabl accuracy 0.7134\n",
      "epoch 0: client-1 loss:3.908834747970104 acc:0.986328125 loss1:0.0018012200016528368 loss2:0.537160336971283 loss3:0.025938300415873528\n",
      "epoch 0: client-1 loss:1.5550336837768555 acc:0.99765625 loss1:0.009839193895459175 loss2:0.2114318460226059 loss3:0.03393804654479027\n",
      "epoch 0: client-2 loss:15.736254930496216 acc:0.8576\n",
      "epoch 0: client-2 loss:12.00586673617363 acc:0.886\n",
      "epoch 0: client-3 loss:18.830618977546692 acc:0.827\n",
      "epoch 0: client-3 loss:14.940919280052185 acc:0.8578\n",
      "epoch 0: client-4 loss:23.01353371143341 acc:0.8164\n",
      "epoch 0: client-4 loss:14.703649580478668 acc:0.8682\n",
      "epoch 0: client-5 loss:13.375234961509705 acc:0.892\n",
      "epoch 0: client-5 loss:8.475032187998295 acc:0.9268\n",
      "epoch 0: client-6 loss:8.577478504390456 acc:0.9236\n",
      "epoch 0: client-6 loss:5.336703334003687 acc:0.9518\n",
      "epoch 0: client-7 loss:11.465831838548183 acc:0.9058\n",
      "epoch 0: client-7 loss:6.000880883075297 acc:0.947\n",
      "epoch 0: client-8 loss:8.82042409479618 acc:0.919\n",
      "epoch 0: client-8 loss:5.796703841537237 acc:0.9472\n",
      "epoch 0: client-9 loss:17.49267816543579 acc:0.8818\n",
      "epoch 0: client-9 loss:7.475600048899651 acc:0.9354\n",
      "epoch 0: client-10 loss:18.830683544278145 acc:0.8698\n",
      "epoch 0: client-10 loss:6.3645935617387295 acc:0.9388\n",
      "epoch 0: gloabl accuracy 0.4303\n",
      "epoch 1: client-1 loss:10.866083793342113 acc:0.87109375 loss1:0.001196903409436345 loss2:0.5692850351333618 loss3:0.12376023828983307\n",
      "epoch 1: client-1 loss:2.1186103001236916 acc:0.96796875 loss1:0.010057411156594753 loss2:0.18975934386253357 loss3:0.03972247615456581\n",
      "epoch 1: client-2 loss:22.072872549295425 acc:0.8232\n",
      "epoch 1: client-2 loss:12.48229917883873 acc:0.8856\n",
      "epoch 1: client-3 loss:19.355616182088852 acc:0.83\n",
      "epoch 1: client-3 loss:14.706573873758316 acc:0.8622\n",
      "epoch 1: client-4 loss:21.572805307805538 acc:0.8218\n",
      "epoch 1: client-4 loss:14.4804647564888 acc:0.8706\n",
      "epoch 1: client-5 loss:15.156367495656013 acc:0.886\n",
      "epoch 1: client-5 loss:7.738497447222471 acc:0.9302\n",
      "epoch 1: client-6 loss:7.774118095636368 acc:0.9302\n",
      "epoch 1: client-6 loss:4.986696507781744 acc:0.954\n",
      "epoch 1: client-7 loss:11.755880735814571 acc:0.9108\n",
      "epoch 1: client-7 loss:5.761486351490021 acc:0.9506\n",
      "epoch 1: client-8 loss:8.579170823097229 acc:0.9212\n",
      "epoch 1: client-8 loss:5.589668788015842 acc:0.948\n",
      "epoch 1: client-9 loss:17.518039852380753 acc:0.8754\n",
      "epoch 1: client-9 loss:7.13523043692112 acc:0.937\n",
      "epoch 1: client-10 loss:19.561958611011505 acc:0.8678\n",
      "epoch 1: client-10 loss:6.3144834116101265 acc:0.94\n",
      "epoch 1: gloabl accuracy 0.6948\n",
      "epoch 2: client-1 loss:2.094817839562893 acc:0.948046875 loss1:0.005798373371362686 loss2:0.22340834140777588 loss3:0.14808455109596252\n",
      "epoch 2: client-1 loss:1.2713189907371998 acc:0.98359375 loss1:0.0029105525463819504 loss2:0.2525806128978729 loss3:0.07351099699735641\n",
      "epoch 2: client-2 loss:16.239967301487923 acc:0.8478\n",
      "epoch 2: client-2 loss:12.111087992787361 acc:0.8872\n",
      "epoch 2: client-3 loss:17.5697183907032 acc:0.8358\n",
      "epoch 2: client-3 loss:14.173982694745064 acc:0.87\n",
      "epoch 2: client-4 loss:21.754308342933655 acc:0.8214\n",
      "epoch 2: client-4 loss:14.323699429631233 acc:0.8702\n",
      "epoch 2: client-5 loss:12.667679063975811 acc:0.8994\n",
      "epoch 2: client-5 loss:7.996648624539375 acc:0.937\n",
      "epoch 2: client-6 loss:8.663672134280205 acc:0.9238\n",
      "epoch 2: client-6 loss:4.91633889451623 acc:0.957\n",
      "epoch 2: client-7 loss:11.529004514217377 acc:0.9158\n",
      "epoch 2: client-7 loss:5.48547824844718 acc:0.9516\n",
      "epoch 2: client-8 loss:7.877415895462036 acc:0.9254\n",
      "epoch 2: client-8 loss:5.4047218561172485 acc:0.9518\n",
      "epoch 2: client-9 loss:15.695396289229393 acc:0.8858\n",
      "epoch 2: client-9 loss:7.03330647200346 acc:0.9434\n",
      "epoch 2: client-10 loss:20.918432094156742 acc:0.8618\n",
      "epoch 2: client-10 loss:6.25370129942894 acc:0.9444\n",
      "epoch 2: gloabl accuracy 0.4391\n",
      "epoch 3: client-1 loss:10.002635568380356 acc:0.883984375 loss1:0.005266624968498945 loss2:0.26656925678253174 loss3:0.042769961059093475\n",
      "epoch 3: client-1 loss:1.617182221263647 acc:0.980078125 loss1:0.009386321529746056 loss2:0.15756691992282867 loss3:0.03132494539022446\n",
      "epoch 3: client-2 loss:22.373935475945473 acc:0.8306\n",
      "epoch 3: client-2 loss:11.753135547041893 acc:0.888\n",
      "epoch 3: client-3 loss:17.993514850735664 acc:0.831\n",
      "epoch 3: client-3 loss:14.473785668611526 acc:0.8702\n",
      "epoch 3: client-4 loss:21.17829442769289 acc:0.8194\n",
      "epoch 3: client-4 loss:14.212836593389511 acc:0.873\n",
      "epoch 3: client-5 loss:18.94069604575634 acc:0.8684\n",
      "epoch 3: client-5 loss:7.86968831717968 acc:0.9358\n",
      "epoch 3: client-6 loss:8.401849500834942 acc:0.924\n",
      "epoch 3: client-6 loss:4.936239138245583 acc:0.9548\n",
      "epoch 3: client-7 loss:10.789643340744078 acc:0.9106\n",
      "epoch 3: client-7 loss:5.4789867997169495 acc:0.9516\n",
      "epoch 3: client-8 loss:8.101158283650875 acc:0.9264\n",
      "epoch 3: client-8 loss:5.23253234103322 acc:0.9538\n",
      "epoch 3: client-9 loss:14.222425781190395 acc:0.8948\n",
      "epoch 3: client-9 loss:6.815831013023853 acc:0.9434\n",
      "epoch 3: client-10 loss:20.495983332395554 acc:0.8636\n",
      "epoch 3: client-10 loss:6.258621871471405 acc:0.9466\n",
      "epoch 3: gloabl accuracy 0.6262\n",
      "epoch 4: client-1 loss:3.171606622636318 acc:0.881640625 loss1:0.0039057896938174963 loss2:0.2622607350349426 loss3:0.18803854286670685\n",
      "epoch 4: client-1 loss:1.4841312356293201 acc:0.9609375 loss1:0.002220162423327565 loss2:0.17251431941986084 loss3:0.09976955503225327\n",
      "epoch 4: client-2 loss:19.12459148466587 acc:0.8276\n",
      "epoch 4: client-2 loss:12.929972141981125 acc:0.882\n",
      "epoch 4: client-3 loss:18.121411353349686 acc:0.84\n",
      "epoch 4: client-3 loss:14.597934052348137 acc:0.8668\n",
      "epoch 4: client-4 loss:21.714335054159164 acc:0.817\n",
      "epoch 4: client-4 loss:14.340091779828072 acc:0.8682\n",
      "epoch 4: client-5 loss:14.710652887821198 acc:0.8876\n",
      "epoch 4: client-5 loss:7.886685952544212 acc:0.9338\n",
      "epoch 4: client-6 loss:9.274084283038974 acc:0.921\n",
      "epoch 4: client-6 loss:4.989229962229729 acc:0.956\n",
      "epoch 4: client-7 loss:11.403346222708933 acc:0.9106\n",
      "epoch 4: client-7 loss:5.36895792838186 acc:0.9526\n",
      "epoch 4: client-8 loss:7.793946720659733 acc:0.9314\n",
      "epoch 4: client-8 loss:5.208401273936033 acc:0.9526\n",
      "epoch 4: client-9 loss:13.803097352385521 acc:0.8924\n",
      "epoch 4: client-9 loss:6.5935155134648085 acc:0.9428\n",
      "epoch 4: client-10 loss:19.771817483007908 acc:0.8666\n",
      "epoch 4: client-10 loss:6.073060089722276 acc:0.9466\n",
      "epoch 4: gloabl accuracy 0.4583\n"
     ]
    }
   ],
   "source": [
    "poisondataID = 52\n",
    "\n",
    "before_acc = acc_test(model_before_backdoor, global_testloader)\n",
    "print(f\"bafore backdoor gloabl accuracy {before_acc}\")\n",
    "\n",
    "\n",
    "for epoch in range(backdoor_rounds):\n",
    "    \n",
    "    for client_idx in range(client_num):\n",
    "        client = clients[client_idx]\n",
    "        trainloader = trainloaders[client_idx]\n",
    "        optimizer = optimizers[client_idx]\n",
    "\n",
    "        if  client_idx != adversary_client_id:\n",
    "            for local_epoch in range(local_epochs):\n",
    "                running_loss = 0.0\n",
    "                total =0\n",
    "                correct =0\n",
    "                for i, data in enumerate(trainloader, 0): # index_start=0\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    outputs, _ = client(inputs)\n",
    "                    loss = criterion(outputs, labels) # labels.to(torch.int64)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # training acc\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (preds == labels).sum().item()\n",
    "                    running_loss += loss.item()\n",
    "                    training_acc = correct/total\n",
    "\n",
    "                print(f\"epoch {epoch}: client-{client_idx+1} loss:{running_loss} acc:{training_acc}\")\n",
    "\n",
    "        # 恶意客户端 在最后n轮 执行后门植入\n",
    "        else:\n",
    "            for local_epoch in range(backdoor_local_epochs):\n",
    "    \n",
    "                running_loss = 0.0\n",
    "                total =0\n",
    "                correct =0\n",
    "                poison_set = LabeledDataset(dataset, f\"./image/poison_img/exp_{poisondataID}/original\", \n",
    "                            fake_label, (1, 1+2560), transform=transforms.ToTensor())\n",
    "                poison_loader = torch.utils.data.DataLoader(poison_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "                clean_loader = trainloader\n",
    "\n",
    "                poison_iter = iter(poison_loader)\n",
    "                clean_iter = iter(clean_loader)\n",
    "\n",
    "                for i, data in enumerate(poison_loader, 0): # index_start=0\n",
    "                    if (local_epoch + 1) == 0:\n",
    "                        print(f\"perform backdoor planting.........\")\n",
    "                    (input1, label1) = data\n",
    "                    (input2, label2) = next(clean_iter)\n",
    "\n",
    "                    input1 = input1.to(device)\n",
    "                    label1 = label1.to(device)\n",
    "                    input2 = input2.to(device)\n",
    "                    label2 = label2.to(device)\n",
    "                    input3 = input2.clone()\n",
    "                    label3 = label2.clone()\n",
    "                    \n",
    "                    # 全加上trigger  正常样本作为惩罚项\n",
    "\n",
    "                    input1[:, :, 32-2-trigger_size:32-2, 32-2-trigger_size:32-2] = trigger\n",
    "                    input2[:, :, 32-2-trigger_size:32-2, 32-2-trigger_size:32-2] = trigger\n",
    "                    \n",
    "                    # inputs = torch.cat([input1, input2])\n",
    "                    # labels = torch.cat([label1, label2])\n",
    "\n",
    "                    # 后门植入时 只更新全连接层\n",
    "                    set_parameter_requires_grad_false(client)\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    output1, _ = client(input1)\n",
    "                    loss1 = criterion(output1, label1) # labels.to(torch.int64)\n",
    "                    \n",
    "                    output2, _ = client(input2)\n",
    "                    loss2 = criterion(output2, label2)\n",
    "\n",
    "                    output3, _ = client(input3)\n",
    "                    loss3 = criterion(output3, label3)\n",
    "                    \n",
    "                    loss = loss1 + beta1 * loss2 + beta2 * loss3\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # training acc\n",
    "                    _, preds = torch.max(output3.data, 1)\n",
    "                    total += label3.size(0)\n",
    "                    correct += (preds == label3).sum().item()\n",
    "                    running_loss += loss.item()\n",
    "                    training_acc = correct/total\n",
    "\n",
    "                print(f\"epoch {epoch}: client-{client_idx+1} loss:{running_loss} acc:{training_acc} loss1:{loss1.item()} loss2:{loss2.item()} loss3:{loss3.item()}\")\n",
    "\n",
    "    # 恶意客户端将梯度放大后聚合\n",
    "    server.action(attID=adversary_client_id, zoom=gradient_zoom)\n",
    "    \n",
    "\n",
    "    # global test\n",
    "    global_acc = acc_test(server.server_model, global_testloader)\n",
    "    print(f\"epoch {epoch}: gloabl accuracy {global_acc}\")\n",
    "\n",
    "    save_checkpoint({\"state_dict\":server.server_model.state_dict()\n",
    "                    }, filename= f\"./checkpoint/experiment_{experimentID}/globmod/epoch_{epoch}_acc_{round(global_acc,3)}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop:精确到每个类别的分类情况\n",
    "#### total:只区分目标类和非目标类，考察整体ASR和主任务性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_test_loop(n, loader, trigger, size):\n",
    "    n.eval()\n",
    "    acc_list=[]\n",
    "    print('target    | acc')\n",
    "    for la in range(10):\n",
    "        total =0\n",
    "        correct =0\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.cuda()\n",
    "            labels = torch.tensor([la]*len(labels)).cuda()\n",
    "\n",
    "            if size != 0:\n",
    "                for z in range(imgs.size(0)):\n",
    "                    \n",
    "                    imgs[z, :, 32-2-size:32-2, 32-2-size:32-2] = trigger\n",
    "\n",
    "            output, _ = n(imgs)\n",
    "            \n",
    "            _, preds = torch.max(output.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "        acc = round(float(correct/total), 2)\n",
    "        acc_list.append(acc)\n",
    "        print(la,\"        \",acc)\n",
    "    return acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_test_total(n, loader, trigger, size):\n",
    "    n.eval()\n",
    "    total =0\n",
    "    correct =0\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "\n",
    "        if size != 0:\n",
    "            for z in range(imgs.size(0)):\n",
    "                \n",
    "                imgs[z, :, 32-2-size:32-2, 32-2-size:32-2] = trigger\n",
    "\n",
    "        output, _ = n(imgs)\n",
    "        \n",
    "        _, preds = torch.max(output.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    print(\"Acc:\",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_label_loop(image_label):\n",
    "\tprint(\"source label:\", image_label)\n",
    "\ttest_img = image_label\n",
    "\ttest_lab = 7\n",
    "\tmnist_cus_ds = LabeledDataset(\"mnist\", f\"/home/mhc/public_dataset/mnist_imgs/test/{test_img}\", \n",
    "\t\t\t\t\t\ttest_lab, (1, 201), mnist_trans)\n",
    "\tmnist_cus_loader = torch.utils.data.DataLoader(mnist_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\tcifar_cus_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{test_img}\", \n",
    "\t\t\t\t\t\ttest_lab, (1, 201), cifar_trans)\n",
    "\tcifar_cus_loader = torch.utils.data.DataLoader(cifar_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t# model_test = alexnet(\"cifar\",False)\n",
    "\t# model_test.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_8/globmod/epoch_19_acc_0.779.pth\")[\"state_dict\"])\n",
    "\t\n",
    "\tmodel_test = server.server_model\n",
    "\tprint(\"after finetuning\")\n",
    "\n",
    "\n",
    "\tprint(\"-------------------pathched--------------------\")\n",
    "\ttrigger_test_loop(model_test, cifar_cus_loader , trigger, trigger_size)\n",
    "\tprint(\"-------------------unpathched--------------------\")\n",
    "\ttrigger_test_loop(model_test, cifar_cus_loader , trigger, 0)\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "# \tcifar_label_loop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source label: 0\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.65\n",
      "1          0.08\n",
      "2          0.03\n",
      "3          0.24\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.78\n",
      "1          0.03\n",
      "2          0.06\n",
      "3          0.09\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.04\n",
      "source label: 1\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.92\n",
      "2          0.0\n",
      "3          0.06\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.01\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.92\n",
      "2          0.0\n",
      "3          0.02\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.04\n",
      "source label: 2\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.04\n",
      "1          0.03\n",
      "2          0.43\n",
      "3          0.48\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.01\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.06\n",
      "1          0.01\n",
      "2          0.64\n",
      "3          0.27\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.01\n",
      "source label: 3\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.02\n",
      "2          0.02\n",
      "3          0.95\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.01\n",
      "2          0.05\n",
      "3          0.91\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.02\n",
      "source label: 4\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.05\n",
      "1          0.02\n",
      "2          0.17\n",
      "3          0.76\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.09\n",
      "1          0.01\n",
      "2          0.35\n",
      "3          0.48\n",
      "4          0.01\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.04\n",
      "8          0.0\n",
      "9          0.02\n",
      "source label: 5\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.03\n",
      "2          0.05\n",
      "3          0.92\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.02\n",
      "1          0.01\n",
      "2          0.07\n",
      "3          0.87\n",
      "4          0.0\n",
      "5          0.01\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.01\n",
      "source label: 6\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.0\n",
      "1          0.06\n",
      "2          0.1\n",
      "3          0.84\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.0\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.01\n",
      "1          0.06\n",
      "2          0.22\n",
      "3          0.59\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.12\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.02\n",
      "source label: 7\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.11\n",
      "1          0.02\n",
      "2          0.09\n",
      "3          0.74\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.02\n",
      "8          0.0\n",
      "9          0.02\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.16\n",
      "1          0.01\n",
      "2          0.12\n",
      "3          0.39\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.27\n",
      "8          0.0\n",
      "9          0.06\n",
      "source label: 8\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.34\n",
      "1          0.27\n",
      "2          0.02\n",
      "3          0.36\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.01\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.44\n",
      "1          0.21\n",
      "2          0.02\n",
      "3          0.19\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.07\n",
      "9          0.07\n",
      "source label: 9\n",
      "-------------------pathched--------------------\n",
      "target    | acc\n",
      "0          0.04\n",
      "1          0.29\n",
      "2          0.01\n",
      "3          0.22\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.43\n",
      "-------------------unpathched--------------------\n",
      "target    | acc\n",
      "0          0.03\n",
      "1          0.11\n",
      "2          0.01\n",
      "3          0.07\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "7          0.0\n",
      "8          0.0\n",
      "9          0.78\n"
     ]
    }
   ],
   "source": [
    "def cifar_label_loop(source, model_test):\n",
    "\tprint(\"source label:\", source)\n",
    "\n",
    "\tmnist_cus_ds = LabeledDataset(\"mnist\", f\"/home/mhc/public_dataset/mnist_imgs/test/{source}\", \n",
    "\t\t\t\t\t\tsource, (1, 501), mnist_trans)\n",
    "\tmnist_cus_loader = torch.utils.data.DataLoader(mnist_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\tcifar_cus_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{source}\", \n",
    "\t\t\t\t\t\tsource, (1, 501), cifar_trans)\n",
    "\tcifar_cus_loader = torch.utils.data.DataLoader(cifar_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\t\n",
    "\tprint(\"-------------------pathched--------------------\")\n",
    "\tpatched_acc = trigger_test_loop(model_test, cifar_cus_loader , trigger, trigger_size)\n",
    "\tprint(\"-------------------unpathched--------------------\")\n",
    "\tunpatched_acc = trigger_test_loop(model_test, cifar_cus_loader , trigger, 0)\n",
    "\n",
    "\treturn patched_acc, unpatched_acc\n",
    "\n",
    "\n",
    "patched_acc_list = []\n",
    "unpatched_acc_list = []\n",
    "model = server.server_model\n",
    "for i in range(10):\n",
    "\tpa, ua = cifar_label_loop(i, model)\n",
    "\tpatched_acc_list.append(pa)\n",
    "\tunpatched_acc_list.append(ua)\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(np.array(patched_acc_list))\n",
    "df2 = pd.DataFrame(np.array(unpatched_acc_list))\n",
    "\n",
    "\n",
    "df1.to_csv(f'/home/mhc/Drawing/backdoor/patched_acc_{experimentID}.csv')\n",
    "df2.to_csv(f'/home/mhc/Drawing/backdoor/unpatched_acc_{experimentID}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cus_test_ds(classlist):\n",
    "\t\n",
    "\tdatalist = []\n",
    "\tif dataset == 'cifar10':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('cifar10', f\"/home/mhc/public_dataset/cifar_imgs/test/{cls}\", cls, (1, 501), cifar_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\tif dataset == 'mnist':\n",
    "\t\tfor cls in classlist:\n",
    "\t\t\tds = LabeledDataset('mnist', f\"/home/mhc/public_dataset/mnist_imgs/test/{cls}\", cls, (1, 501), mnist_trans)\n",
    "\t\t\tdatalist.append(ds)\n",
    "\t\n",
    "\tdatatup = tuple(datalist)\n",
    "\tconcat_ds = torch.utils.data.ConcatDataset(datatup)\n",
    "\treturn concat_ds\n",
    "\n",
    "\n",
    "\n",
    "def total_test():\n",
    "\ttarget_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{target_label}\", \n",
    "\t\t\t\t\t\ttarget_label, (1, 501), cifar_trans)\n",
    "\ttarget_loader = torch.utils.data.DataLoader(target_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\tuntarget_ds = cus_test_ds([0,1,2,3,4,5,6,8,9])\n",
    "\tuntarget_loader = torch.utils.data.DataLoader(untarget_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\tfor s in ['before', 'after']:\n",
    "\t\tif s == 'before':\n",
    "\t\t\tmodel_test = model_before_backdoor\n",
    "\t\t\tprint(\"before finetuning\")\n",
    "\t\tif s == 'after':\n",
    "\t\t\t# model_test = alexnet(\"cifar\",False)\n",
    "\t\t\t# model_test.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_8/globmod/epoch_19_acc_0.779.pth\")[\"state_dict\"])\n",
    "\t\t\tmodel_test = server.server_model\n",
    "\t\t\tprint(\"after finetuning\")\n",
    "\n",
    "\t\t# acc_test(model_test, dataloaders_dict['patched'])\n",
    "\t\t# acc_test(model_test, poison_loader)\n",
    "\t\t# print(acc_test(model_test, mnist_cus_loader))\n",
    "\t\t\n",
    "\t\tprint(\"-------------------pathched target--------------------\")\n",
    "\t\ttrigger_test_total(model_test, target_loader , trigger, trigger_size)\n",
    "\t\tprint(\"-------------------unpathched target--------------------\")\n",
    "\t\ttrigger_test_total(model_test, target_loader , trigger, 0)\n",
    "\n",
    "\n",
    "\t\tprint(\"-------------------pathched nontarget--------------------\")\n",
    "\t\ttrigger_test_total(model_test, untarget_loader , trigger, trigger_size)\n",
    "\t\tprint(\"-------------------unpathched nontarget--------------------\")\n",
    "\t\ttrigger_test_total(model_test, untarget_loader , trigger, 0)\n",
    "\n",
    "\n",
    "total_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_label_loop(image_label):\n",
    "\tprint(\"source label:\", image_label)\n",
    "\ttest_img = image_label\n",
    "\ttest_lab = 7\n",
    "\tmnist_cus_ds = LabeledDataset(\"mnist\", f\"/home/mhc/public_dataset/mnist_imgs/test/{test_img}\", \n",
    "\t\t\t\t\t\ttest_lab, (1, 201), mnist_trans)\n",
    "\tmnist_cus_loader = torch.utils.data.DataLoader(mnist_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\tcifar_cus_ds = LabeledDataset(\"cifar10\", f\"/home/mhc/public_dataset/cifar_imgs/test/{test_img}\", \n",
    "\t\t\t\t\t\ttest_lab, (1, 201), cifar_trans)\n",
    "\tcifar_cus_loader = torch.utils.data.DataLoader(cifar_cus_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\tfor s in ['before', 'after']:\n",
    "\t\tif s == 'before':\n",
    "\t\t\tmodel_test = alexnet(\"mnist\",False)\n",
    "\t\t\tmodel_test.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_28/globmod/epoch_14_acc_0.983.pth\")[\"state_dict\"])\n",
    "\t\t\t\n",
    "\t\t\t# model_test = model_before_backdoor\n",
    "\t\t\tprint(\"before backdoor\")\n",
    "\t\tif s == 'after':\n",
    "\t\t\tmodel_test = alexnet(\"mnist\",False)\n",
    "\t\t\tmodel_test.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_28/globmod/epoch_19_acc_0.959.pth\")[\"state_dict\"])\n",
    "\t\t\t\n",
    "\t\t\t# model_test = server.server_model\n",
    "\t\t\t\n",
    "\t\t\tprint(\"after backdoor\")\n",
    "\n",
    "\t\t# acc_test(model_test, dataloaders_dict['patched'])\n",
    "\t\t# acc_test(model_test, poison_loader)\n",
    "\t\t# print(acc_test(model_test, mnist_cus_loader))\n",
    "\t\tprint(\"-------------------pathched--------------------\")\n",
    "\t\ttrigger = torch.ones(1, 4, 4)\n",
    "\t\ttrigger_test(model_test, mnist_cus_loader , trigger, 4)\n",
    "\t\tprint(\"-------------------not pathched--------------------\")\n",
    "\t\ttrigger_test(model_test, mnist_cus_loader , trigger, 0)\n",
    "\t\t\n",
    "\n",
    "for i in range(7,8):\n",
    "\tmnist_label_loop(i)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ee93600a6eb60504e508f539cf2b837386ccee6f718dcf413180ced79f68df2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
