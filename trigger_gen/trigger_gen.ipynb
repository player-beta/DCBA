{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from model.classify_models import alexnet, alexnet_cut\n",
    "from utils import LabeledDataset, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trans = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),   # resize 参数是元组\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "cifar_trans = transforms.Compose([\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "\n",
    "#target 后门攻击中的target\n",
    "target_label = 0\n",
    "target_set = LabeledDataset('cifar', f\"/home/mhc/public_dataset/cifar_imgs/train/{target_label}\", target_label, (1, 2561), mnist_trans)\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "#reconstruct data  后门攻击中的source\n",
    "rec_label = 7\n",
    "rec_set = LabeledDataset('cifar', f\"/home/mhc/public_dataset/cifar_imgs/train/{rec_label}\", rec_label, (1, 2561), mnist_trans)\n",
    "rec_loader = torch.utils.data.DataLoader(rec_set, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "model = alexnet(\"cifar10\",False)\n",
    "model.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_29/globmod/epoch_23_acc_0.692.pth\")[\"state_dict\"])\n",
    "\t\t\t\n",
    "model_cut = alexnet_cut(\"cifar10\",False)\n",
    "model_cut.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_29/globmod/epoch_23_acc_0.692.pth\")[\"state_dict\"], strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(lr, iter):\n",
    "\t\"\"\"Sets the learning rate to the initial LR decayed by 0.5 every 1000 iterations\"\"\"\n",
    "\tlr = lr * (0.8 ** (iter // 1000))\n",
    "\treturn lr\n",
    "\n",
    "def save_img(img_tensor, fname):\n",
    "\ttoPIL = transforms.ToPILImage()\n",
    "\timg = toPIL(img_tensor)\n",
    "\timg.save(fname, quality=95, subsampling=0)\n",
    "\n",
    "class AverageMeter(object):\n",
    "\t\"\"\"Computes and stores the average and current value\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.val = 0\n",
    "\t\tself.avg = 0\n",
    "\t\tself.sum = 0\n",
    "\t\tself.count = 0\n",
    "\n",
    "\tdef update(self, val, n=1):\n",
    "\t\tself.val = val\n",
    "\t\tself.sum += val\n",
    "\t\tself.count += n\n",
    "\t\tself.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定位目标神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NGR(net, tc, dl):\n",
    "    \n",
    "    for batch_idx, (img, target) in enumerate(dl):\n",
    "        print(img.shape, target.shape) \n",
    "        break  # 只取一个batch\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.to(device)\n",
    "        target = target.to(device)\n",
    "        net.to(device)\n",
    "        criterion=criterion.to(device)\n",
    "\n",
    "\n",
    "    net.eval()\n",
    "    output, _ = net(img)\n",
    "    print(\"network output: \",output.shape)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    for m in net.modules(): \n",
    "        # 遍历网络中所有的模块中的量化层\n",
    "        if hasattr(m, 'weight'):\n",
    "            if m.weight.grad is not None:\n",
    "                m.weight.grad.data.zero_()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for name, module in net.named_modules():\n",
    "        if isinstance(module, nn.Linear) and name=='1.fc3':\n",
    "            w_v, w_id = module.weight.grad.detach().abs().topk(100) \n",
    "            # taking only 100 top weights thus wb=100 \n",
    "            # A namedtuple of (values, indices) is returned, \n",
    "            # where the indices are the indices of the elements in the original input tensor.\n",
    "            \n",
    "            print(\"linear module.weight.shape: \", module.weight.shape)  #[10, 512]\n",
    "            print(\"wv:\", w_v.shape)   #[10,100]\n",
    "            print(\"wid:\", w_id.shape)  #[10,100]\n",
    "\n",
    "            tar=w_id[tc] \n",
    "            # targetclass = 0  倒数第二层512个神经元中, 对类别0 影响最大的 top 100 个神经元的索引值\n",
    "            # print(tar) \n",
    "\n",
    "    return tar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fgsm(model, data, target, tar, ep, data_min=0, data_max=1):\n",
    "\n",
    "#         model.eval() # 固定BN层和Dropout层\n",
    "\n",
    "#         perturbed_data = data.clone()\n",
    "#         perturbed_data.requires_grad = True\n",
    "\n",
    "#         output, _ = model(perturbed_data)\n",
    "\n",
    "#         criterion = nn.MSELoss()\n",
    "#         # 通过tar索引定位到特定神经元，计算其MSE\n",
    "#         loss = criterion(output[:,tar], target[:,tar])\n",
    "#         # print(\"ep={} loss:{}\".format(ep, loss.item()))\n",
    "        \n",
    "#         # 每一轮梯度清零\n",
    "#         if perturbed_data.grad is not None:\n",
    "#             perturbed_data.grad.data.zero_()\n",
    "\n",
    "#         # 保留计算图而不自动释放\n",
    "#         loss.backward(retain_graph=True)\n",
    "        \n",
    "#         # Collect the element-wise sign of the data gradient\n",
    "#         # 返回相同尺寸的包含 1 -1 0 的张量\n",
    "#         sign_data_grad = perturbed_data.grad.data.sign()\n",
    "#         perturbed_data.requires_grad = False\n",
    "\n",
    "#         # 默认以下所有计算不保存梯度\n",
    "#         with torch.no_grad():\n",
    "#             # Create the perturbed image by adjusting each pixel of the input image\n",
    "#             # 梯度下降？生成针对目标类的trigger\n",
    "#             perturbed_data[:,0:3,start:end,start:end] -= ep*sign_data_grad[:,0:3,start:end,start:end]  \n",
    "\n",
    "#             # 限制像素值范围[0, 1]\n",
    "#             perturbed_data.clamp_(data_min, data_max) \n",
    "    \n",
    "#         return perturbed_data, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model, input, trigger, ind):\n",
    "    model.eval() # 固定BN层和Dropout层\n",
    "\n",
    "    num_iter = 3000\n",
    "    lr = 0.01\n",
    "    eps = 1.0\n",
    "    losses = AverageMeter()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    tri = trigger.clone()\n",
    "    target = torch.randn(256,100).to(device)\n",
    "    target[:,:]=10\n",
    "    # tri = nn.Parameter(tri.to(device))\n",
    "    # tri.requires_grad = True\n",
    "\n",
    "    # PGD iteration \n",
    "    for j in range(num_iter):\n",
    "        if tri.grad == None:\n",
    "            tri = nn.Parameter(tri.to(device))\n",
    "            tri.requires_grad=True\n",
    "        \n",
    "        else:\n",
    "            tri.grad.data.zero_()\n",
    "        \n",
    "        lr1 = adjust_learning_rate(lr, j+1)\n",
    "        \n",
    "        input[:, :, 22:30, 22:30] = tri\n",
    "        \n",
    "        output = model(input)\n",
    "        # print(tri.is_leaf)\n",
    "\n",
    "        # 通过tar索引定位到特定神经元，计算其MSE\n",
    "\n",
    "        loss = criterion(output[:,ind], target)\n",
    "        \n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        trigrad = tri.grad\n",
    "        tri = tri - lr1*tri.grad\n",
    "        tri = torch.clamp(tri, 0, eps).detach_()\n",
    "        \n",
    "        if (j+1) %100 == 0:\n",
    "            print(\" iter: {:5d} | LR: {:2.4f} | Loss Val: {}\"\n",
    "\t\t\t\t\t\t.format(j, lr1, loss.item()))\n",
    "                        \n",
    "    return tri\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_gen(net, net2, ts, t_dl, s_dl):\n",
    "\n",
    "    nid = NGR(net, ts, t_dl)\n",
    "\n",
    "    tri = torch.randn(3, 8, 8, requires_grad=True)\n",
    "    tri[:,:,:] = 0.5\n",
    "\n",
    "\n",
    "    iter_source = iter(s_dl)\n",
    "    for i in range(len(s_dl)): \n",
    "        (input, label) = next(iter_source)\n",
    "        input = input.to(device)\n",
    "\n",
    "        tri = pgd(net2, input, tri, nid)\n",
    "\n",
    "        fname = '/home/mhc/AIJack/invert_and_poison/image/triggers/specific/iter{}.jpg'.format(i)\n",
    "        if not os.path.exists(os.path.dirname(fname)):\n",
    "            os.makedirs(os.path.dirname(fname))\n",
    "            \n",
    "        save_img(tri, fname)\n",
    "\n",
    "\n",
    "trigger_gen(model, model_cut, 0, target_loader, rec_loader)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.06613226452905811\n"
     ]
    }
   ],
   "source": [
    "def trigger_test_total(n, loader, trigger, size=8):\n",
    "    n.eval()\n",
    "    total =0\n",
    "    correct =0\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "                \n",
    "        imgs[:, :, 22:30, 22:30] = trigger\n",
    "\n",
    "        output, _ = n(imgs)\n",
    "        \n",
    "        _, preds = torch.max(output.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    print(\"Acc:\",correct/total)\n",
    "\n",
    "\n",
    "triggertrans = transforms.Compose([\n",
    "transforms.Resize((8,8)),\n",
    "transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trigger = Image.open('./image/triggers/specific/trigger3/iter8.jpg').convert('RGB')\n",
    "trigger = triggertrans(trigger) # size [3, 8, 8]\n",
    "\n",
    "test_img = 7\n",
    "test_label = 7\n",
    "test_set = LabeledDataset('cifar', f\"/home/mhc/public_dataset/cifar_imgs/train/{test_img}\", test_label, (1, 500), transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "model = alexnet(\"cifar10\",False)\n",
    "model.load_state_dict(torch.load(\"/home/mhc/AIJack/invert_and_poison/checkpoint/experiment_29/globmod/epoch_23_acc_0.692.pth\")[\"state_dict\"])\n",
    "\n",
    "trigger_test_total(model, test_loader, trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "patch_size = 8\n",
    "lr = 0.0001\n",
    "eps = (255/255.0)\n",
    "batch_size = 256\n",
    "num_iter = 3000  # PGD iteration\n",
    "\n",
    "losses = AverageMeter()\n",
    "cossim = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "iter_source = iter(rec_loader)\n",
    "iter_target = iter(target_loader)\n",
    "\n",
    "tri = torch.randn(3, patch_size, patch_size, requires_grad=True)\n",
    "tri[:,:,:] = 0.5\n",
    "tri = nn.Parameter(tri.to(device))\n",
    "\n",
    "for i in range(len(target_loader)): \n",
    "\t# LOAD ONE BATCH OF SOURCE AND ONE BATCH OF TARGET ITERALLY\n",
    "\t(input1, label1) = next(iter_target)\n",
    "\t(input2, label2) = next(iter_source)\n",
    "\t\n",
    "\n",
    "\tinput1 = input1.to(device)\n",
    "\tinput2 = input2.to(device)\n",
    "\t\n",
    "\toutput1, feat1 = model(input1)\n",
    "\t# feat1 = feat1.detach().clone()\n",
    "\t# print(\"feat1 size:\", feat1.size()) [B, fc_in] [256,2304]\n",
    "\n",
    "\n",
    "\t# PGD iteration \n",
    "\tfor j in range(num_iter):\n",
    "\n",
    "\t\tif tri.grad == None:\n",
    "\t\t\ttri = nn.Parameter(tri.to(device))\n",
    "\n",
    "\t\telse:\n",
    "\t\t\ttri.grad.data.zero_()\n",
    "\n",
    "\t\tlr1 = adjust_learning_rate(lr, j+1)\n",
    "\n",
    "\t\tinput2[:, :, 32-2-patch_size:32-2, 32-2-patch_size:32-2] = tri\n",
    "\t\toutput2, feat2 = model(input2)\n",
    "\n",
    "\t\t# FIND CLOSEST PAIR WITHOUT REPLACEMENT using greedy alorithm\n",
    "\t\t# feat11 = feat1.clone()\n",
    "\t\t# dist = torch.cdist(feat1, feat2)\n",
    "\t\t# # print(\"dist size:\", dist.size()) [B, B]\n",
    "\t\t\n",
    "\t\t# for _ in range(feat2.size(0)):\n",
    "\t\t# \tdist_min_index = (dist == torch.min(dist)).nonzero(as_tuple=False).squeeze()\n",
    "\t\t# \tfeat1[dist_min_index[1]] = feat11[dist_min_index[0]]\n",
    "\t\t# \tdist[dist_min_index[0], dist_min_index[1]] = 1e5\n",
    "\n",
    "\t\t# MSE  cosine_similarity ? \n",
    "\t\tloss1 = ((feat1-feat2)**2).sum(dim=1)\n",
    "\t\t# loss1 = - cossim(feat1, feat2)\n",
    "\t\tloss = loss1.sum()\n",
    "\n",
    "\t\tlosses.update(loss.item(), input1.size(0))\n",
    "\n",
    "\t\tloss.backward(retain_graph=True)\n",
    "\n",
    "\t\ttrigrad = tri.grad\n",
    "\t\ttri = tri - lr1*tri.grad\n",
    "\t\ttri = torch.clamp(tri, 0, eps).detach_()\n",
    "\n",
    "\t\t# input2_origin = input2.detach().clone()\n",
    "\t\t# input2[:, :, 32-2-patch_size:32-2, 32-2-patch_size:32-2] = tri\n",
    "\t\t# input2 = input2.clamp(0, 1)\n",
    "\n",
    "\t\tif (j+1) %50 == 0:\n",
    "\t\t\tprint(\" i: {} | iter: {:5d} | LR: {:2.4f} | Loss Val: {:5.3f} | Loss Avg: {:5.3f}\"\n",
    "\t\t\t\t\t\t.format( i, j, lr1, losses.val, losses.avg))\n",
    "\t\t\n",
    "\t\t# end the optimization \n",
    "\t\tif j == (num_iter-1):\n",
    "\t\t\tfname = '/home/mhc/AIJack/invert_and_poison/image/triggers/specific/iter{}.jpg'.format(i)\n",
    "\t\t\tif not os.path.exists(os.path.dirname(fname)):\n",
    "\t\t\t\tos.makedirs(os.path.dirname(fname))\n",
    "\t\t\t\t\n",
    "\t\t\tsave_img(tri, fname)\n",
    "\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# tri = (input2 - input2_origin)[0, :, 32-2-patch_size:32-2, 32-2-patch_size:32-2]  # [256, 1, 32, 32] -> [3,8,8], 且各个维度相同\n",
    "\t\t\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee93600a6eb60504e508f539cf2b837386ccee6f718dcf413180ced79f68df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
